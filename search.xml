<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>sadasds$$$$$</title>
      <link href="/2020/01/08/sadasds$$$$$/"/>
      <url>/2020/01/08/sadasds$$$$$/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><s>sadasds</s>$$$$$</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯</title>
      <link href="/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
      <url>/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>title: 朴素贝叶斯<br>tags:<br>-机器学习<br>categories: 算法<br>cover: /img/ML.png</p><h1 id="涉及公式"><a class="markdownIt-Anchor" href="#涉及公式"></a> 涉及公式</h1><p>先验概率P(A)：在不考虑任何情况下，A事件发生的概率<br>条件概率P(B|A)：A事件发生的情况下，B事件发生的概率:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(AB)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>后验概率P(A|B)：在B事件发生之后，对A事件发生的概率的重新评估<br>全概率：如果A和A’构成样本空间的一个划分，那么事件B的概率为：A和A’的概率分别乘以B对这两个事件的概率之和。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(B)=P(A)*P(B|A)+P(A')*P(B|A')</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(B)=\sum_{i=1}^{n}{P(A_i)*(B|A_i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p><h1 id="朴素贝叶斯算法"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法"></a> 朴素贝叶斯算法</h1><p>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。而朴素朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。</p><p><a href="/img/beiyesi/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="/img/beiyesi/1.jpg" class="lazyload" title="1"></a></p><h2 id="分类问题综述"><a class="markdownIt-Anchor" href="#分类问题综述"></a> 分类问题综述</h2><p><strong>从数学角度来说，分类问题可做如下定义：已知集合</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>y</mi><mi>n</mi></msub><mi mathvariant="normal">和</mi><mi>I</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">C=y_1,y_2,......y_n和I=x_1,x_2,......x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>确定映射规则y=f()，<strong>使得任意</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">x_i\in I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>**有且仅有一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">y_i\in C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>**使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y_i\in f(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>成立</p><p>其中C叫做类别集合，其中每一个元素是一个类别，而I叫做项集合（<strong>特征集合</strong>），其中每一个元素是一个待分类项，f叫做分类器。<strong>分类算法的任务就是构造分类器f。</strong></p><p><strong>分类算法的内容是要求给定特征，让我们得出类别，这也是所有分类问题的关键。那么如何由指定特征，得到我们最终的类别，也是我们下面要讲的，每一个不同的分类算法，对应着不同的核心思想。</strong></p><h2 id="朴素贝叶斯分类"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类"></a> 朴素贝叶斯分类</h2><p>那么既然是朴素贝叶斯<strong>分类算法</strong>，它的核心算法又是什么呢？</p><p><strong>是下面这个贝叶斯公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(B)*P(A|B)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>换个表达形式就会明朗很多，如下：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(类别|特征)=\frac{P(类别)*P(特征|类别)}{P(特征)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mord">∣</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord">∣</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>我们最终求的p(类别|特征)即可！就相当于完成了我们的任务。</strong></p><h2 id="例题分析"><a class="markdownIt-Anchor" href="#例题分析"></a> <strong>例题分析</strong></h2><p><strong>下面我先给出例子问题。</strong></p><p><strong>给定数据如下：</strong></p><p><a href="/img/beiyesi/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="/img/beiyesi/1.png" class="lazyload" title="1"></a></p><p><strong>现在给我们的问题是，如果一对男女朋友，男生想女生求婚，男生的四个特点分别是不帅，性格不好，身高矮，不上进，请你判断一下女生是嫁还是不嫁？</strong></p><p>这是一个典型的分类问题，<strong>转为数学问题就是比较p(嫁|(不帅、性格不好、身高矮、不上进))与p(不嫁|(不帅、性格不好、身高矮、不上进))的概率</strong>，谁的概率大，我就能给出嫁或者不嫁的答案！</p><p>这里我们联系到朴素贝叶斯公式：<a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/beiyesi/2.png" class="lazyload" title="2"></a></p><p>我们需要求p(嫁|(不帅、性格不好、身高矮、不上进),这是我们不知道的，但是通过朴素贝叶斯公式可以转化为好求的三个量，<strong>p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)（至于为什么能求，后面会讲，那么就太好了，将待求的量转化为其它可求的值，这就相当于解决了我们的问题！）</strong></p><h2 id="朴素贝叶斯算法的朴素一词解释"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法的朴素一词解释"></a> <strong>朴素贝叶斯算法的朴素一词解释</strong></h2><p><strong>那么这三个量是如何求得？</strong></p><p>是根据已知训练数据统计得来，下面详细给出该例子的求解过程。</p><p>回忆一下我们要求的公式如下：</p><p><a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/beiyesi/2.png" class="lazyload" title="2"></a></p><p>那么我只要求得p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)即可，好的，下面我分别求出这几个概率，最后一比，就得到最终结果。</p><p><strong>p(不帅、性格不好、身高矮、不上进|嫁) = p(不帅|嫁)*p(性格不好|嫁)*p(身高矮|嫁)*p(不上进|嫁)，那么我就要分别统计后面几个概率，也就得到了左边的概率！</strong></p><p>等等，为什么这个成立呢？学过概率论的同学可能有感觉了，这个等式成立的条件需要特征之间相互独立吧！</p><p><strong>对的！这也就是为什么朴素贝叶斯分类有朴素一词的来源，朴素贝叶斯算法是假设各个特征之间相互独立，那么这个等式就成立了！</strong></p><p><strong>但是为什么需要假设特征之间相互独立呢？</strong></p><p>1、我们这么想，假如没有这个假设，那么我们对右边这些概率的估计其实是不可做的，这么说，我们这个例子有4个特征，其中帅包括{帅，不帅}，性格包括{不好，好，爆好}，身高包括{高，矮，中}，上进包括{不上进，上进}，<strong>那么四个特征的联合概率分布总共是4维空间，总个数为2*3*3*2=36个。</strong></p><p><strong>24个，计算机扫描统计还可以，但是现实生活中，往往有非常多的特征，每一个特征的取值也是非常之多，那么通过统计来估计后面概率的值，变得几乎不可做，这也是为什么需要假设特征之间独立的原因。</strong></p><p>2、假如我们没有假设特征之间相互独立，那么我们统计的时候，就需要在整个特征空间中去找，比如统计p(不帅、性格不好、身高矮、不上进|嫁),</p><p><strong>我们就需要在嫁的条件下，去找四种特征全满足分别是不帅，性格不好，身高矮，不上进的人的个数，这样的话，由于数据的稀疏性，很容易统计到0的情况。 这样是不合适的。</strong></p><p>根据上面俩个原因，朴素贝叶斯法对条件概率分布做了条件独立性的假设，由于这是一个较强的假设，朴素贝叶斯也由此得名！这一假设使得朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p><p>好的，上面我解释了为什么可以拆成分开连乘形式。那么下面我们就开始求解！</p><p>我们将上面公式整理一下如下：<a href="/img/beiyesi/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="/img/beiyesi/3.png" class="lazyload" title="3"></a></p><p>下面我将一个一个的进行统计计算（<strong>在数据量很大的时候，根据中心极限定理，频率是等于概率的，这里只是一个例子，所以我就进行统计即可</strong>）。</p><p>p(嫁)=？</p><p>首先我们整理训练数据中，嫁的样本数如下：<a href="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" data-fancybox="group" data-caption="v2-82d69514c761c791c6eaf90dc0771b44_b" class="fancybox"><img alt="v2-82d69514c761c791c6eaf90dc0771b44_b" data-src="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" class="lazyload" title="v2-82d69514c761c791c6eaf90dc0771b44_b"></a></p><p><strong>则 p(嫁) = 6/12（总样本数） = 1/2</strong></p><p><strong>p(不帅|嫁) = 3/6 = 1/2</strong></p><p><strong>则p(性格不好|嫁)= 1/6</strong></p><p>p(矮|嫁) = 1/6**</p><p>p(不上进|嫁) = 1/6**</p><p><strong>下面开始求分母，p(不帅)，p（性格不好），p（矮），p（不上进）</strong></p><p><strong>不帅统计占4个，那么p（不帅）= 4/12 = 1/3</strong></p><p>性格不好占4个，那么p（性格不好） = 4/12 = 1/3</p><p>身高矮统计，占7个，那么p（身高矮） = 7/12</p><p>不上进统计所示，占4个，那么p（不上进） = 4/12 = 1/3</p><p><strong>到这里，要求p(不帅、性格不好、身高矮、不上进|嫁)的所需项全部求出来了，下面我带入进去即可，<a href="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" data-fancybox="group" data-caption="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" class="fancybox"><img alt="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" data-src="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" class="lazyload" title="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b"></a></strong></p><p>= (1/2<em>1/6</em>1/6<em>1/6</em>1/2)/(1/3<em>1/3</em>7/12*1/3)</p><p><strong>下面我们根据同样的方法来求p(不嫁|不帅，性格不好，身高矮，不上进)，完全一样的做法，为了方便理解，我这里也走一遍帮助理解。首先公式如下：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload" title="v2-7caa2cca71867344273c32a949b291f3_b"></a></strong></p><p>下面我也一个一个来进行统计计算，这里与上面公式中，分母是一样的，于是我们分母不需要重新统计计算！</p><p>p(不嫁)=6/12 = 1/2</p><p>p（不帅|不嫁） = 1/6</p><p>p（性格不好|不嫁） =3/6 = 1/2</p><p>p（矮|不嫁） = 6/6 = 1</p><p>p（不上进|不嫁） = 3/6 = 1/2</p><p>那么根据公式：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload" title="v2-7caa2cca71867344273c32a949b291f3_b"></a></p><p>p (不嫁|不帅、性格不好、身高矮、不上进) = ((1/6<em>1/2</em>1<em>1/2)<em>1/2)/(1/3</em>1/3</em>7/12*1/3)</p><p><strong>很显然(1/6*1/2*1*1/2) > (1/2*1/6*1/6*1/6*1/2)</strong></p><p><strong>于是有p (不嫁|不帅、性格不好、身高矮、不上进)>p (嫁|不帅、性格不好、身高矮、不上进)</strong></p><p><strong>所以我们根据朴素贝叶斯算法可以给这个女生答案，是不嫁！！！！</strong></p><h2 id="朴素贝叶斯分类的优缺点"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类的优缺点"></a> <strong>朴素贝叶斯分类的优缺点</strong></h2><p>优点：</p><p>（1） 算法逻辑简单,易于实现</p><p>（2）分类过程中时空开销小</p><p>缺点：</p><p>理论上，<strong>朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong></p><p>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</p><h2 id="常用朴素贝叶斯分类模型"><a class="markdownIt-Anchor" href="#常用朴素贝叶斯分类模型"></a> 常用朴素贝叶斯分类模型</h2><p><a href="/ppt/beiys.pptx">PPT</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SVM算法总结</title>
      <link href="/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="感知机模型"><a class="markdownIt-Anchor" href="#感知机模型"></a> 感知机模型：</h1><p>感知器模型是SVM、神经网络、深度学习等算法的基础;感知器模型就是试图找到一条直线，能够把所有的“+1”类和“-1”类分隔开，如果是高维空间中，感知器模型寻找的就是一个超平面，能够把所有的二元类别分割开。感知器模型的前提是：数据是线性可分的。</p><p><a href="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" class="lazyload"></a></p><p>目标是找到一个超平面，即： <a href="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" class="lazyload"></a></p><p>感知器模型为: <a href="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" class="lazyload"></a></p><p>感知器模型正确分类（预测和实际类别一致）：yθx>0（y为实际值，θx为预测值），错误分类（预测和实际类别不一致）：yθx<0；所以我们可以定义我们的损失函数为：期望使分类错误的所有样本(k条样本)到超平面的距离之和最小。</p><p>即：<a href="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" class="lazyload"></a> (去绝对值符号，分类错误<0,分子加”—“)</p><p>简化损失函数：因为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）:</p><p>简化损失函数：因 为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存 在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）: <a href="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" class="lazyload"></a> (即 <a href="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" class="lazyload"></a> ,分子分母相抵消，模长对结果无影响)。</p><p>直接使用梯度下降法就可以对损失函数求解，不过由于这里的k是分类错误的样本点集合，不是固定的，所以我们不能使用批量梯度下降法(BGD)求解，只能使用随机梯度下降(SGD)或者小批量梯度下降(MBGD)；一般在感知器模型中使用SGD来求解。</p><hr><h1 id="svm支持向量机"><a class="markdownIt-Anchor" href="#svm支持向量机"></a> SVM(支持向量机)</h1><p>支持向量机(Support Vecor Machine, SVM)本身是一个二元分类算法，是对感知器算法模型的一种扩展，现在的SVM算法支持线性分类和非线性分类的分类应用，并且也能够直接将SVM应用于回归应用中，同时通过OvR或者OvO的方式我们也可以将SVM应用在多元分类领域中。在不考虑集成学习算法，不考虑特定的数据集的时候，在分类算法中SVM可以说是特别优秀的。</p><p><a href="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" class="lazyload"></a></p><p>在感知器模型中，算法是在数据中找出一个划分超平面，让尽可能多的数据分布在这个平面的两侧，从而达到分类的效果，但是在实际数据中这个符合我们要求的超平面是可能存在多个的。</p><p><a href="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" class="lazyload"></a></p><p>SVM思想：在感知器模型中，我们可以找到多个可以分类的超平面将数据分开，并且优化时希望所有的点(预测正确的点)都离超平面尽可能的远，但是实际上离超平面足够远的点基本上都是被正确分类的，所以这个是没有意义的；反而比较关心那些离超平面很近的点，这些点比较容易分错。所以说我们<strong>只要让离超平面比较近的点尽可能的远离这个超平面</strong>，那么我们的模型分类效果应该就会比较不错。SVM其实就是这个思想。</p><p><a href="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" class="lazyload"></a></p><p>名词概念：</p><ul><li>线性可分(Linearly Separable)：在数据集中，如果可以找出一个超平面，将两组数据分开，那么这个数据集叫做线性可分数据。</li><li>线性不可分(Linear Inseparable)：在数据集中，没法找出一个超平面，能够将两组数据分开，那么这个数据集就叫做线性不可分数据。</li><li>分割超平面(Separating Hyperplane)：将数据集分割开来的直线/平面叫做分割超平面。</li><li>支持向量(Support Vector)：离分割超平面最近的那些点叫做支持向量。</li><li>间隔(Margin)：支持向量数据点到分割超平面的距离称为间隔。</li></ul><p>支持向量到超平面的距离为：在SVM中支持向量到超平面的函数距离一般设置为1</p><p>∵ <a href="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" class="lazyload"></a></p><p>∵ <a href="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" class="lazyload"></a></p><p>∴ <a href="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" class="lazyload"></a></p><p>SVM模型是让所有的分类点在各自类别的支持向量远离超平面的一侧，同时要求支持向量尽可能的远离这个超平面，用数学公式表示如下：</p><p>W^{T}=(w_1,w_2,…,w_n)</p><p><a href="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>(s.t: 指”受限制于…“)</p><p><a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> (对偶问题）</p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>则SVM原始目标函数/损失函数为：</p><p><a href="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>将此时的目标函数和约束条件使用KKT条件转换为拉格朗日函数，从而转换为无约束的优化函数。</p><p><a href="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" class="lazyload"></a></p><p>引入拉格朗日乘子后，优化目标变成：</p><p><a href="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" class="lazyload"></a>g(x)小于等于0 当L取最大值 g(x)等于0 消去g(x) KKT条件分析</p><p>根据拉格朗日对偶化特性，将该优化目标转换为等价的对偶问题来求解，从而优化目标变成：</p><p><a href="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" class="lazyload"></a></p><p>所以对于该优化函数而言，可以先求优化函数对于w和b的极小值，然后再求解对于拉格朗日乘子β的极大值。</p><p>首先求让函数L极小化的时候w和b的取值，这个极值可以直接通过对函数L分别求w和b的偏导数得到：</p><p><a href="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" class="lazyload"></a></p><p>将求解出来的w和b带入优化函数L中，定义优化之后的函数如下：</p><p><a href="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" class="lazyload"></a></p><p>通过对w、b极小化后，我们最终得到的优化函数只和β有关，所以此时我们可以直接极大化我们的优化函数，得到β的值，从而可以最终得到w和b的值。β值的求解使用SMO算法</p><p><a href="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" class="lazyload"></a></p><p>假设存在最优解β*； 根据w、b和β的关系，可以分别计算出对应的w值和b值(一般使用所有支持向量的计算均值来作为实际的b值)；</p><p><a href="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" class="lazyload"></a></p><p>这里的(xs,ys)即支持向量，根据KKT条件中的对偶互补条件(松弛条件约束)，支持向量必须满足一下公式：</p><p><a href="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" class="lazyload"></a></p><p>2.线性可分SVM算法流程：</p><ul><li>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</li><li>构造约束优化问题；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" class="lazyload"></a></p><p>使用SMO算法求出上式优化中对应的最优解β*；</p><ul><li>找出所有的支持向量集合S;</li></ul><p><a href="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" class="lazyload"></a></p><ul><li>更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" class="lazyload"></a></p><ul><li>构建最终的分类器；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" class="lazyload"></a></p><h2 id="线性可分svm总结"><a class="markdownIt-Anchor" href="#线性可分svm总结"></a> 线性可分SVM总结</h2><p>\1. 要求数据必须是线性可分的；</p><p>\2. 纯线性可分的SVM模型对于异常数据的预测可能会不太准；</p><p>\3. 对于线性可分的数据，线性SVM分类器的效果非常不错。</p><h1 id="svm的软间隔模型"><a class="markdownIt-Anchor" href="#svm的软间隔模型"></a> SVM的软间隔模型</h1><p>线性可分SVM中要求数据必须是线性可分的，才可以找到分类的超平面，但是有的时候线性数据集中存在少量的异常点，由于这些异常点导致了数据集不能够线性划分；直白来讲就是：正常数据本身是线性可分的，但是由于存在异常点数据，导致数据集不能够线性可分；</p><p><a href="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" class="lazyload"></a></p><p>如果线性数据中存在异常点导致没法直接使用SVM线性分割模型的时候，我们可以通过引入软间隔的概念来解决这个问题；</p><p>硬间隔：可以认为线性划分SVM中的距离度量就是硬间隔，在线性划分SVM中，要求函数距离一定是大于1的，最大化硬间隔条件为：</p><p><a href="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" class="lazyload"></a></p><p>软间隔：SVM对于训练集中的每个样本都引入一个松弛因子(ξ)，使得函数距离加上松弛因子后的值是大于等于1；这表示相对于硬间隔，对样本到超平面距离的要求放松了。(引入松弛因子(ξ))</p><p><a href="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" class="lazyload"></a></p><p>松弛因子(ξ)越大，表示样本点离超平面越近，如果松弛因子大于1，那么表示允许该样本点分错，所以说加入松弛因子是有成本的，过大的松弛因子可能会导致模型分类错误，所以最终的目标函数就转换成为：</p><p><a href="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" class="lazyload"></a>注：函数中的C&amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;0是惩罚参数，是一个超参数，类似L1/L2 norm的参数；C越大表示对误分类的惩罚越大，也就是越不允许存在分错的样本；C越小表示对误分类的惩罚越小， 也就是表示允许更多的分错样本存在；C值的给定需要调参。</p><p>同线性可分SVM，根据KKT条件构造软间隔最大化的约束问题对应的拉格朗日函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" class="lazyload"></a></p><p>从而将我们的优化目标函数转换为：</p><p><a href="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" class="lazyload"></a></p><p>优化目标同样满足KKT条件，所以使用拉格朗日对偶将优化问题转换为等价的对偶问题：</p><p><a href="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" class="lazyload"></a></p><p>先求优化函数对于w、b、ξ的极小值，这个可以通过分别对优化函数L求w、b、ξ的偏导数得，从而可以得到w、b、ξ关于β和μ之间的关系。</p><p><a href="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" class="lazyload"></a></p><p>将w、b、ξ的值带入L函数中，就可以消去优化函数中的w、b、ξ，定义优化之后的函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" class="lazyload"></a></p><p>最终优化后的目标函数/损失函数和线性可分SVM模型基本一样，除了约束条件不同而已， 也就是说也可以使用SMO算法来求解。</p><p><a href="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" class="lazyload"></a></p><ul><li>在硬间隔最大化的时候，支持向量比较简单，就是离超平面的函数距离为1的样本点就是支持向量。</li><li>在软间隔中，根据KKT条件中的对偶互补条件: β(1-ξ-y(wx+b))=0和μ(-ξ)=0，以及C-β-μ=0；从而有：</li><li>当0<βi≤C的时候，并且ξi=0的样本点均是支持向量(即所有的0<βi<c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑 第二个kkt条件)< li></c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑></li><li>当0<βi<c对应的样本就是支持向量。< li></c对应的样本就是支持向量。<></li><li>注：软间隔和硬间隔中的支持向量的规则是一样的；</li><li><a href="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" class="lazyload"></a> 则x1是支持变量</li></ul><p><a href="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型算法流程"><a class="markdownIt-Anchor" href="#svm的软间隔模型算法流程"></a> SVM的软间隔模型算法流程：</h2><p>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</p><p>step 1:选择一个惩罚系数C>0，构造约束优化问题；</p><p><a href="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" class="lazyload"></a></p><ul><li>Step2:使用SMO算法求出上式优化中对应的最优解β*；</li><li>step3:找出所有的支持向量集合S;</li></ul><p><a href="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" class="lazyload"></a></p><ul><li>step4:更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" class="lazyload"></a></p><ul><li>step5:构建最终的分类器</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型总结"><a class="markdownIt-Anchor" href="#svm的软间隔模型总结"></a> SVM的软间隔模型总结</h2><ul><li>\1. 可以解决线性数据中携带异常点的分类模型构建的问题；</li><li>\2. 通过引入惩罚项系数(松弛因子)，可以增加模型的泛化能力，即鲁棒性；</li><li>\3. 如果给定的惩罚项系数C越小，表示在模型构建的时候，就允许存在越多的分类错误的样本， 也就表示此时模型的准确率会比较低；如果惩罚项系数越大，表示在模型构建的时候，就越不允许存在分类错误的样本，也就表示此时模型的准确率会比较高。</li></ul><h1 id="非线性可分svm"><a class="markdownIt-Anchor" href="#非线性可分svm"></a> 非线性可分SVM</h1><p>不管是线性可分SVM还是加入惩罚系数后的软间隔线性可分SVM其实都要求数据本身是线性可分的，对于完全不可以线性可分的数据，这两种算法模型就没法解决这个问题了</p><p><a href="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" class="lazyload"></a></p><p>结合多项式回归在处理非线性可分数据时候的作用，在SVM的线性不可分的数据上，如果将数据映射到高维空间中，那么数据就会变成线性可分的，从而就可以使用线性可分SVM模型或者软间隔线性可分SVM模型。也就是说，对于线性不可分SVM模型来讲，重点在于低维特征数据到高维特征数据之间的映射。</p><p>定义一个从低维特征空间到高维特征空间的映射函数Ф，非线性可分SVM的优化目标函数：</p><p><a href="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" class="lazyload"></a></p><p>可以看到的是，只需要将原来的低维空间中的两个向量的点积转换为高维空间中两个向量的点积即可。</p><p><strong>问题</strong>：这样一来问题就解决了吗？似乎是的：拿到非线性数据，就找一个映射，然后一股脑把原来的数据映射到新空间中，再做线性 SVM 即可。不过事实上没有这么简单！其实刚才的方法稍想一下就会发现有问题：在最初的例子里做了一个二阶多项式的转换，对一个二维空间做映射，选择的新空间是原始空间的所有一阶和二阶的组合，得到了5个维度；如果原始空间是三维，那么我们会得到9维的新空间；如果原始空间是n维，那么我们会得到一个n(n+3)/2维的新空间**；这个数目是呈爆炸性增长的，这给计算带来了非常大的困难，而且如果遇到无穷维的情况，就根本无从计算。**</p><p><strong>2.核函数</strong></p><p>假设函数Ф是一个从低维特征空间到高维特征空间的一个映射，那么如果存在函数K(x,z), 对于任意的低维特征向量x和z，都有：</p><p><a href="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" class="lazyload"></a></p><p>称函数K(x,z)为核函数(kernal function)：在低维空间上的计算值等价于向量做维度扩展后的点乘的结果。 核函数在解决线性不可分问题的时候，采取的方式是：使用低维特征空间上的计算来避免在高维特征空间中向量内积的恐怖计算量；也就是说此时SVM模型可以应用在高维特征空间中数据可线性分割的优点，同时又避免了引入这个高维特征空间恐怖的内积计算量。</p><p>即：用低维空间中少的内积的计算量来让模型具有高维空间中的线性可分的优点。</p><p><strong>例</strong>：，设两个向量<a href="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" class="lazyload"></a> 和<a href="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" class="lazyload"></a>，而即是到前面说的五维空间的映射，因此映射过后的内积为：</p><p><a href="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" class="lazyload"></a></p><p>而同时我们可以发现有一下公式</p><p><a href="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" class="lazyload"></a></p><p>可以发现两者之间非常相似，所以我们只要乘上一个相关的系数，就可以让这两个式子的值相等，这样不就将五维空间的一个内积转换为两维空间的内积的运算。</p><p>现有有两个两维的向量，进行二阶多项式扩展，然后进行内积计算，这个时候映射高维后计算的计算量为：11次乘法+4次加法；采用近似计算的计算量为：3次乘法+2次加法；采用加系数后的近似计算的计算量为：4次乘法+2次加法；</p><p><a href="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" class="lazyload"></a></p><h1 id="核函数总结"><a class="markdownIt-Anchor" href="#核函数总结"></a> 核函数总结</h1><p>\1. 核函数可以自定义；核函数必须是正定核函数，即Gram矩阵是半正定矩阵；</p><p>\2. 核函数的价值在于它的效果相当于将特征进行从低维到高维的转换，但核函数它是在低维空间上的计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算；</p><p>\3. 通过核函数，可以将非线性可分的数据转换为线性可分数据；</p><p><a href="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" class="lazyload"></a></p><h2 id="svr"><a class="markdownIt-Anchor" href="#svr"></a> SVR</h2><p>做回归用，了解即可</p><h1 id="坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"><a class="markdownIt-Anchor" href="#坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"></a> 坐标下降（上升）法原理(搬运自<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/u010626937/article/details/75044343">https://blog.csdn.net/u010626937/article/details/75044343</a>)</h1><p>假设要求解下面的优化问题：</p><p><a href="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" class="lazyload"></a></p><p>在这里，我们需要求解m个变量αi，一般来说是通过梯度下降（这里是求最大值，所以应该叫上升）等算法来求解，每一次迭代对所有m个变量αi也就是α向量进行一次性优化。（这里指的是一个向量的所有分量）。通过每次迭代中的误差调整α向量中每个元素的值。而坐标上升法（坐标上升与坐标下降可以看做是一对，坐标上升是用来求解max最优化问题，坐标下降用于求min最优化问题）的思想是每次迭代只调整一个变量αi的值，其他变量的值在这次迭代中固定不变。(这里指的是一个向量中的一个分量)。</p><p><a href="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" class="lazyload"></a></p><p>最里面语句的意思是固定除αi之外的所有αj(i不等于j)，这时W可看作只是关于αi的函数，那么直接对αi求导优化即可。这里我们进行最大化求导的顺序i是从1到m，可以通过更改优化顺序来使W能够更快地增加并收敛。如果W在内循环中能够很快地达到最优，那么坐标上升法会是一个很高效的求极值方法。</p><p>用个二维的例子来说明下坐标下降法：我们需要寻找f(x,y)=x2+xy+y2的最小值处的(x*, y*)，也就是下图的F*点的地方.</p><p><a href="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" class="lazyload"></a></p><p>假设我们初始的点是A（图是函数投影到xoy平面的等高线图，颜色越深值越小），我们需要达到F<em>的地方。那最快的方法就是图中黄色线的路径，一次性就到达了，其实这个是牛顿优化法，但如果是高维的话，这个方法就不太高效了（因为需要求解矩阵的逆，这个不在这里讨论）。我们也可以按照红色所指示的路径来走。从A开始，先固定x，沿着y轴往让f(x, y)值减小的方向走到B点，然后固定y，沿着x轴往让f(x, y)值减小的方向走到C点，不断循环，直到到达F</em>。反正每次只要我们都往让f(x, y)值小的地方走就行了，这样脚踏实地，一步步走，每一步都使f(x, y)慢慢变小，总有一天，皇天不负有心人的。到达F*也是时间问题。到这里你可能会说，这红色线比黄色线贫富差距也太严重了吧。因为这里是二维的简单的情况嘛。如果是高维的情况，而且目标函数很复杂的话，再加上样本集很多，那么在梯度下降中，目标函数对所有αi求梯度或者在牛顿法中对矩阵求逆，都是很耗时的。这时候，如果W只对单个αi优化很快的时候，坐标下降法可能会更加高效。</p><p>数学例题讲解</p><p>下面以如下的优化问题为例：</p><p><a href="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" class="lazyload"></a></p><p>在迭代的过程中，每次固定x2更新x1，在确定了x1的条件下，固定x1，更新x2。即每次迭代求解：</p><p><a href="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" class="lazyload"></a></p><p>也即求解</p><p><a href="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" class="lazyload"></a></p><p>，假设我们首先固定x2,来更新x1：</p><p><a href="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" class="lazyload"></a></p><p>再固定x1，得到：</p><p><a href="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" class="lazyload"></a></p><p>不断按照上述的过程，直到算法收敛。</p><h1 id="七-smo可略过"><a class="markdownIt-Anchor" href="#七-smo可略过"></a> 七、SMO（可略过）</h1><p>序列最小优化算法(Sequential minimal optimization, SMO)是一种用于解决SVM训练过程中所产生的优化问题的算法。 于1998年由John Platt发明。SMO的思想类似坐标上升算法，我们需要优化一系列的αα的值，我们每次选择尽量少的 <a href="https://www.zhihu.com/equation?tex=%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Calpha" class="lazyload"></a> 来优化，不断迭代直到函数收敛到最优值。</p><p>梯度提升算法采用增量完成迭代，SMO利用自身完成迭代，如 <a href="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" class="lazyload"></a> 。</p><p>目标函数：</p><p><a href="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" class="lazyload"></a></p><p>假定存在一个β*=(β1,β2,…,βm)是我们最终的最优解，那么根据KKT条件我们可以计算出w和b的最优解，如下：</p><p><a href="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" class="lazyload"></a></p><p>进而我们可以得到最终的分离超平面为:</p><p><a href="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" class="lazyload"></a></p><p>拉格朗日乘子法和KKT的对偶互补条件为：</p><p><a href="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" class="lazyload"></a></p><p>β、μ和C之间的关系为：</p><p><a href="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" class="lazyload"></a></p><p>根据这个对偶互补条件，我们有如下关系式：</p><p><a href="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" class="lazyload"></a></p><p>也就是说我们找出的最优的分割超平面必须满足下列的目标条件(g(x)):</p><p><a href="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" class="lazyload"></a></p><p>拉格朗日对偶化要求的两个限制的初始条件为：</p><p><a href="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" class="lazyload"></a></p><p>从而可以得到解决问题的思路如下：</p><ul><li>首先，初始化后一个β值，让它满足对偶问题的两个初始限制条件；</li><li>然后不断优化这个β值，使得由它确定的分割超平面满足g(x)目标条件；而且在优化过程中，始终保证β值满足初始限制条件。</li><li>备注：这个求解过程中，和传统的思路不太一样，不是对目标函数求最小值，而是让g(x)目标条件尽可能的满足。</li></ul><p>在这样一个过程中，到底如何优化这个β值呢？？？整理可以发现β值的优化必须遵循以下两个基本原则：</p><ul><li>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</li><li>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于1的，yg(x)结果越是小于1就表示违反g(x)目标条件就越多。</li></ul><p>或者换一种思路来理解，因为目标函数中存在m个变量，直接优化比较难，利用启发式的方法/EM算法的思想，每次优化的时候，只优化两个变量，将其它的变量看成常数项，这样SMO算法就将一个复杂的优化算法转换为一个比较简单的两变量优化问题了。</p><p><a href="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" class="lazyload"></a></p><p>认为β1、β2是变量，其它β值是常量，从而将目标函数转换如下(C是常数项)：</p><p><a href="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" class="lazyload"></a></p><p>由于 <a href="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" class="lazyload"></a> ,并且y2=1，也就是我们使用β2来表示β1的值：</p><p>将上式带入目标优化函数，就可以消去β1，从而只留下仅仅包含β2的式子。</p><p><a href="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" class="lazyload"></a>V1,V2</p><p><a href="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" class="lazyload"></a>消去beta1</p><p><a href="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" class="lazyload"></a></p><p>考虑β1和β2的取值限定范围，假定新求出来的β值是满足我们的边界限制的，即如下所示：</p><p><a href="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" class="lazyload"></a></p><p>当y1=y2的时候，β1+β2=k； 由于β的限制条件，我们可以得到：</p><p><a href="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" class="lazyload"></a></p><p><a href="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" class="lazyload"></a></p><p>可以发现SMO算法中，是选择两个合适的β变量做迭代，其它变量作为常量来进行优化的一个过程，那么这两个变量到底怎么选择呢???</p><p>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</p><p>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于等于1的，越是小于1违反g(x)目标条件就越多。</p><p>SMO算法在选择第一个β变量的时候，需要选择在训练集上违反KKT条件最严重的样本点。一般情况下，先选择0<β<c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。< p></c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。<></p><p><a href="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" class="lazyload"></a></p><p>在选择第一个变量β1后，在选择第二个变量β2的时候，希望能够按照优化后的β1和β2有尽可能多的改变来选择，也就是说让|E1-E2|足够的大，当E1为正的时候，选择最小的Ei作为E2；当E1为负的时候，选择最大的Ei作为E2。</p><p>备注：如果选择的第二个变量不能够让目标函数有足够的下降，那么可以通过遍历所有样本点来作为β2，直到目标函数有足够的下降，如果都没有足够的下降的话，那么直接跳出循环，重新选择β1；</p><p>在每次完成两个β变量的优化更新之后，需要重新计算阈值b和差值Ei。当0<β1new<c时，有：< p></c时，有：<></p><p><a href="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" class="lazyload"></a></p><p>化简可得：</p><p><a href="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" class="lazyload"></a></p><p>同样的当β2的取值为: 0<β2<c的时候，我们也可以得到< p></c的时候，我们也可以得到<></p><p><a href="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" class="lazyload"></a></p><p>最终计算出来的b为：</p><p><a href="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" class="lazyload"></a></p><p>当更新计算阈值b后，就可以得到差值Ei为：</p><p><a href="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一、1</title>
      <link href="/2020/01/06/%E4%B8%80%E3%80%811/"/>
      <url>/2020/01/06/%E4%B8%80%E3%80%811/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>一、1.感知机模型：感知器模型是SVM、神经网络、深度学习等算法的基础;感知器模型就是试图找到一条直线，能够把所有的“+1”类和“-1”类分隔开，如果是高维空间中，感知器模型寻找的就是一个超平面，能够把所有的二元类别分割开。感知器模型的前提是：数据是线性可分的。![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/v2-624de9659125f370026c972f21dcbb69_r.jpg)<a href="data:image/jpeg;base64,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" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="data:image/jpeg;base64,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" class="lazyload"></a>目标是找到一个超平面，即： [![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdb2.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation)感知器模型为: [![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdc1.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation(1))感知器模型正确分类（预测和实际类别一致）：yθx>0（y为实际值，θx为预测值），错误分类（预测和实际类别不一致）：yθx<0；所以我们可以定义我们的损失函数为：期望使分类错误的所有样本(k条样本)到超平面的距离之和最小。即：[![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdd1.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation(2)) (去绝对值符号，分类错误<0,分子加”—“)</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/01/06/hello-world/"/>
      <url>/2020/01/06/hello-world/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
