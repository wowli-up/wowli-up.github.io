<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于python实现CNN卷积层及卷积运算优化学习</title>
      <link href="/2020/03/04/%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0CNN%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%8A%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/03/04/%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0CNN%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%8A%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="推导过程"><a class="markdownIt-Anchor" href="#推导过程"></a> 推导过程：</h1><h2 id="符号说明"><a class="markdownIt-Anchor" href="#符号说明"></a> 符号说明：</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.5.png" data-fancybox="group" data-caption="7.5" class="fancybox"><img alt="7.5" title="7.5" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.5.png" class="lazyload"></a></p><h2 id="dnn反向传播原理"><a class="markdownIt-Anchor" href="#dnn反向传播原理"></a> DNN反向传播原理</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.1.jpg" data-fancybox="group" data-caption="7.1" class="fancybox"><img alt="7.1" title="7.1" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.1.jpg" class="lazyload"></a></p><h2 id="卷积层反向传播推导"><a class="markdownIt-Anchor" href="#卷积层反向传播推导"></a> 卷积层反向传播推导</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.2.jpg" data-fancybox="group" data-caption="7.2" class="fancybox"><img alt="7.2" title="7.2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.2.jpg" class="lazyload"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.3.jpg" data-fancybox="group" data-caption="7.3" class="fancybox"><img alt="7.3" title="7.3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.3.jpg" class="lazyload"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.4.jpg" data-fancybox="group" data-caption="7.4" class="fancybox"><img alt="7.4" title="7.4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.4.jpg" class="lazyload"></a></p><h1 id="前向传播"><a class="markdownIt-Anchor" href="#前向传播"></a> 前向传播：</h1><h2 id="im2col的实现"><a class="markdownIt-Anchor" href="#im2col的实现"></a> im2col的实现</h2><p>im2col()：输入数据根据滤波器、步幅等展开的二维数组，每一行代表一条卷积输入数据</p><p>卷积就是卷积核跟图像矩阵的运算。卷积核是一个小窗口，记录的是权重。卷积核在输入图像上按步长滑动，每次操作卷积核对应区域的输入图像，将卷积核中的权值和对应的输入图像的值相乘再相加，赋给卷积核中心所对应的输出特征图的一个值。</p><p>im2col的作用就是优化卷积运算，如何优化呢，我们先学习一下这个函数的原理。<br>我们假设卷积核的尺寸为2×2，输入图像尺寸为3×3.im2col$做的事情就是对于卷积核每一次要处理的小窗，将其展开到新矩阵的一行（列），新矩阵的列（行）数，就是对于一副输入图像，卷积运算的次数（卷积核滑动的次数）</p><hr><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" title="4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/4.png" class="lazyload"></a></p><p>以最右侧一列为例，卷积核为2*2，所以新矩阵的列数就为4；步长为一，卷积核共滑动4次，行数就为4.</p><p>看到这里我就产生了一个疑问：我们把一个卷积核对应的值展开，到底应该展开为行还是列呢？卷积核的滑动先行后列还是相反？区别在哪？<br>这其实主要取决于我们使用的框架访存的方式。计算机一次性读取相近的内存是最快的，尤其是当需要把数据送到GPU去计算的时候，这样可以节省访存的时间，以达到加速的目的。不同框架的访存机制不一样，所以会有行列相反这样的区别。在caffe框架下，im2col是将一个小窗的值展开为一行，而在matlab中则展开为列。所以说，行列的问题没有本质区别，目的都是为了在计算时读取连续的内存。<br>这也解释了我们为什么要通过这个变化来优化卷积。如果按照数学上的步骤做卷积读取内存是不连续的，这样就会增加时间成本。同时我们注意到做卷积对应元素相乘再相加的做法跟向量内积很相似，所以通过im2col将矩阵卷积转化为矩阵乘法来实现。</p><h1 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im2col2</span><span class="params">(input_data, fh, fw, stride=<span class="number">1</span>, pad=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">     input_data--输入数据，shape为(batch_size,Channel,Height,Width)</span></span><br><span class="line"><span class="string">     fh -- 滤波器的height 3</span></span><br><span class="line"><span class="string">     fw --滤波器的width 3</span></span><br><span class="line"><span class="string">     stride -- 步幅 1</span></span><br><span class="line"><span class="string">     pad -- 填充 1</span></span><br><span class="line"><span class="string">     Returns :</span></span><br><span class="line"><span class="string">     col -- 输入数据根据滤波器、步幅等展开的二维数组，每一行代表一条卷积数据</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    N, C, H, W = input_data.shape   <span class="string">"[20,1,28,28]"</span></span><br><span class="line"></span><br><span class="line">    out_h = (H + <span class="number">2</span> * pad - fh) // stride + <span class="number">1</span>    <span class="string">"[28]"</span></span><br><span class="line">    out_w = (W + <span class="number">2</span> * pad - fw) // stride + <span class="number">1</span>     <span class="string">"[28]"</span></span><br><span class="line"></span><br><span class="line">    img = np.pad(input_data, [(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>), (pad, pad), (pad, pad)], <span class="string">"constant"</span>) </span><br><span class="line">     </span><br><span class="line">    <span class="string">"[30*30*1]"</span></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    col = np.zeros((N, out_h, out_w, fh * fw * C))  <span class="string">"fh * fw * C 负责存储每次参与卷积的参数"</span></span><br><span class="line">    print(col.shape)</span><br><span class="line">    <span class="comment"># 将所有维度上需要卷积的值展开成一行（列）,卷积次数为out_h*out_w*c,每次卷积内含参数量为（fh*fw*c）</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(out_h):</span><br><span class="line">        y_start = y * stride</span><br><span class="line">        y_end = y_start + fh</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(out_w):</span><br><span class="line">            x_start = x * stride</span><br><span class="line">            x_end = x_start + fw</span><br><span class="line">            col[:, y, x] = img[:, :, y_start:y_end, x_start:x_end].reshape(N, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    col = col.reshape(N * out_h * out_w, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> col</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">col2im2</span><span class="params">(col, out_shape, fh, fw, stride=<span class="number">1</span>, pad=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     col: 二维数组</span></span><br><span class="line"><span class="string">     out_shape-- 输出的shape，shape为(Number of example,Channel,Height,Width)</span></span><br><span class="line"><span class="string">     fh -- 滤波器的height</span></span><br><span class="line"><span class="string">     fw --滤波器的width</span></span><br><span class="line"><span class="string">     stride -- 步幅</span></span><br><span class="line"><span class="string">     pad -- 填充</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     Returns :</span></span><br><span class="line"><span class="string">     img -- 将col转换成的img ，shape为out_shape</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    N, C, H, W = out_shape</span><br><span class="line"></span><br><span class="line">    col_m, col_n = col.shape</span><br><span class="line"></span><br><span class="line">    out_h = (H + <span class="number">2</span> * pad - fh) // stride + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    out_w = (W + <span class="number">2</span> * pad - fw) // stride + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"out_h,out_w"</span>,out_h,out_w)</span><br><span class="line">    img = np.zeros((N, C, H, W))</span><br><span class="line">    <span class="comment">#img = np.pad(img,[(0,0),(0,0),(pad,pad),(pad,pad)],"constant")</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将col转换成一个filter</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(C):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> range(out_h):</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(out_w):</span><br><span class="line">                col_index = (c * out_h * out_w) + y * out_w + x</span><br><span class="line">                ih = y * stride</span><br><span class="line">                iw = x * stride</span><br><span class="line">                img[:, c, ih:ih + fh, iw:iw + fw] = col[col_index].reshape((fh, fw))</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></tbody></table></figure></div><p>测试：</p><p>输入input_data=[20,1,28,28];  fh=fw=3;采用SAME方式填充，则卷积的shape与input_data相同；</p><p>共卷积次数为15680次，每次卷积时input_data参与卷积的像素点数为9（卷积核为3*3）；所以col大小应为（15680，9）</p><p>程序输出结果：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">"测试"</span></span><br><span class="line">x=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">out = im2col2(x,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">print(out.shape)  “(<span class="number">15680</span>, <span class="number">9</span>)”</span><br></pre></td></tr></tbody></table></figure></div><h2 id="卷积层实现"><a class="markdownIt-Anchor" href="#卷积层实现"></a> 卷积层实现;</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Convolution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, W, fb, stride=<span class="number">1</span>, pad=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        W-- 滤波器权重，shape为(FN,NC,FH,FW),FN 为滤波器的个数</span></span><br><span class="line"><span class="string">        fb -- 滤波器的偏置，shape 为(1,FN)</span></span><br><span class="line"><span class="string">        stride -- 步长</span></span><br><span class="line"><span class="string">        pad -- 填充个数</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.W = W</span><br><span class="line">        self.fb = fb</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.pad = pad</span><br><span class="line"></span><br><span class="line">        self.col_X = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.col_W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.dW = <span class="literal">None</span></span><br><span class="line">        self.db = <span class="literal">None</span></span><br><span class="line">        self.out_shape = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#    self.out = None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        input_X-- shape为(m,nc,height,width)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.X = input_X</span><br><span class="line">        FN, NC, FH, FW = self.W.shape</span><br><span class="line"></span><br><span class="line">        m, input_nc, input_h, input_w = self.X.shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment"># 将输入数据展开成二维数组，shape为（m*out_h*out_w,FH*FW*C)</span></span><br><span class="line">        self.col_X = col_X = im2col2(self.X, FH, FW, self.stride, self.pad)</span><br><span class="line">        print(<span class="string">"self.col_X.shape"</span>,self.col_X .shape)</span><br><span class="line">        <span class="comment"># 将滤波器一个个按列展开(FH*FW*C,FN)       col_W.shape 15680,9 col_w 9,20  输出 15680，20</span></span><br><span class="line">        self.col_W = col_W = self.W.reshape(FN, <span class="number">-1</span>).T</span><br><span class="line">        out = np.dot(col_X, col_W) + self.fb</span><br><span class="line"></span><br><span class="line">        out = out.T <span class="comment">#     20，15680</span></span><br><span class="line"></span><br><span class="line">        out = out.reshape(m, FN, input_h, input_w)</span><br><span class="line">        self.out_shape = out.shape</span><br><span class="line">        print(<span class="string">"out.shape"</span>, out.shape)</span><br><span class="line">        <span class="keyword">return</span> out <span class="comment">#(20, 20, 28, 28)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, dz, learning_rate)</span>:</span></span><br><span class="line">        print(<span class="string">"==== Conv backbward ==== "</span>)</span><br><span class="line">        <span class="keyword">assert</span> (dz.shape == self.out_shape)</span><br><span class="line"></span><br><span class="line">        FN, NC, FH, FW = self.W.shape <span class="comment">#[20,1,28,28]</span></span><br><span class="line">        o_FN, o_NC, o_FH, o_FW = self.out_shape <span class="comment">#[20,20,28,28]</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"o_FN = {0}, o_NC = {1}, o_FH = {2}, o_FW = {3} "</span>.format(o_FN,o_NC,o_FH,o_FW))</span><br><span class="line"></span><br><span class="line">        col_dz = dz.reshape(o_NC, <span class="number">-1</span>)  <span class="comment">#col_dz  [20,15680]   dz[20, 20, 28, 28]</span></span><br><span class="line"></span><br><span class="line">        col_dz = col_dz.T</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"self.col_X.T,col_dz"</span>,self.col_X.shape,col_dz.shape)</span><br><span class="line">        self.dW = np.dot(self.col_X.T, col_dz)  <span class="comment"># [15680,9]  [15680,20]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.db = np.sum(col_dz, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.dW = self.dW.T.reshape(self.W.shape)</span><br><span class="line">        self.db = self.db.reshape(self.fb.shape)</span><br><span class="line">        print(<span class="string">"dw.shape = {0},db.shape = {1} ,self.col_W={2}"</span>.format(self.dW.shape, self.db.shape,self.col_W.shape))</span><br><span class="line">        d_col_x = np.dot(col_dz, self.col_W.T)  <span class="comment"># shape is (m*out_h*out_w,FH,FW*C)</span></span><br><span class="line">        print(<span class="string">"d_col_x.shape= "</span>, d_col_x.shape)</span><br><span class="line">        dx = col2im2(d_col_x, self.X.shape, FH, FW, stride=<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">"dx.shape= "</span>,dx.shape)</span><br><span class="line">        <span class="keyword">assert</span> (dx.shape == self.X.shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新W和b</span></span><br><span class="line">        self.W = self.W - learning_rate * self.dW</span><br><span class="line">        self.fb = self.fb - learning_rate * self.db</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dx</span><br></pre></td></tr></tbody></table></figure></div><p>测试：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">数据载入</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">x=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)) <span class="comment">#测试集采用[20,1,28,28]</span></span><br><span class="line">w=np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))   <span class="comment">#卷积核采用通道数为1的3*3的卷积核，卷积次数为20</span></span><br><span class="line">b=x=np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">20</span>)) </span><br><span class="line">dz=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">20</span>,<span class="number">28</span>,<span class="number">28</span>))<span class="comment">#dz.shape与前向传播大小相同</span></span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">正向与反向传播测试</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = Convolution(w,b)</span><br><span class="line">test.forward(x)</span><br><span class="line">test.backward(dz,<span class="number">0.01</span>)</span><br></pre></td></tr></tbody></table></figure></div><p>forward()内部变量输出：</p><p>self.col_X.shape (15680, 9)</p><p>out.shape (20, 20, 28, 28)</p><p>与设计思想相符合</p><p>backward()内部变量输出输出值</p><p>dz.shape = (20, 20, 28, 28),col_dz.shape = (20, 15680)<br>dw.shape = (20, 1, 3, 3),db.shape = (1, 20)<br>d_col_x.shape=  (15680, 9)<br>dx.shape=  (20, 1, 28, 28)</p><h2 id="代码源文件"><a class="markdownIt-Anchor" href="#代码源文件"></a> 代码源文件</h2><p><a href="C:%5CUsers%5C52664%5CDesktop%5C%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E7%82%B9%E5%8C%B9%E9%85%8D%E7%9A%84%E8%A7%86%E9%A2%91%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%5Cuntitled1%5C%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0%E5%8D%B7%E7%A7%AF%E5%B1%82.py">基于python实现卷积层.py</a></p><h2 id="tensflow实现卷积层"><a class="markdownIt-Anchor" href="#tensflow实现卷积层"></a> tensflow实现卷积层</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def conv2d_answer():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        </span><br><span class="line">        # [N, height, width, channels] 4-D的tensors</span><br><span class="line">        #占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [30, 28, 28, 1], name='input_x') </span><br><span class="line">        </span><br><span class="line">        x = np.ones(shape=[30, 28, 28, 1])</span><br><span class="line"></span><br><span class="line">        #卷积核变量</span><br><span class="line">        filter_w = tf.get_variable(</span><br><span class="line">            'w', initializer=tf.truncated_normal(shape=[3, 3, 1, 20])</span><br><span class="line">        )</span><br><span class="line">        filter_b = tf.get_variable(</span><br><span class="line">            'b', initializer=tf.zeros(20)</span><br><span class="line">        )</span><br><span class="line">        strides = [1, 2, 2, 1]  # 标准的写法。</span><br><span class="line">        pad = 'VALID'</span><br><span class="line">    </span><br><span class="line">        conv_output = tf.nn.conv2d(</span><br><span class="line">            input=input_x, filter=filter_w, strides=strides, padding=pad</span><br><span class="line">        )</span><br><span class="line">        print(conv_output.get_shape())</span><br><span class="line">        conv_output = conv_output + filter_b</span><br><span class="line">        # print(conv_output)</span><br><span class="line">        # fixme 高级api</span><br><span class="line">        conv_output1 = tf.layers.conv2d(</span><br><span class="line">            inputs=input_x, kernel_size=7, filters=20, strides=2, padding='valid',</span><br><span class="line">            use_bias=True</span><br><span class="line">        )</span><br><span class="line">        print(conv_output1.get_shape())</span><br><span class="line">        # with tf.Session() as sess:</span><br><span class="line">        #     sess.run(tf.global_variables_initializer())</span><br><span class="line">        #     print(sess.run(conv_output, feed_dict={input_x: x}))</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    conv2d_answer()</span><br></pre></td></tr></tbody></table></figure></div><p>tensflow卷积层通过函数 tf.nn.conv2d 或者tf.layers.conv2d实现，</p><pre><code>"""    tf.nn.conv2d(input,    # 卷积的输入，必须是一个4-D tensor对象        filter,            # 滤波器        strides,           # 步幅        padding,           # 填充方式  string:  'SAME'   or  'VALID'        data_format="NHWC",   # 对输入数据格式的要求，[N, height, width, channels]； 也可以是另一种格式："NCHW"        dilations=[1, 1, 1, 1],         name=None)    """</code></pre><h2 id="caffe"><a class="markdownIt-Anchor" href="#caffe"></a> caffe</h2><p>在Caffe中是使用src/caffe/util/im2col.cu中的im2col和col2im来完成矩阵的变形和还原操作，即为上方python实现的代码，将卷积运算转化为矩阵相乘，提升了运算速度。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结：</h1><p>相比于现有框架，我的卷积运算部分还有待优化。实现了以矩阵相乘实现卷积运算，但是内存利用率低，可以用加速GEMM进行提高。</p><h1 id="探究如何优化卷积运算速度"><a class="markdownIt-Anchor" href="#探究如何优化卷积运算速度"></a> 探究：如何优化卷积运算速度</h1><p>提升卷积层运算速度，主要在于提高卷积的计算速度。</p><h2 id="朴素卷积naive-convolution"><a class="markdownIt-Anchor" href="#朴素卷积naive-convolution"></a> <strong>朴素卷积（Naive Convolution）</strong></h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">'''Convolve `input` with `kernel` to generate `output`    </span><br><span class="line">input.shape = [input_channels, input_height, input_width]    </span><br><span class="line">kernel.shape = [num_filters, input_channels, kernel_height, kernel_width]    </span><br><span class="line">output.shape = [num_filters, output_height, output_width]</span><br><span class="line">'''</span><br><span class="line">for filter in 0..num_filters    </span><br><span class="line">    for channel in 0..input_channels        </span><br><span class="line">        for out_h in 0..output_height            </span><br><span class="line">            for out_w in 0..output_width                </span><br><span class="line">                for k_h in 0..kernel_height    </span><br><span class="line">                   for k_w in 0..kernel_width   </span><br><span class="line">                    output[filter, channel, out_h, out_h] +=   </span><br><span class="line">                    kernel[filter, channel, k_h, k_w] *    </span><br><span class="line">                    input[channel, out_h + k_h, out_w + k_w]</span><br></pre></td></tr></tbody></table></figure></div><p>涉及到了6个for嵌套循环，最内的循环进行了两次浮点运算（乘和加）。对于实验所使用的卷积层规模，它执行了8516万次，即该卷积需要1.7亿次浮点运算（170MFLOPs）。</p><p>内存访问同样需要时间：无法快速获取数据则无法快速处理数据。上述高度嵌套的for-loop使得数据访问非常艰难，从而无法充分利用缓存。</p><p>探究问题：如何访问正在处理的数据，以及这与数据存储方式有何关联。</p><p>逻辑上我们将矩阵/图像/张量看作是多维度的，但实际上它们存储在线性、一维的计算机内存中。我们必须定义一个惯例，来规定如何将多个维度展开到线性一维存储空间中，反之亦然。</p><p>大部分现代深度学习库使用行主序作为存储顺序。这意味着同一行的连续元素被存储在相邻位置。对于多维度而言，行主序通常意味着：在线性扫描内存时第一个维度的变化速度最慢。</p><h2 id="从卷积到矩阵相乘"><a class="markdownIt-Anchor" href="#从卷积到矩阵相乘"></a> <strong>从卷积到矩阵相乘</strong></h2><h3 id="采用矩阵相乘替换朴素卷积"><a class="markdownIt-Anchor" href="#采用矩阵相乘替换朴素卷积"></a> 采用矩阵相乘替换朴素卷积</h3><p>卷积是滤波器和输入图像块（patch）的点乘。如果我们将滤波器展开为2-D矩阵，将输入块展开为另一个2-D矩阵，则将两个矩阵相乘可以得到同样的数字。将图像块展开为矩阵的过程叫做im2col（image to column）。我们将图像重新排列为矩阵的列，每个列对应一个输入块，卷积滤波器就应用于这些输入块上。</p><p>在现实中，不同图像块之间通常会有重叠，因而im2col可能导致内存重叠。生成im2col 缓冲（im2col buffer）和过多内存（inflated memory）所花费的时间必须通过GEMM(矩阵乘优化)实现的加速来抵消。</p><h2 id="加速gemm"><a class="markdownIt-Anchor" href="#加速gemm"></a> <strong>加速GEMM</strong></h2><h3 id="缓存"><a class="markdownIt-Anchor" href="#缓存"></a> <strong>缓存</strong></h3><p>RAM是大的存储空间，但速度较慢。CPU缓存的速度要快得多，但其规模较小，因此恰当地使用CPU缓存至关重要。但是并不存在明确的指令：「将该数据加载到缓存」。该过程是由CPU自动管理的。</p><p>每一次从主内存中获取数据时，CPU会将该数据及其邻近的数据加载到缓存中，以便利用访问局部性（locality of reference）。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.1.jpg" data-fancybox="group" data-caption="1.1" class="fancybox"><img alt="1.1" title="1.1" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.1.jpg" class="lazyload"></a></p><p>你应该首先注意到我们访问数据的模式。我们按照下图A的形式逐行遍历数据，按照下图B的形式逐列遍历数据。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.2.jpg" data-fancybox="group" data-caption="1.2" class="fancybox"><img alt="1.2" title="1.2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.2.jpg" class="lazyload"></a></p><p>它们的存储也是行优先的，因此一旦我们找到 A[i, k]，则它在该行中的下一个元素A[i, k+1]已经被缓存了。接下来我们来看B中发生了什么：</p><ul><li>列的下一个元素并未出现在缓存中，即出现了缓存缺失（cache miss）。这时尽管获取到了数据，CPU也出现了一次停顿。</li><li>获取数据后，缓存同时也被 B 中同一行的其他元素填满。我们实际上并不会使用到它们，因此它们很快就会被删除。多次迭代后，当我们需要那些元素时，我们将再次获取它们。我们在用实际上不需要的值污染缓存。</li></ul><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.3.jpg" data-fancybox="group" data-caption="1.3" class="fancybox"><img alt="1.3" title="1.3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.3.jpg" class="lazyload"></a></p><p>我们需要重新修改loop，以充分利用缓存能力。如果数据被读取，则我们要使用它。这就是我们所做的第一项改变：循环重排序（loop reordering）。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">for i in 0..M:    </span><br><span class="line">    for j in 0..N:        </span><br><span class="line">        for k in 0..K:            </span><br><span class="line">            C[i, j] += A[i, k] * B[k, j]</span><br></pre></td></tr></tbody></table></figure></div><p>将i,j,k 循环重新排序为 i,k,j：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">for i in 0..M:    </span><br><span class="line">    for k in 0..K:        </span><br><span class="line">        for j in 0..N:</span><br></pre></td></tr></tbody></table></figure></div><p>乘/加的顺序对结果没有影响。而遍历顺序则变成了如下状态：</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.4.jpg" data-fancybox="group" data-caption="1.4" class="fancybox"><img alt="1.4" title="1.4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.4.jpg" class="lazyload"></a></p><p>速度大大提升。</p><h3 id="平铺tiling"><a class="markdownIt-Anchor" href="#平铺tiling"></a> <strong>平铺（Tiling）</strong></h3><p>要想进一步改进重排序，我们需要考虑另一个缓存问题。</p><p>对于A中的每一行，我们针对B中所有列进行循环。而对于 B 中的每一步，我们会在缓存中加载一些新的列，去除一些旧的列。当到达A的下一行时，我们仍旧重新从第一列开始循环。我们不断在缓存中添加和删除同样的数据，即缓存颠簸（cache thrashing）。</p><p>如果所有数据均适应缓存，则颠簸不会出现。如果我们处理的是小型矩阵，则它们会舒适地待在缓存里，不用经历重复的驱逐。庆幸的是，我们可以将矩阵相乘分解为子矩阵。要想计算 C 的r×c平铺，我们仅需要A的r行和B的c列。接下来，我们将 C 分解为6x16的平铺：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C(x, y) += A(k, y) * B(x, k);</span><br><span class="line"></span><br><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for yo in 0..M/6:        </span><br><span class="line">    for yi in 6:            </span><br><span class="line">        for xi in 0..16:                </span><br><span class="line">            for k in 0..K:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><p>我们将x,y 维度分解为外侧的xo,yo和内侧的xi,yi。我们将为该6x16 block优化micro-kernel（即xi,yi），然后在所有block上运行micro-kernel（通过xo,yo进行迭代）。</p><h3 id="向量化-fma"><a class="markdownIt-Anchor" href="#向量化-fma"></a> <strong>向量化 & FMA</strong></h3><p>大部分现代CPU支持SIMD（Single Instruction Multiple Data，单指令流多数据流）。在同一个CPU循环中，SIMD可在多个值上同时执行相同的运算/指令（如加、乘等）。如果我们在4个数据点上同时运行SIMD指令，就会直接实现4倍的加速。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.5.jpg" data-fancybox="group" data-caption="1.5" class="fancybox"><img alt="1.5" title="1.5" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.5.jpg" class="lazyload"></a></p><p>因此，当我们计算处理器的峰值速度时，我们其实有些作弊，把该向量化性能作为峰值性能。对于向量等数据而言，SIMD用处多多，在处理此类数据时，我们必须对每一个向量元素执行同样的指令。但是我们仍然需要设计计算核心，以充分利用它。<br>计算峰值FLOPs时，我们所使用的第二个技巧是FMA（Fused Multiply-Add）。尽管乘和加是两种独立的浮点运算，但它们非常常见，有些专用硬件单元可以将二者融合为一，作为单个指令来执行。编译器通常会管理FMA的使用。<br>在英特尔CPU上，我们可以使用SIMD（AVX & SSE）在单个指令中处理多达8个浮点数。编译器优化通常能够独自识别向量化的时机，但是我们需要掌控向量化以确保无误。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for yo in 0..M/6:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        for yi in 6:                </span><br><span class="line">            for vectorized xi in 0..16:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><h3 id="多线程处理threading"><a class="markdownIt-Anchor" href="#多线程处理threading"></a> <strong>多线程处理（Threading）</strong></h3><p>到现在为止，我们仅使用了一个CPU内核。我们拥有多个内核，每个内核可同时执行多个指令。一个程序可被分割为多个线程，每个线程在单独的内核上运行。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8).parallel(yo)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16 in steps of 16:    </span><br><span class="line">for parallel yo in steps of 6:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        for yi in 6:                </span><br><span class="line">            for vectorized xi in 0..16 in steps of 8:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><p>你可能注意到，对于非常小的规模而言，性能反而下降了。这是因为工作负载很小，线程花费较少的时间来处理工作负载，而花费较多的时间同步其他线程。多线程处理存在大量此类问题。</p><h3 id="展开unrolling"><a class="markdownIt-Anchor" href="#展开unrolling"></a> <strong>展开（Unrolling）</strong></h3><p>循环使我们避免重复写同样代码的痛苦，但同时它也引入了一些额外的工作，如检查循环终止、更新循环计数器、指针运算等。如果手动写出重复的循环语句并展开循环，我们就可以减少这一开销。例如，不对1个语句执行8次迭代，而是对4个语句执行2次迭代。</p><p>这种看似微不足道的开销实际上是很重要的，最初意识到这一点时我很惊讶。尽管这些循环操作可能「成本低廉」，但它们肯定不是免费的。每次迭代2-3个额外指令的成本会很快累积起来，因为此处的迭代次数是数百万。随着循环开销越来越小，这种优势也在不断减小。</p><p>展开是几乎完全被编译器负责的另一种优化方式，除了我们想要更多掌控的micro-kernel。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8).unroll(xi).unroll(yi)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for parallel yo:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        C(xi:xi+8, yi+0)            </span><br><span class="line">        C(xi:xi+8, yi+1)            </span><br><span class="line">        ...            </span><br><span class="line">        C(xi:xi+8, yi+5)            </span><br><span class="line">        C(xi+8:xi+16, yi+0)            </span><br><span class="line">        C(xi+8:xi+16, yi+1)            </span><br><span class="line">        ...            </span><br><span class="line">        C(xi+8:xi+16, yi+5)*/</span><br></pre></td></tr></tbody></table></figure></div><p>现在我们可以将速度提升到接近60 GFLOP/s。</p><h2 id="总结-2"><a class="markdownIt-Anchor" href="#总结-2"></a> <strong>总结</strong></h2><p>上述步骤涵盖一些性能加速最常用的变换。它们通常以不同方式组合，从而得到更加复杂的调度策略来计算同样的任务。</p><p>下面就是用Halide语言写的一个调度策略：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">matrix_mul(x, y) += A(k, y) * B(x, k);    </span><br><span class="line">out(x, y) = matrix_mul(x, y);</span><br><span class="line"></span><br><span class="line">out.tile(x, y, xi, yi, 24, 32)        </span><br><span class="line">  .fuse(x, y, xy).parallel(xy)        </span><br><span class="line">  .split(yi, yi, yii, 4)        </span><br><span class="line">  .vectorize(xi, 8)        </span><br><span class="line">  .unroll(xi)        </span><br><span class="line">  .unroll(yii);</span><br><span class="line"></span><br><span class="line"> matrix_mul.compute_at(out, yi)        </span><br><span class="line">   .vectorize(x, 8).unroll(y);</span><br><span class="line"></span><br><span class="line"> matrix_mul.update(0)        </span><br><span class="line">   .reorder(x, y, k)        </span><br><span class="line">   .vectorize(x, 8)        </span><br><span class="line">   .unroll(x)        </span><br><span class="line">   .unroll(y)        </span><br><span class="line">   .unroll(k, 2);</span><br></pre></td></tr></tbody></table></figure></div><ol><li>将out分解为32x24的平铺，然后将每个平铺进一步分解为8x24的子平铺。</li><li>使用类似的重排序、向量化和展开，在临时缓冲区（matrix_mul）计算8x24 matmul。</li><li>使用向量化、展开等方法将临时缓冲区matrix_mul 复制回out。</li><li>在全部32x24平铺上并行化这一过程</li></ol><h1 id="参考文章"><a class="markdownIt-Anchor" href="#参考文章"></a> 参考文章：</h1><p><a href="tps://zhuanlan.zhihu.com/p/66958390">通用矩阵乘（GEMM）优化与卷积计算</a></p><p><a href="https://zhuanlan.zhihu.com/p/85344625" target="_blank" rel="noopener">如何实现高速卷积？深度学习库使用了这些「黑魔法</a></p><p><a href="https://zhuanlan.zhihu.com/p/79584889" target="_blank" rel="noopener">手推DNN，CNN池化层，卷积层反向传播</a></p><h1 id="额外笔记"><a class="markdownIt-Anchor" href="#额外笔记"></a> 额外笔记：</h1><h2 id="same和valid"><a class="markdownIt-Anchor" href="#same和valid"></a> ”SAME”和“VALID”</h2><p>卷积之后的尺寸大小计算公式为：</p><ul><li>input_x  (FN,FC,FH,FW)</li><li>滤波器  Filter大小  (FN,FC,FH,FW)</li><li>Height与width  步长strides   S</li><li>Padding size P</li><li>求输出的shape: (FN,FC,FH,FW)</li></ul><p>我们可以得出输出大小</p><p>new_height = (input_height - filter_height + 2 * P)/S + 1<br>new_width = (input_width - filter_width + 2 * P)/S + 1</p><p>在实际操作时，我们还会碰到 **padding的两种方式 “SAME” 和 “VALID”，padding = “SAME”时，会在图像的周围填 “0”，padding = “VALID”则不需要，即 P=0。**一般会选“SAME”，以来减缓图像变小的速度，二来防止边界信息丢失</p><ol><li>padding = “VALID”：  P=0</li><li>padding = “SAME”：  kernel_size=1时，P=0；kernel_size=3时，P=1；kernel_size=5时，P=3，以此类推。</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogleNet 和ResNet</title>
      <link href="/2020/03/01/GoogleNet%20%E5%92%8CResNet/"/>
      <url>/2020/03/01/GoogleNet%20%E5%92%8CResNet/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>GoogleNet 和ResNet</p><p>GoogleNet ：</p><p>在同一层级上运行具备多个尺寸的滤波器,通过1x1，3x3和5x5、和池化层，提取了多尺度的特征,另外，在pooling层添加一个额外的并行pooling路径用于提高效率。</p><p>GoogelNet V1-V4</p><p>V1:</p><p>ResNet：</p><p>ResNet-bottleneck优化</p><p>ResNet中提出了一种bottleneck的结构块来代替常规的残差块，它借鉴了Inception网络中1x1 conv来缩减或扩张feature map维度<br>目的：不降低模型精度的前提下，降低参数量和计算量。</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.png" class="lazyload" title="1"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/2.png" class="lazyload" title="2"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/3.png" class="lazyload" title="3"></a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>学习率(Learning rate)的理解以及如何调整学习率</title>
      <link href="/2020/02/17/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/2020/02/17/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="1什么是学习率learning-rate"><a class="markdownIt-Anchor" href="#1什么是学习率learning-rate"></a> 1.什么是学习率(Learning rate)？</h2><p>**学习率(Learning rate)**作为监督学习以及深度学习中重要的超参，其决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。<br>  这里以梯度下降为例，来观察一下不同的学习率对代价函数的收敛过程的影响（这里以代价函数为凸函数为例）：<br>  回顾一下梯度下降的代码：<br>  repeat{</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>j</mi></msub><mo>=</mo><msub><mi>θ</mi><mi>j</mi></msub><mo>−</mo><mi>α</mi><mfrac><mrow><mi mathvariant="normal">Δ</mi><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><msub><mi>θ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\theta_j = \theta_j -\alpha\frac{\Delta J(\theta)}{\Delta\theta_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.55232em;vertical-align:-0.5423199999999999em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathdefault mtight" style="margin-right:0.09618em;">J</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>​            ｝</p><p>当学习率设置的<strong>过小</strong>时，收敛过程如下：</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/5.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" title="5" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/5.jpg" class="lazyload"></a></p><p>​     当学习率设置的<strong>过大</strong>时，收敛过程如下：<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.jpg" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" title="6" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.jpg" class="lazyload"></a></p><p>由上图可以看出来，当学习率设置的<strong>过小</strong>时，<strong>收敛过程将变得十分缓慢</strong>。而当学习率设置的<strong>过大</strong>时，<strong>梯度可能会在最小值附近来回震荡，甚至可能无法收敛</strong>。<br>  我们再来看一下学习率对<strong>深度学习</strong>模型训练的影响：<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.1.jpg" data-fancybox="group" data-caption="6.1" class="fancybox"><img alt="6.1" title="6.1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.1.jpg" class="lazyload"></a></p><p>可以由上图看出，固定学习率时，当到达收敛状态时，会在最优值附近一个<strong>较大的区域内</strong>摆动；而当随着迭代轮次的增加而减小学习率，会使得在收敛时，在最优值附近一个<strong>更小的区域</strong>内摆动。（之所以曲线震荡朝向最优值收敛，是因为在每一个mini-batch中都存在噪音）。<br>  因此，选择一个合适的学习率，对于模型的训练将至关重要。下面来了解一些学习率调整的方法。</p><hr><h2 id="2-学习率的调整"><a class="markdownIt-Anchor" href="#2-学习率的调整"></a> 2. 学习率的调整</h2><h3 id="21-离散下降discrete-staircase"><a class="markdownIt-Anchor" href="#21-离散下降discrete-staircase"></a> 2.1 离散下降(discrete staircase)</h3><p>对于<strong>深度学习</strong>来说，每 tt 轮学习，学习率减半。对于<strong>监督学习</strong>来说，初始设置一个较大的学习率，然后随着迭代次数的增加，减小学习率。</p><h3 id="22-指数减缓exponential-decay"><a class="markdownIt-Anchor" href="#22-指数减缓exponential-decay"></a> 2.2 指数减缓(exponential decay)</h3><p>对于<strong>深度学习</strong>来说，学习率按训练轮数增长指数差值递减。例如：</p><p>​<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.9</mn><msup><mn>5</mn><mrow><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></msup><mo>⋅</mo><msub><mi>α</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\alpha = 0.95^{epoch\_num}\cdot\alpha_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord"><span class="mord">5</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>​        又或者公式为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mfrac><mi>k</mi><msqrt><mrow><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\alpha = \frac{k}{\sqrt{epoch\_num}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.709708em;vertical-align:-0.8296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.5046085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9791307142857142em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span><span style="top:-2.951130714285714em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width="400em" height="1.5428571428571431em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.47744071428571444em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8296em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>​ 其中epoch_num为当前epoch的迭代轮数。不过第二种方法会引入另一个超参 kk 。</p><h3 id="23-分数减缓1t-decay"><a class="markdownIt-Anchor" href="#23-分数减缓1t-decay"></a> 2.3 分数减缓(1/t decay)</h3><p>​  对于<strong>深度学习</strong>来说，学习率按照公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mfrac><mi>α</mi><mrow><mn>1</mn><mo>+</mo><mi>d</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>y</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>∗</mo><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha = \frac{\alpha}{1+decay\_rate*epoch\_num}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2573919999999998em;vertical-align:-0.5619999999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">e</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5619999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>变化， decay_rate控制减缓幅度。</p><h1 id="软饱和与梯度消散"><a class="markdownIt-Anchor" href="#软饱和与梯度消散"></a> 软饱和与梯度消散</h1><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.3.png" data-fancybox="group" data-caption="6.3" class="fancybox"><img alt="6.3" title="6.3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.3.png" class="lazyload"></a></p><h1 id="交叉熵损失函数"><a class="markdownIt-Anchor" href="#交叉熵损失函数"></a> 交叉熵损失函数</h1><p>通过最大似然估计的原理，我们可以得到，当似然函数最大的时候，似然函数中对应的模型参数是我们求解的最优参数；而在损失函数中，我们认为当损失函数最小的时候，损失函数中对应模型参数是我们求解的最优参数；故我们可以使用负的似然函数作为损失函数，这样我们可以得到Logistic回归的损失函数（交叉熵损失函数）</p><p>详见知乎：</p><p><a href="https://www.zhihu.com/search?type=content&q=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">https://www.zhihu.com/search?type=content&q=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0</a></p><h1 id="sotfmax-bp-推导"><a class="markdownIt-Anchor" href="#sotfmax-bp-推导"></a> <strong>sotfmax BP 推导</strong></h1><p><a href="https://zhuanlan.zhihu.com/p/25723112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25723112</a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>δ</mi><mfrac><mi>A</mi><mi>B</mi></mfrac></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mfrac><mrow><mi>δ</mi><mi>A</mi></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac><mi>B</mi><mo>−</mo><mi>A</mi><mfrac><mrow><mi>δ</mi><mi>B</mi></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac></mrow><msup><mi>B</mi><mn>2</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">\frac{\delta\frac{A}{B}}{\delta a} =\frac{ \frac{\delta A}{\delta a}B -A\frac{\delta B }{\delta a}     }{B^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.506265em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.161265em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5508em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8720928571428572em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.51182em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.16682em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5508em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8800285714285714em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">A</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8800285714285714em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.4.png" data-fancybox="group" data-caption="6.4" class="fancybox"><img alt="6.4" title="6.4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.4.png" class="lazyload"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.5.png" data-fancybox="group" data-caption="6.5" class="fancybox"><img alt="6.5" title="6.5" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.5.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Canny边缘检测</title>
      <link href="/2020/02/13/Canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/"/>
      <url>/2020/02/13/Canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">title: Canny边缘检测-论鸡尾酒疗法</span><br><span class="line">tags:</span><br><span class="line">-数字图像处理</span><br><span class="line">categories: cv</span><br><span class="line">cover: /img/ML.png</span><br><span class="line">katex: true</span><br></pre></td></tr></tbody></table></figure></div><p>Canny 边缘检测算法被很多人认为是边缘检测的最优算法，为什么说它是最优算法呢？我们参考一下业界的评判标准：</p><ul><li><strong>低错误率:</strong> 标识出尽可能多的实际边缘，同时尽可能的减少噪声产生的误报。</li><li><strong>高定位性:</strong> 标识出的边缘要与图像中的实际边缘尽可能接近。</li><li><strong>最小响应:</strong> 图像中的边缘只能标识一次。</li></ul><p>那么问题来了，我们都已经介绍过Sobel、Laplace这种一阶或二阶的算子了，Canny算子又是什么？它又是凭什么获得最优这个称号的？</p><blockquote><p>什么是Canny边缘检测？</p></blockquote><p>Canny 边缘检测算法其实就是 John F. Canny 于 1986年开发出来的一个多级边缘检测算法，用Canny的名字命名，用来检测图像边缘的一种算法。</p><blockquote><p>它为什么这么厉害？</p></blockquote><p>Canny一定是调酒大师，简单的素材在他手里组合一下就焕发了新的活力。简单的回答是，Canny合理的运用了滤波、一阶、二阶边缘检测、边缘细化以及关键的提出了“双阈值边缘连接处理”，把这些基础简单的算法组合一下，达到了最优的效果。可以参考下面的顺序：</p><ol><li><strong>彩色图像转换为灰度图像</strong></li><li><strong>对图像进行高斯模糊</strong></li><li><strong>计算图像梯度，根据梯度计算图像边缘幅值与角度</strong></li><li><strong>非最大信号压制处理（边缘细化）</strong></li><li><strong>双阈值边缘连接处理</strong></li><li><strong>二值化图像输出结果</strong></li></ol><blockquote><p><strong>彩色图像转换为灰度图像</strong></p></blockquote><p>这个不用过多解释了把，cvtColor。因为Canny只能处理灰度图像，而且转换的最终结果是二值图。所以如果是彩色图，转换后才能灰度图还是很有必要的</p><blockquote><p><strong>对图像进行高斯模糊</strong></p></blockquote><p>在Canny内部，已经做了一个size=5的高斯滤波，可以参考如下内核算子。但是需要注意的是，在做Canny之前是否要再做一次高斯滤波是非常值得考究的事情。</p><p><a href="../img/cv/6.png" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" data-src="../img/cv/6.png" class="lazyload" title="6"></a></p><blockquote><p><strong>计算图像梯度，根据梯度计算图像边缘幅值与角度</strong></p><p><strong>最大信号压制处理（边缘细化）</strong></p><p><strong>双阈值边缘连接处理</strong></p><p><strong>二值化图像输出结果</strong></p></blockquote><p>参考https://blog.csdn.net/weixin_40647819/article/details/91411424</p><p><a href="https://zhuanlan.zhihu.com/p/79896426" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79896426</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>图像金字塔</title>
      <link href="/2020/02/12/%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/"/>
      <url>/2020/02/12/%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">title:  图像金字塔</span><br><span class="line">tags:</span><br><span class="line">-数字图像处理</span><br><span class="line">categories: cv</span><br><span class="line">cover: /img/ML.png</span><br><span class="line">katex: true</span><br></pre></td></tr></tbody></table></figure></div><h1 id="图像金字塔"><a class="markdownIt-Anchor" href="#图像金字塔"></a> 图像金字塔：</h1><p>一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。我们将一层一层的图像比喻成金字塔，层级越高，则图像越小，分辨率越低。就像这样：</p><p><a href="../img/cv/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="../img/cv/1.jpg" class="lazyload" title="1"></a></p><p>作用：</p><p>图像金字塔是图像中多尺度表达的一种，最初用于机器视觉和图像压缩，最主要用于图像的分割、融合。</p><p>分类：</p><p>高斯金字塔（Gussianpyramid）：用来下采样，主要的图像金字塔。</p><p>拉普拉斯金字塔（Laplacianpyramid）：用来从金字塔底层图像搭建上层未采样图像，上采样重建一个图像。在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。</p><p>图像金字塔中的向上和向下采样分别通过OpenCv函数pyrUp和pyrDown实现。</p><p>这里的向下与向上采样，是对图像的尺寸而言的（和金字塔的方向相反），即向下就是图像尺寸缩小，向上是图像尺寸变大。</p><h2 id="11高斯金字塔缩小图像"><a class="markdownIt-Anchor" href="#11高斯金字塔缩小图像"></a> 1.1高斯金字塔（缩小图像）</h2><p>高斯金字塔是由底部的最大分辨率图像逐次向下采样得到的一系列图像。最下面的图像分辨率最高，越往上图像分辨率越低。</p><p><a href="../img/cv/3.jpg" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/cv/3.jpg" class="lazyload" title="3"></a></p><p>高斯金字塔的向下采样过程是：</p><ol><li><p>对于给定的图像先做一次高斯平滑处理，也就是使用一个大小为的卷积核对图像进行卷积操作.OpenCv 中使用的高斯核:<a href="../img/cv/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" data-src="../img/cv/4.png" class="lazyload" title="4"></a></p></li><li><p>然后再对图像采样，去除图像中的偶数行和偶数列，然后就得到一张图片</p></li><li><p>对这张图片循环1) 和 2)操作就可以得到高斯金字塔。</p></li></ol><p>如模型可以看出，一次循环得到的图像即为G_(i+1)的图像，显而易见，结果图像只有原图的四分之一。通过对输入图像G_i(原始图像)不停迭代以上步骤就会得到整个金字塔。同时我们也可以看到，向下取样会逐渐丢失图像的信息。以上就是对图像的向下取样操作，即缩小图像。</p><h3 id="高斯金字塔的向上采样过程是"><a class="markdownIt-Anchor" href="#高斯金字塔的向上采样过程是"></a> <strong>高斯金字塔的向上采样过程是：</strong></h3><ol><li><p>将图像在每个方向扩大为原来的两倍，新增的行和列以0填充</p></li><li><p>使用先前同样的内核(乘以4)与放大后的图像卷积，获得 “新增像素”的近似值</p></li></ol><p>得到的图像即为放大后的图像，但是与原来的图像相比会发觉比较模糊，因为在缩放的过程中已经丢失了一些信息，如果想在缩小和放大整个过程中减少信息的丢失，这些数据形成了<strong>拉普拉斯金字塔</strong>。</p><p>注意：上采样和下采样是非线性处理，不可逆，有损的处理！</p><h2 id="12拉普拉斯金字塔放大图像"><a class="markdownIt-Anchor" href="#12拉普拉斯金字塔放大图像"></a> <strong>1.2拉普拉斯金字塔（放大图像）</strong></h2><p>用来从金字塔低层图像重建上层未采样图像，在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。</p><p><a href="../img/cv/5.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" data-src="../img/cv/5.jpg" class="lazyload" title="5"></a></p><p>​                                                       拉普拉斯金字塔的生成和高斯金字塔的关系</p><p>好在拉普拉斯金字塔有现成的公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mi>G</mi><mi>i</mi></msub><mo>−</mo><msub><mi>U</mi><mi>p</mi></msub><mo stretchy="false">(</mo><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>⊗</mo><mo stretchy="false">)</mo><msub><mi>κ</mi><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow></msub></mrow><annotation encoding="application/x-tex">L_{i} = G_{i} -U_{p} (G_{i+1}\otimes )\kappa_{5\times5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord">⊗</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span><span class="mbin mtight">×</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">G_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示第i层的高斯图像;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">G_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>表示第i+1层的高斯图像;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>U</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">U_{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>表示向上采样，将源图像中位置为(x,y)的像素映射到目标图像的(2x+1,2y+1)位置;</p><p>$\otimes $ 用来表示卷积;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>κ</mi><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\kappa_{5\times5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span><span class="mbin mtight">×</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>表示5*5的内核（参考上面的高斯内核）</p><p>因此在OpenCv中的拉普拉斯公式等价于   <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mi>G</mi><mi>i</mi></msub><mo>−</mo><mi>P</mi><mi>y</mi><mi>r</mi><mi>U</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{i} = G_{i} -PyrUp(G_{i+1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>也就是说，拉普拉斯金字塔是通过源图像减去先缩小后再放大的图像的一系列图像构成的。保留的是残差！为图像还原做准备！</p><p><a href="../img/cv/2.jpg" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/cv/2.jpg" class="lazyload" title="2"></a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SVM算法总结</title>
      <link href="/2020/02/12/%E5%88%9D%E5%A7%8B/"/>
      <url>/2020/02/12/%E5%88%9D%E5%A7%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cnn</title>
      <link href="/2020/02/03/cnn/"/>
      <url>/2020/02/03/cnn/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><a href="https://www.cnblogs.com/pinard/p/6489633.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6489633.html</a></p><p><a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6494810.html</a></p><p>特征图</p><ol><li>数据输入层：Input Layer</li><li>卷积计算层：CONV Layer<br>ReLU激励层：ReLU Incentive  Layer<br>池化层：Pooling Layer  下采样</li><li>全连接层：FC Layer    -分类，回归<br>备注：Batch Normalization Layer（必备）<br>结构：输入层–{[卷积层+批归一化+激活函数+dropout(可选)]*N-池化层}*M–拉平层–[FC+批归一化+激活]*K–输出层–激活函数(分类用:softmax或sigmoid)</li></ol><p>卷积神经网络-Input Layer：</p><p>分类：one-hot 哑编码</p><p>回归：z-score</p><p>和神经网络/机器学习一样，需要对输入的数据需要进行预处理操作，需要进行预处理的主要原因是：<br>输入数据单位不一样，可能会导致神经网络收敛速度慢，训练时间长<br>数据范围大（方差大）的输入在模式分类中的作用可能偏大，而数据范围小的作用就有可能偏小<br>由于神经网络中存在的激活函数是有值域限制的，因此需要将网络训练的目标数据映射到激活函数的值域<br>S形激活函数在(-4, 4)区间以外区域很平缓，区分度太小。例如S形函数f(X)，f(100)与f(5)只相差0.0067</p><p>常见3种数据预处理方式<br>去均值<br>将输入数据的各个维度中心化到0<br>归一化   (0,255) (0,1)<br>将输入数据的各个维度的幅度归一化到同样的范围<br>PCA/白化<br>用PCA降维（去掉特征与特征之间的相关性）<br>白化是在PCA的基础上，对转换后的数据每个特征轴上的幅度进行归一化<br><a href="http://ufldl.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96" target="_blank" rel="noopener">http://ufldl.stanford.edu/wiki/index.php/白化</a></p><p>卷积计算层：CONV Layer<br>局部关联：每个神经元看做一个filter/kernel<br>窗口(receptive field–感受野)滑动，filter对局部数据进行计算<br>相关概念<br>输入特征图的深度：  depth == channel<br>卷积核大小(滤波器):   kernel  size  11 3/3<br>输出深度==卷积核个数<br>步幅：stride（取值：1   2   4 ） 影响输出图片的高和宽<br>填充值：zero-padding<br>填充方式：same  或者  valid<br>CONV过程参考：<a href="http://cs231n.github.io/assets/conv-demo/index.html" target="_blank" rel="noopener">http://cs231n.github.io/assets/conv-demo/index.html</a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">tf.nn.conv2d(input,    # 卷积的输入，必须是一个4-D tensor对象</span><br><span class="line">    filter,            # 滤波器</span><br><span class="line">    strides,           # 步幅</span><br><span class="line">    padding,           # 填充方式  string:  'SAME'   or  'VALID'</span><br><span class="line">    data_format="NHWC",   # 对输入数据格式的要求，[N, height, width, channels]； 也可以是另一种格式："NCHW"</span><br><span class="line">    dilations=[1, 1, 1, 1],   #扩大感受野</span><br><span class="line">    name=None)</span><br><span class="line">"""</span><br><span class="line">或者</span><br><span class="line">  conv_output1 = tf.layers.conv2d(</span><br><span class="line">            inputs=input_x, kernel_size=7, filters=20, strides=2, padding='valid',</span><br><span class="line">            use_bias=True</span><br><span class="line">        )</span><br></pre></td></tr></tbody></table></figure></div><p>池化层：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">max_pool(value,   # 也是4-D tensors [N, height, width, channels] </span><br><span class="line">    ksize,     # 池化核大小</span><br><span class="line">    strides,   # 池化步幅大小</span><br><span class="line">    padding,   # 填充方式</span><br><span class="line">    data_format="NHWC",   # 对输入数据格式的约定，也可以是另一种格式："NCHW"</span><br><span class="line">    name=None)</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>卷积神经网络-参数初始化:</p><p>在卷积神经网络中，可以看到神经元之间的连接是通过权重w以及偏置b实现的。在具体的神经网络之前，我们还有一个任务需要做，那就是初始化参数<br>权重的初始化（截尾正态分布 标准差为(经验分布)<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><msqrt><mi>n</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.383108em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6258665em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8059050000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-2.765905em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.234095em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>或者0.1）<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/2.png" class="lazyload" title="2"></a></p><p>​            一般方式：很小的随机数(对于多层深度神经网络，太小的值会导致回传的梯度非常小)，一般随机数是服从均值为0，方差未知(建议：2/n, n为权重数量，<a href="https://arxiv.org/pdf/1502.01852.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.01852.pdf</a>)的高斯分布随机数列。<br>错误方式：全部初始化为0，全部设置为0，在反向传播的时候是一样的梯度值，那么这个网络的权重是没有办法差异化的，也就没有办法学习到东西。<br>偏置项的初始化<br>​                  一 般直接设置为0，在存在ReLU激活函数的网络中，也可以考虑设置为一个很小的数字</p><p>卷积神经网络正则化和Dropout</p><p>神经网络的学习能力受神经元数目以及神经网络层次的影响，神经元数目越大，神经网络层次越高，那么神经网络的学习能力越强，那么就有可能出现过拟合的问题；(通俗来讲：神经网络的空间表达能力变得更紧丰富了)<br>Regularization：正则化，通过降低模型的复杂度，通过在cost函数上添加一个正则项的方式来降低overfitting，主要有L1和L2两种方式</p><p>或</p><p>Dropout：通过随机删除神经网络中的神经元来解决overfitting问题，在每次迭代的时候，只使用部分神经元训练模型获取W和d的值，参考：《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/4.png" class="lazyload" title="4"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/3.png" class="lazyload" title="3"></a></p><p>模型保存与恢复持久化训练</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_file_path</span><span class="params">(dir_path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    创建文件夹函数</span></span><br><span class="line"><span class="string">    :param dir_path:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_path):</span><br><span class="line">        os.makedirs(dir_path)</span><br><span class="line">        print(<span class="string">'创建文件夹:{}'</span>.format(dir_path))</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 6、构建持久化对象</span><br><span class="line">CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">create_file_path(CKECKPOINT_DIR)</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1)</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#持久化模型</span><br><span class="line">checkpoints_file = 'model_{}'</span><br></pre></td></tr></tbody></table></figure></div><p>全部代码：Mnist数据集cnn分类</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(</span><br><span class="line">    '../datas/mnist', one_hot=True, reshape=False)</span><br><span class="line">print(mnist.train.num_examples)</span><br><span class="line"></span><br><span class="line"># 超参数设置</span><br><span class="line">lr = 1e-2</span><br><span class="line">epochs = 10</span><br><span class="line">batch_size = 256</span><br><span class="line">test_valid_size = 512  # 验证或者测试样本的数量</span><br><span class="line">num_classes = 10  # 类别数量</span><br><span class="line">keep_prob = 0.7   # dropout保留概率， 丢弃概率=1-0.7 = 0.3</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">网络结构图</span><br><span class="line">input [N, 28, 28, 1]</span><br><span class="line">Conv1 weights=[5, 5, 1, 32] S=1    ---> [N, 28, 28, 32]</span><br><span class="line">MaxPool1  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/2, 28/2, 32]</span><br><span class="line">Conv2 weights=[5, 5, 32, 64] S=1    ---> [N, 28/2, 28/2, 64]</span><br><span class="line">MaxPool2  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/4, 28/4, 64]</span><br><span class="line"></span><br><span class="line">Flatten [N, 28/4, 28/4, 64] 4-D  ---> [N, 7*7*64]  2-D</span><br><span class="line">FC1 Weights=[7*7*64, 1024] ---> [N, 1024]</span><br><span class="line">FC2 Weights=[1024, 10] ---> [N, 10]</span><br><span class="line">"""</span><br><span class="line"># 构建模型图 1、创建变量</span><br><span class="line">graph = tf.Graph()</span><br><span class="line">with graph.as_default():</span><br><span class="line">    weights = {</span><br><span class="line">        'conv1': tf.get_variable('w1', shape=[5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'conv2': tf.get_variable('w2', shape=[5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'fc1': tf.get_variable('w3', shape=[7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'fc2': tf.get_variable('w4', shape=[1024, num_classes], initializer=tf.truncated_normal_initializer(stddev=0.1))</span><br><span class="line">    }</span><br><span class="line">    biases = {</span><br><span class="line">        'conv1': tf.get_variable('b1', shape=[32], initializer=tf.zeros_initializer()),</span><br><span class="line">        'conv2': tf.get_variable('b2', shape=[64], initializer=tf.zeros_initializer()),</span><br><span class="line">        'fc1': tf.get_variable('b3', shape=[1024], initializer=tf.zeros_initializer()),</span><br><span class="line">        'fc2': tf.get_variable('b4', shape=[num_classes], initializer=tf.zeros_initializer())</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def conv2d(input_tensor, filter_w, filter_b, strides=[1, 1, 1, 1]):</span><br><span class="line">    """</span><br><span class="line">    实现 卷积 + 偏置项相加 + 激活函数</span><br><span class="line">    :param input_tensor: 输入</span><br><span class="line">    :param filter_w:   卷积核变量</span><br><span class="line">    :param filter_b:    偏置项</span><br><span class="line">    :param strides:     步幅</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、卷积</span><br><span class="line">    conv = tf.nn.conv2d(</span><br><span class="line">        input=input_tensor, filter=filter_w, strides=strides, padding='SAME'</span><br><span class="line">    )</span><br><span class="line">    # 2、偏置项相加</span><br><span class="line">    conv = tf.nn.bias_add(conv, filter_b)</span><br><span class="line">    # 3、激活</span><br><span class="line">    conv = tf.nn.relu(conv)</span><br><span class="line">    return conv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def maxpool2d(input_tensor, k=2):</span><br><span class="line">    kernel_size = [1, k, k, 1]</span><br><span class="line">    strides = [1, k, k, 1]</span><br><span class="line">    maxpool_out = tf.nn.max_pool(</span><br><span class="line">        value=input_tensor, ksize=kernel_size, strides=strides, padding='SAME'</span><br><span class="line">    )</span><br><span class="line">    return maxpool_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def fully_connect(input_tensor, weights, biases, activation=tf.nn.relu):</span><br><span class="line">    """</span><br><span class="line">    实现全连接 + 偏置项相加 + 激活</span><br><span class="line">    :param input_tensor:</span><br><span class="line">    :param weights:</span><br><span class="line">    :param biases:</span><br><span class="line">    :param activation:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    fc = tf.matmul(input_tensor, weights) + biases</span><br><span class="line">    if activation:</span><br><span class="line">        fc = activation(fc)</span><br><span class="line">        return fc</span><br><span class="line">    else:</span><br><span class="line">        # 这里是为了返回最终输出的logits。</span><br><span class="line">        return fc</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">网络结构图</span><br><span class="line">input [N, 28, 28, 1]</span><br><span class="line">Conv1 weights=[5, 5, 1, 32] S=1    ---> [N, 28, 28, 32]</span><br><span class="line">MaxPool1  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/2, 28/2, 32]</span><br><span class="line">Conv2 weights=[5, 5, 32, 64] S=1    ---> [N, 28/2, 28/2, 64]</span><br><span class="line">MaxPool2  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/4, 28/4, 64]</span><br><span class="line">Flatten [N, 28/4, 28/4, 64] 4-D  ---> [N, 7*7*64]  2-D</span><br><span class="line">FC1 Weights=[7*7*64, 1024] ---> [N, 1024]</span><br><span class="line">FC2 Weights=[1024, 10] ---> [N, 10]</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def model(input_x, weights, biases, keep_prob):</span><br><span class="line">    """</span><br><span class="line">    搭建CNN网络，返回logits</span><br><span class="line">    :param input_x:   模型输入，是占位符</span><br><span class="line">    :param weights:</span><br><span class="line">    :param biases:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.variable_scope('Network'):</span><br><span class="line">        # 卷积1  [N, 28, 28, 1]  --> [N, 28, 28, 32]</span><br><span class="line">        conv1 = conv2d(</span><br><span class="line">            input_tensor=input_x, filter_w=weights['conv1'], filter_b=biases['conv1'])</span><br><span class="line">        # 池化1 [N, 28, 28, 32]  -->[N, 28/2, 28/2, 32]</span><br><span class="line">        pool1 = maxpool2d(conv1)</span><br><span class="line">        # 卷积2  [N, 28/2, 28/2, 32]  --> [N, 28/2, 28/2, 64]</span><br><span class="line">        conv2 = conv2d(</span><br><span class="line">            input_tensor=pool1, filter_w=weights['conv2'], filter_b=biases['conv2'])</span><br><span class="line">        # 池化2 [N, 28/2, 28/2, 64]  -->[N, 28/4, 28/4, 64]</span><br><span class="line">        pool2 = maxpool2d(conv2)</span><br><span class="line"></span><br><span class="line">        # 拉平层 [N, 28/4, 28/4, 64] ---> [N, 7*7*64]</span><br><span class="line">        shape = pool2.get_shape()  # [N, 7, 7, 64]</span><br><span class="line">        flatten_shape = shape[1] * shape[2] * shape[3]</span><br><span class="line">        flatted = tf.reshape(pool2, shape=[-1, flatten_shape])</span><br><span class="line"></span><br><span class="line">        # 全连接层1  [N, 7*7*64] ---> [N, 1024]</span><br><span class="line">        fc1 = fully_connect(</span><br><span class="line">            input_tensor=flatted, weights=weights['fc1'], biases=biases['fc1'])</span><br><span class="line">        fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line">        # 全连接层2（输出层）   [N, 1024] --->  [N, 10]</span><br><span class="line">        logits = fully_connect(</span><br><span class="line">            input_tensor=fc1, weights=weights['fc2'], biases=biases['fc2'], activation=None</span><br><span class="line">        )</span><br><span class="line">        return logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_file_path(dir_path):</span><br><span class="line">    """</span><br><span class="line">    创建文件夹函数</span><br><span class="line">    :param dir_path:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    if not os.path.exists(dir_path):</span><br><span class="line">        os.makedirs(dir_path)</span><br><span class="line">        print('创建文件夹:{}'.format(dir_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train():</span><br><span class="line">    """</span><br><span class="line">    构建模型</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with graph.as_default():</span><br><span class="line">        # 1、创建占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='input_x')</span><br><span class="line">        input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')</span><br><span class="line">        learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')</span><br><span class="line">        keep_probab = tf.placeholder(tf.float32, shape=None, name='keep_probab')</span><br><span class="line"></span><br><span class="line">        # 2、构建模型</span><br><span class="line">        logits = model(input_x, weights, biases, keep_prob=keep_probab)</span><br><span class="line"></span><br><span class="line">        # 3、构建模型损失</span><br><span class="line">        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">            logits=logits, labels=input_y</span><br><span class="line">        ))</span><br><span class="line">        # 可视化代码</span><br><span class="line">        tf.summary.scalar('train_loss', loss, collections=['train'])</span><br><span class="line">        tf.summary.scalar('valid_loss', loss, collections=['valid'])</span><br><span class="line"></span><br><span class="line">        # 4、构建模型优化器</span><br><span class="line">        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">        train_opt = optimizer.minimize(loss=loss)</span><br><span class="line"></span><br><span class="line">        # 5、求模型准确率</span><br><span class="line">        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(input_y, 1))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line">        # 可视化代码</span><br><span class="line">        tf.summary.scalar('train_accuracy', accuracy, collections=['train'])</span><br><span class="line">        tf.summary.scalar('valid_accuracy', accuracy, collections=['valid'])</span><br><span class="line"></span><br><span class="line">        # 6、构建持久化对象</span><br><span class="line">        CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">        create_file_path(CKECKPOINT_DIR)</span><br><span class="line">        saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session(graph=graph) as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        # todo 模型可视化。</span><br><span class="line">        train_sum = tf.summary.merge_all('train')</span><br><span class="line">        valid_sum = tf.summary.merge_all('valid')</span><br><span class="line"></span><br><span class="line">        LOG_DIR = './model/graph'</span><br><span class="line">        train_writer = tf.summary.FileWriter(LOG_DIR+ '/train_graph', graph=sess.graph)</span><br><span class="line">        valid_writer = tf.summary.FileWriter(LOG_DIR+ '/valid_graph')</span><br><span class="line"></span><br><span class="line">        step = 1</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            # 构建批量数据的循环操作</span><br><span class="line">            for batch in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                # 获取当前批量的数据(该数据已经归一化，且随机打乱的)</span><br><span class="line">                batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                feed = {input_x: batch_x, input_y:batch_y,</span><br><span class="line">                        learning_rate:lr, keep_probab:keep_prob}</span><br><span class="line">                sess.run(train_opt, feed_dict=feed)  # 执行模型训练</span><br><span class="line">                if step % 2 == 0:</span><br><span class="line">                    feed = {input_x: batch_x, input_y: batch_y,</span><br><span class="line">                            learning_rate: lr, keep_probab: 1.0}</span><br><span class="line">                    train_loss, train_acc, train_sum_ = sess.run(</span><br><span class="line">                        [loss, accuracy, train_sum], feed)</span><br><span class="line">                    train_writer.add_summary(train_sum_, global_step=step)</span><br><span class="line"></span><br><span class="line">                    val_feed = {input_x: mnist.validation.images[:test_valid_size],</span><br><span class="line">                                input_y: mnist.validation.labels[:test_valid_size],</span><br><span class="line">                                keep_probab: 1.0}</span><br><span class="line">                    val_loss, val_acc, valid_sum_ = sess.run(</span><br><span class="line">                        [loss, accuracy, valid_sum], val_feed)</span><br><span class="line">                    valid_writer.add_summary(valid_sum_, global_step=step)</span><br><span class="line">                    print('Epochs:{} - Step:{} - Train Loss:{:.5f} - Valid Loss:{:.5f} - Valid Acc:{:.5f}'.format(</span><br><span class="line">                        e, step, train_loss, val_loss, val_acc</span><br><span class="line">                    ))</span><br><span class="line">                step += 1</span><br><span class="line">                # todo 模型持久化</span><br><span class="line">                if step % 50 == 0:</span><br><span class="line">                    files = 'model.ckpt'</span><br><span class="line">                    save_files = os.path.join(CKECKPOINT_DIR, files)</span><br><span class="line">                    saver.save(sess, save_path=save_files, global_step=step)</span><br><span class="line">                    print('模型成功持久化到文件夹:{}'.format(save_files))</span><br><span class="line">        # todo 测试数据集效果</span><br><span class="line">        test_feed = {input_x: mnist.test.images[:test_valid_size],</span><br><span class="line">                     input_y: mnist.test.labels[:test_valid_size],</span><br><span class="line">                     keep_probab: 1.0}</span><br><span class="line">        test_acc = sess.run(accuracy, test_feed)</span><br><span class="line">        print('Test Acc:{:.5f}'.format(test_acc))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def restore_train():</span><br><span class="line">    """</span><br><span class="line">    恢复模型继续训练</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with graph.as_default():</span><br><span class="line">        # 1、创建占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='input_x')</span><br><span class="line">        input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')</span><br><span class="line">        learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')</span><br><span class="line">        keep_probab = tf.placeholder(tf.float32, shape=None, name='keep_probab')</span><br><span class="line"></span><br><span class="line">        # 2、构建模型</span><br><span class="line">        logits = model(input_x, weights, biases, keep_prob=keep_probab)</span><br><span class="line"></span><br><span class="line">        # 3、构建模型损失</span><br><span class="line">        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">            logits=logits, labels=input_y</span><br><span class="line">        ))</span><br><span class="line"></span><br><span class="line">        # 4、构建模型优化器</span><br><span class="line">        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">        train_opt = optimizer.minimize(loss=loss)</span><br><span class="line"></span><br><span class="line">        # 5、求模型准确率</span><br><span class="line">        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(input_y, 1))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line">        # 6、构建持久化对象</span><br><span class="line">        CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">        saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session(graph=graph) as sess:</span><br><span class="line">        # fixme 恢复模型继续训练.</span><br><span class="line">        # 获取持久化对象的信息。</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(CKECKPOINT_DIR)</span><br><span class="line">        if ckpt is not None:</span><br><span class="line">            saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">            print('成功恢复模型继续训练!')</span><br><span class="line">        else:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            print('没有持久化的模型，从头随机初始化开始训练!')</span><br><span class="line"></span><br><span class="line">        step = 1</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            # 构建批量数据的循环操作</span><br><span class="line">            for batch in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                # 获取当前批量的数据(该数据已经归一化，且随机打乱的)</span><br><span class="line">                batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                feed = {input_x: batch_x, input_y:batch_y,</span><br><span class="line">                        learning_rate:lr, keep_probab:keep_prob}</span><br><span class="line">                sess.run(train_opt, feed_dict=feed)  # 执行模型训练</span><br><span class="line">                if step % 2 == 0:</span><br><span class="line">                    feed = {input_x: batch_x, input_y: batch_y,</span><br><span class="line">                            learning_rate: lr, keep_probab: 1.0}</span><br><span class="line">                    train_loss, train_acc = sess.run(</span><br><span class="line">                        [loss, accuracy], feed)</span><br><span class="line"></span><br><span class="line">                    val_feed = {input_x: mnist.validation.images[:test_valid_size],</span><br><span class="line">                                input_y: mnist.validation.labels[:test_valid_size],</span><br><span class="line">                                keep_probab: 1.0}</span><br><span class="line">                    val_loss, val_acc = sess.run(</span><br><span class="line">                        [loss, accuracy], val_feed)</span><br><span class="line">                    print('Epochs:{} - Step:{} - Train Loss:{:.5f} - Valid Loss:{:.5f} - Valid Acc:{:.5f}'.format(</span><br><span class="line">                        e, step, train_loss, val_loss, val_acc</span><br><span class="line">                    ))</span><br><span class="line">                step += 1</span><br><span class="line">                # todo 模型持久化</span><br><span class="line">                if step % 50 == 0:</span><br><span class="line">                    files = 'model.ckpt'</span><br><span class="line">                    save_files = os.path.join(CKECKPOINT_DIR, files)</span><br><span class="line">                    saver.save(sess, save_path=save_files, global_step=step)</span><br><span class="line">                    print('模型成功持久化到文件夹:{}'.format(save_files))</span><br><span class="line">        # todo 测试数据集效果</span><br><span class="line">        test_feed = {input_x: mnist.test.images[:test_valid_size],</span><br><span class="line">                     input_y: mnist.test.labels[:test_valid_size],</span><br><span class="line">                     keep_probab: 1.0}</span><br><span class="line">        test_acc = sess.run(accuracy, test_feed)</span><br><span class="line">        print('Test Acc:{:.5f}'.format(test_acc))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # train()</span><br><span class="line">    restore_train()</span><br></pre></td></tr></tbody></table></figure></div><p>批归一化：</p><p>批归一化BN原理—平滑了损失函数超平面<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.6.png" data-fancybox="group" data-caption="6.6" class="fancybox"><img alt="6.6" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.6.png" class="lazyload" title="6.6"></a></p><p><a href="https://www.cnblogs.com/skyfsm/p/8453498.html" target="_blank" rel="noopener">https://www.cnblogs.com/skyfsm/p/8453498.html</a></p><p>训练集</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.7.png" data-fancybox="group" data-caption="6.7" class="fancybox"><img alt="6.7" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.7.png" class="lazyload" title="6.7"></a></p><p>对测试集<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.8.png" data-fancybox="group" data-caption="6.8" class="fancybox"><img alt="6.8" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.8.png" class="lazyload" title="6.8"></a></p><p>批归一化在激活函数前 dropout在激活函数后</p><h1 id="cnn-adam优化器"><a class="markdownIt-Anchor" href="#cnn-adam优化器"></a> cnn-Adam优化器</h1><h2 id="自适应学习率本质是调整梯度值"><a class="markdownIt-Anchor" href="#自适应学习率本质是调整梯度值"></a> 自适应学习率（本质是调整梯度值）</h2><h3 id="指数移动平均数"><a class="markdownIt-Anchor" href="#指数移动平均数"></a> 指数移动平均数</h3><p>Mean t = beta* Mean t-1 + (1-beta) * 当前均值<br>beta = 0.9  0.99</p><p><a href="https://zhuanlan.zhihu.com/p/32335746" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32335746</a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.9.png" data-fancybox="group" data-caption="6.9" class="fancybox"><img alt="6.9" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.9.png" class="lazyload" title="6.9"></a></p><p>只需保存v这个变量</p><h3 id="动量momentum"><a class="markdownIt-Anchor" href="#动量momentum"></a> 动量Momentum</h3><p>tf.train.MomentumOptimizer()</p><p>减小震荡，向最优值前进。</p><p>能够跳出局部最优(当W_2为0，还有V_2）<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.13.png" data-fancybox="group" data-caption="6.13" class="fancybox"><img alt="6.13" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.13.png" class="lazyload" title="6.13"></a></p><p>2、均方根RMSProp</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.14.png" data-fancybox="group" data-caption="6.14" class="fancybox"><img alt="6.14" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.14.png" class="lazyload" title="6.14"></a></p><p>tf.train.RMSPropOptimizer()</p><p>3、Adam</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.15.png" data-fancybox="group" data-caption="6.15" class="fancybox"><img alt="6.15" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.15.png" class="lazyload" title="6.15"></a></p><p>tf.train.AdamOptimizer()</p><h2 id="批归一化作用"><a class="markdownIt-Anchor" href="#批归一化作用"></a> 批归一化作用</h2><ol><li><p><strong>网络训练更快</strong> – 神经网络每一次迭代都会做大量的计算（正向和反向，以及调整超参数），导致很慢。如果能够更快的收敛，那么整体训练速度自然要快很多。</p></li><li><p><strong>允许更大的学习率</strong> – 梯度下降算法要求使用非常小的学习率，网络才能收敛。网络越深，反向传播的梯度也会越小，就需要更多的迭代来学习。批归一化允许我们使用相对来说大一些的学习率，可以加速网络训练。</p></li><li><p><strong>权重初始化更容易</strong> – 权重初始化是很难的，特别是当网络越来越来深。批归一化允许我们不用过分关心权重初始化的值。</p></li><li><p><strong>使激活函数有更多选择</strong> – 部分激活函数有使用条件限定。Sigmoid不能用于深度网络中，因其丢失梯度过高。 ReLUs经常会梯度消失而导致网络完全停止学习，所以非常小心值域范围（读入激活函数的）。但批归一化对任何进入激活函数的值都做了规范，所以之前在深度网络中表现不好的非线性函数也可以作为备选项了。</p></li><li><p><strong>创建深度网络更简单</strong> – 基于1-4原因，使用批归一化创建并训练深度网络更简单。当然网络越深，一般而言，效果越好。</p></li><li><p><strong>提供了一些正则化作用</strong> – 批归一化是在网络中增加了一些噪音。实际起了一定的dropout功能，所以在使用了批归一化网络中，可以考虑减少dropout的使用。</p></li><li><p><strong>总之，让网络效果更佳</strong> – 有一些测试表明批归一化能够改进网络效果。BN是优化网络速度的手段，而不是提升网络精度的方法。显然，若你可以训练的更快，意味着你可以尝试更多网络设计方案，迭代更多次，也可以构建更深的网络（效果更佳）。最终你通过批归一化达到提升网络效果。</p></li></ol><p>批归一化在批量batch_size很小的情况下会失效</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.11.jpg" data-fancybox="group" data-caption="6.11" class="fancybox"><img alt="6.11" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.11.jpg" class="lazyload" title="6.11"></a><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.10.png" data-fancybox="group" data-caption="6.10" class="fancybox"><img alt="6.10" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.10.png" class="lazyload" title="6.10"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.12.png" data-fancybox="group" data-caption="6.12" class="fancybox"><img alt="6.12" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.12.png" class="lazyload" title="6.12"></a></p><p>做位移和缩放时按通道数（4）去做</p><h1 id="数据增强"><a class="markdownIt-Anchor" href="#数据增强"></a> 数据增强</h1><p>增加训练数据，则能够提升算法的准确率，因为这样可以避免过拟合，而避免了过拟合你就可以增大你的网络结构了。当训练数据有限的时候，可以通过一些变换来从已有的训练数据集中生成一些新的数据，来扩大训练数据。数据增强的方法有：</p><p>1）水平翻转（旋转） CNN不具有旋转不变性</p><p>2）随机裁剪(crop采样)<br>如原始图像大小为256<em>256，随机裁剪出一些图像224</em>224的图像。如下图，红色方框内为随机裁剪出的224*224的图片。 AlexNet 训练时，对左上、右上、左下、右下、中间做了5次裁剪，然后翻转，得到一些剪切图片。防止大网络过拟合(under ubstantial overfitting)。</p><p>3）样本不均衡（解决方案：增加小众类别的图像数据）<br>样本不均衡即有些类别图像特别多，有些特别少。类别不平衡数据的处理：Label shuffle。</p><p>4）其他<br>平移变换；<br>旋转/仿射变换（线性变换+平移）；<br>高斯噪声、模糊处理<br>对颜色的数据增强：图像亮度、饱和度、对比度变化。</p><p>5）训练和测试要协调<br>在训练的时候，我们通常都需要做数据增强，在测试的时候，我们通常很少去做数据增强。这其中似乎有些不协调，因为你训练和测试之间有些不一致。实验发现，训练的最后几个迭代，移除数据增强，和传统一样测试，可以提升一点性能。<br>如果训练的时候一直使用尺度和长宽比增强数据增强，在测试的时候也同样做这个变化，随机取32个裁剪图片来测试，也可以在最后的模型上提升一点性能。<br>就是多尺度的训练，多尺度的测试。</p><h1 id="经典网络71"><a class="markdownIt-Anchor" href="#经典网络71"></a> 经典网络<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.1.png" data-fancybox="group" data-caption="7.1" class="fancybox"><img alt="7.1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.1.png" class="lazyload" title="7.1"></a></h1><p>GoogleNet</p><p>1*1卷积核融合的是通道之间的信息</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.3.jpg" data-fancybox="group" data-caption="7.3" class="fancybox"><img alt="7.3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.3.jpg" class="lazyload" title="7.3"></a><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.4.png" data-fancybox="group" data-caption="7.4" class="fancybox"><img alt="7.4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.4.png" class="lazyload" title="7.4"></a>融合了不同尺度的特征信息<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.2.png" data-fancybox="group" data-caption="7.2" class="fancybox"><img alt="7.2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.2.png" class="lazyload" title="7.2"></a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tensflow</title>
      <link href="/2020/01/17/tensflow/"/>
      <url>/2020/01/17/tensflow/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>TensorFlow变量作用域 TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。 其命名来源于本身的原理，Tensor（张量）意味着N维数组，Flow（流）意味着基于数据流图的计算.Tensorflow运行过程就是张量从图的一端流动到另一端的计算过程。张量从图中流过的直观图像是其取名为“TensorFlow”的原因。</p><p>TensorFlow的关键点是：“Data Flow Graphs”，表示TensorFlow是一种基于图的计算框架，其中节点（Nodes）在图中表示数学操作，线（Edges）则表示在节点间相互联系的多维数据数组，即张量（Tensor），这种基于流的架构让TensorFlow具有非常高的灵活性，该灵活性也让TensorFlow框架可以在多个平台上进行计算，例如：台式计算机、服务器、移动设备等。<br>备注：TensorFlow的开发过程中，重点在于构建执行流图。</p><p>What is Data Flow Graphs?</p><p>数据流图使用节点（Node）和线（Edges）的有向图描述数学计算；节点一般用来表示施加的数学操作，也可以表示数据输入(feed in)的起点和输出(push out)的终点，或者是读取/写入持久变量(persistent variable)的终点。线表示的是节点之间的输入/输出关系，这些线可以输运“size可动态调整”的多维数组，即张量(Tensor)。</p><p>一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/1_ys.png" class="lazyload" title="1_ys"></a></p><p>TensorFlow基本概念:</p><p>图（Graph）：图描述了计算的过程，TensorFlow使用图来表示计算任务。</p><p>张量（Tensor）：TensorFlow使用tensor表示数据。每个Tensor是一个类型化的多维数组。</p><p>操作（op）：图中的节点被称为op（opearation的缩写），一个op获得/输入0个或多个Tensor，执行计算，产生0个或多个Tensor。</p><p>变量（Variable）：运行过程中可以被改变，用于维护状态。</p><p>会话（Session）：图必须在称之为“会话”的上下文中执行。会话将图的op分发到诸如CPU或GPU之类的设备上执行。</p><p>TensorFlow的边即有两种连接关系：<br>数据依赖<br>控制依赖<br>实线边表示数据依赖，代表数据，即张量。任意维度的数据统称为张量。在机器学习算法中，张量在数据流图中从前往后流动一遍就完成一次前向传播，而残差从后向前流动一遍就完成一次反向传播。<br>虚线边表示控制依赖，可以用于控制操作的运行，这被用来确保happens-before关系，这类边上没有数据流过，但源节点必须在目的节点开始执行前完成。</p><p>数据属性：</p><table><thead><tr><th><strong>数据类型</strong></th><th><strong>Python****类型</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>DT_FLOAT</td><td>tf.float32</td><td>32位浮点型</td></tr><tr><td>DT_DOUBLE</td><td>tf.float64</td><td>64位浮点型</td></tr><tr><td>DT_INT64</td><td>tf.int64</td><td>64位有符号整型</td></tr><tr><td>DT_INT32</td><td>tf.int32</td><td>32位有符号整型</td></tr><tr><td>DT_INT16</td><td>tf.int16</td><td>16位有符号整型</td></tr><tr><td>DT_INT8</td><td>tf.int8</td><td>8位有符号整型</td></tr><tr><td>DT_UINT8</td><td>tf.uint8</td><td>8位无符号整型</td></tr><tr><td>DT_STRING</td><td>tf.string</td><td>可变长度的字节数组，每一个张量元素都是一个字节数组</td></tr><tr><td>DT_BOOL</td><td>tf.bool</td><td>布尔型</td></tr><tr><td>DT_COMPLEX64</td><td>tf.complex64</td><td>由两个32位浮点数组成的复数：实数和虚数</td></tr></tbody></table><p>节点：</p><p>节点又称为算子，它代表一个操作，一般用来表示施加的数字运算，也可以表示数据输入的起点以及输出的重点，或者是读取/写出持久化变量的终点。</p><table><thead><tr><th><strong>类别</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td>数学运算操作</td><td>Add、Subtract、Multiply、Div、Exp、Log、Greater、Less、Equal……</td></tr><tr><td>数组运算操作</td><td>Concat, Slice, Split, Constant, Rank, Shape, Shuffle……</td></tr><tr><td>矩阵运算操作</td><td>MatMul, MatrixInverse, MatrixDeterminant……</td></tr><tr><td>有状态的操作</td><td>Variable、Assign、AssignAdd……</td></tr><tr><td>神经网络构建操作</td><td>SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool……</td></tr><tr><td>检查点操作</td><td>Save, Restore……</td></tr><tr><td>队列和同步操作</td><td>Enqueue, Dequeue, MutexAcquire, MutexRelease……</td></tr><tr><td>控制张量流动的操作</td><td>Merge, Switch, Enter, Leave, NextIteration……</td></tr></tbody></table><p>使用TensorFlow必须理解下列概念：<br>使用图(graph)来表示计算任务；<br>在会话(session)的上下文中执行图；<br>使用tensor表示数据；<br>通过变量(Variable)来维护状态 ；<br>使用feed和fetch可以为任意的操作(Operation/op)赋值或者从其中获取数据。</p><p>TensorFlow程序结构:</p><p>TensorFlow的程序一般分为两个阶段：构建阶段和执行阶段；<br>构建阶段：op的执行步骤被描述称为一个图，然后使用TensorFlow提供的API构建这个图。<br>执行阶段：将构建好的执行图(Operation Graph)在给定的会话中执行，并得到执行结果。</p><p>TensorFlow图：</p><p>不使用默认图(Graph)，使用多个图来进行编程；但是注意：操作必须属于同一个图，不同图中的节点不能相连。</p><p>TensorFlow会话:</p><p>当执行图构建完成后，才能给启动图，进入到执行阶段；启动图的第一步就是创建一个Session对象，如果无任何参数的情况下，会话构造器将启动默认图。</p><p>tf.Session在构建会话的时候，如果不给定任何参数，那么构建出来Session对应的内部的Graph其实就是默认Graph，不过我们可以通过参数给定具体对应的是那一个Graph以及当前Session对应的配合参数。Session的构造主  要有三个参数，作用如下：<br>target：给定连接的url，只有当分布式运行的时候需要给定(后面分布式运行讲)；<br>graph：给定当前Session对应的图，默认为TensorFlow中的默认图；<br>config：给定当前Session的相关参数，参数详见：<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto%E4%B8%AD%E7%9A%84%5BConfigProto%5D" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto中的[ConfigProto]</a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">tf.Session(target='', graph=None, config=None)</span><br><span class="line">    target: 给定连接的url，只有当分布式运行的时候需要给定。</span><br><span class="line">    graph:  调用哪张图，如果不给定，则调用默认图。</span><br><span class="line">    config: 会话的配置文件。</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>通过Session的config参数可以对TensorFlow的应用的执行进行一些优化调整，主要涉及到的参数如下：</p><table><thead><tr><th><strong>属性</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>gpu_options</td><td>GPU相关参数，主要参数：per_process_gpu_memory_fraction和allow_growth</td></tr><tr><td>allow_soft_placement</td><td>是否允许动态使用CPU和GPU，默认为False；当我们的安装方式为GPU的时候，建议该参数设置为True，因为TensorFlow中的部分op只能在CPU上运行。</td></tr><tr><td>log_device_placement</td><td>是否打印日志，默认为False，不打印日志</td></tr><tr><td>graph_options</td><td>Graph优化相关参数，一般不需要给定，默认即可，主要参数：optimizer_options(do_common_subexpression_elimination、do_constant_folding和opt_level)</td></tr></tbody></table><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">gpu_options 参数</span><br><span class="line">    per_process_gpu_memory_fraction 浮点数[0, 1.0]， 表示限制该gpu设备显存使用的百分比</span><br><span class="line">    allow_growth  bool值，不预先分配使用整个gpu显存计算，而是从小到大按需增长。</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>在TensorFlow中，除了可以使用Session表示这个会话外，还可以通过InteractiveSession来表示会话，InteractiveSession的意思是：交互式会话，使用交互式会话可以降低代码的复杂度，使用Tensor.eval()或者Operation.run()来代替Session.run()方法，这样可以避免一个变量来维持会话；备注：Session也可以使用Tensor.eval()和Operation.run()获取数据/执行操作(只要明确当前会话)。</p><p>Tensor张量：</p><p>TensorFlow使用Tensor数据结构来代表所有数据，计算图中，操作间传递的数据都是Tensor。Tensor可以看作是一个n维的数组或者列表，一个Tensor主要由一个静态数据类型和动态类型的维数(Rank、Shape)组成。Tensor可以在图中的节点之间流通。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/2.png" class="lazyload" title="2"></a></p><p>TensorFlow变量：</p><p>变量(Variables)是维护图执行过程中的状态信息。在训练模型过程中，可以通过变量来存储和更新参数。变量包含张量(Tensor)存放于内存的缓存区。建模的时候变量必须被明确的初始化，模型训练后变量必须被存储到磁盘。这些变量的值可以在之后的模型训练和分析中被加载。</p><p>在构建变量的时候，必须将一个张量或者可以转化为张量的Python对象作为初始值传入构造函数Variable中。</p><p>占位符：</p><p>可以使用 shape=[None, 3]， None使用类似于numpy。</p><p>input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name=‘input_x’)</p><p>y_hat_, y_hat1_ = sess.run(<br>fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</p><p>以字典方式通过feed_dict传入</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">使用tensorflow 实现简单的 线性回归  y = np.dot(x, W) + b</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def f1():</span><br><span class="line">    """</span><br><span class="line">    先使用常量进行构建，展示大致的业务逻辑</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入</span><br><span class="line">        input_x = tf.constant(</span><br><span class="line">            value=[[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]], dtype=tf.float32, shape=[4, 3], name='input_x'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.constant(</span><br><span class="line">            value=[[-5],</span><br><span class="line">                   [3],</span><br><span class="line">                   [2]], dtype=tf.float32, shape=[3, 1], name='weights'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_ = sess.run(y_hat)</span><br><span class="line">            print(y_hat_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f2():</span><br><span class="line">    """</span><br><span class="line">    变量使用 tf.Variable()来构建</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入</span><br><span class="line">        input_x = tf.constant(</span><br><span class="line">            value=[[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]], dtype=tf.float32, shape=[4, 3], name='input_x'</span><br><span class="line">        )</span><br><span class="line">        """</span><br><span class="line">        tf.Variable(self,</span><br><span class="line">               initial_value=None,    # 给定初始化的值，可以是python的基本数据类型，也可以是tf的tensor对象</span><br><span class="line">               trainable=True,        # bool 该变量是否参与模型训练。也就是该变量是否会执行梯度下降</span><br><span class="line">               collections=None,</span><br><span class="line">               validate_shape=True,</span><br><span class="line">               caching_device=None,</span><br><span class="line">               name=None,            # tensorflow底层的名字。</span><br><span class="line">               variable_def=None,</span><br><span class="line">               dtype=None,           # 数据类型</span><br><span class="line">               expected_shape=None,</span><br><span class="line">               import_scope=None,</span><br><span class="line">               constraint=None):</span><br><span class="line">        """</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_ = sess.run(y_hat)</span><br><span class="line">            print(y_hat_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f3():</span><br><span class="line">    """</span><br><span class="line">    占位符的使用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入(占位符)</span><br><span class="line">        # todo 可以使用 shape=[None, 3]， None使用类似于numpy。</span><br><span class="line">        input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='input_x')</span><br><span class="line">        input_c = tf.placeholder_with_default(</span><br><span class="line">            input=1.0, shape=[], name='input_c'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        y_hat1 = y_hat + input_c</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # 加载训练数据</span><br><span class="line">            data1 = [[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]]</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data1})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">            data2 = [[1, 2, 3],</span><br><span class="line">                     [2, 3, 4],</span><br><span class="line">                     [2, 3, 9]]</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f4():</span><br><span class="line">    """</span><br><span class="line">    tensorboard的调用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入(占位符)</span><br><span class="line">        # todo 可以使用 shape=[None, 3]， None使用类似于numpy。</span><br><span class="line">        input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='input_x')</span><br><span class="line">        input_c = tf.placeholder_with_default(</span><br><span class="line">            input=1.0, shape=[], name='input_c'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        y_hat1 = y_hat + input_c</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # fixme 加入一段可视化代码</span><br><span class="line">            """</span><br><span class="line">            tf.summary.FileWriter(self,</span><br><span class="line">               logdir,                # 记录日志或者事件的路径。</span><br><span class="line">               graph=None,            # 可视化的图对象</span><br><span class="line">               max_queue=10,</span><br><span class="line">               flush_secs=120,</span><br><span class="line">               graph_def=None,</span><br><span class="line">               filename_suffix=None,</span><br><span class="line">               session=None):</span><br><span class="line">            """</span><br><span class="line">            writer = tf.summary.FileWriter(</span><br><span class="line">                logdir='./model/ai13', graph=sess.graph</span><br><span class="line">            )</span><br><span class="line">            # 加载训练数据</span><br><span class="line">            data1 = [[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]]</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data1})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">            data2 = [[1, 2, 3],</span><br><span class="line">                     [2, 3, 4],</span><br><span class="line">                     [2, 3, 9]]</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    f4()</span><br></pre></td></tr></tbody></table></figure></div><p>tensorboard 可视化：</p><p>打开日志文件 tensorboard —logdir 绝对路径（到文件夹 ）</p><p>“”"<br>tf.summary.FileWriter(self,<br>logdir,                # 记录日志或者事件的路径。<br>graph=None,            # 可视化的图对象<br>max_queue=10,<br>flush_secs=120,<br>graph_def=None,<br>filename_suffix=None,<br>session=None):<br>“”"<br>writer = tf.summary.FileWriter(<br>logdir=’./model/ai13’, graph=sess.graph<br>)</p><p>TensorFlow控制依赖：</p><p>with g.control_dependencies[a,b,c]:</p><h1 id="d-and-e-will-only-run-after-a-b-c-have-executed"><a class="markdownIt-Anchor" href="#d-and-e-will-only-run-after-a-b-c-have-executed"></a> “d” and “e” will only run after ‘’’a‘’ ‘’b’’ ‘’c’‘ have executed</h1><p>我们可以通过Variable和assign完成变量的定义和更新，但是如果在更新变量之前需要更新其它变量，那么会导致一个比较严重的问题：也就是需要多次调用sess.run方法来进行变量的更新。通过这种方式，代码复杂程度上升，同时也没有执行效率。<br>解决该问题的方案就是：控制依赖。通过TensorFlow中提供的一组函数来处理不完全依赖的情况下的操作排序问题(即给定哪个操作先执行的问题)， 通过tf.control_dependencies API完成。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def change_var_shape():</span><br><span class="line">    """</span><br><span class="line">    实现动态的更新变量的维度数目。需要设置tf.assign中的validate_shape=False</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个变量</span><br><span class="line">        x = tf.Variable(</span><br><span class="line">            initial_value=[[0, 2, 3, 4, 0]],</span><br><span class="line">            dtype=tf.float32,</span><br><span class="line">            validate_shape=True   # 设置为False时候，表示不进行初始值shape的验证</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 2、做一个矩阵合并的操作---沿着行进行合并。</span><br><span class="line">        temp = [0.0, 2.0, 3.0, 4.0, 0.0]</span><br><span class="line">        concat = tf.concat(values=[x, tf.expand_dims(temp, axis=0)], axis=0) # 必须沿着已经存在的轴进行拼接。tf.expand_dims扩展轴</span><br><span class="line">        # tf.squeeze()  缩减tensor中维度为1的轴（需要指定）。</span><br><span class="line">        # 3、做一个赋值更新的操作</span><br><span class="line">        assign_opt = tf.assign(ref=x, value=concat, validate_shape=False)</span><br><span class="line"></span><br><span class="line">        # 二、执行会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            for _ in range(5):</span><br><span class="line">                _, x_ = sess.run([assign_opt, x])</span><br><span class="line">                print(x_)</span><br></pre></td></tr></tbody></table></figure></div><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/3.png" class="lazyload" title="3"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def factorial():</span><br><span class="line">    """</span><br><span class="line">    实现一个求解n阶乘的值，再乘以3的这样一个需求。</span><br><span class="line">    tf.control_dependencies()</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示一个数字</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行乘法的操作</span><br><span class="line">        temp = sum_x * input_x</span><br><span class="line">        # 将temp 赋值给 sum_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">            y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line">        该段代码的含义是：确保执行顺序为  assign_opt --> assign_opt1 --> y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt1]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow设备:</p><p>设备是指一块可以用来运算并且拥有自己的地址空间的硬件，如CPU和GPU。Tensorflow为了在执行操作的时候，充分利用计算资源，可以明确指定操作在哪个设备上执行。</p><p>一般情况下，不需要显示指定使用CPU还是GPU，TensorFlow会自动检测。如果检测到GPU，TensorFlow会尽可能地利用第一个GPU来执行操作。注意：如果机器上有超过一个可用的GPU，那么除了第一个外其它GPU默认是不参与计算的。所以，在实际TensorFlow编程中，经常需要明确给定使用的CPU和GPU。</p><p>“/cpu:0”：表示使用机器CPU运算<br>“/gpu:0”：表示使用第一个GPU运算，如果有的话<br>“/gpu:1”：表示使用第二个GPU运算，以此类推</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def factorial():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        """</span><br><span class="line">        注意事项：</span><br><span class="line">        如果不使用tf.device指定具体运行的设备的话，tensorflow会根据你安装的版本选择默认的设备运行。</span><br><span class="line">            1、如果安装的是cpu版本的tf，那么运行在cpu上面。</span><br><span class="line">            2、如果安装的是gpu版本的tf，那么运算操作一定运行在第一个gpu，但是会在所有gpu上分配内存。</span><br><span class="line">            如何通过tf.device指定了具体的运行设备，那么该运算一定会放到你指定的设备上运行，如果没有，就会报错。</span><br><span class="line">            建议将：allow_soft_placement=True</span><br><span class="line">        """</span><br><span class="line">        with tf.device('/CPU:0'):</span><br><span class="line">            # 1、定义一个占位符，表示一个数字</span><br><span class="line">            input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        with tf.device('/CPU:1'):</span><br><span class="line">            # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">            sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        with tf.device('/GPU:0'):</span><br><span class="line">            # 3、执行乘法的操作</span><br><span class="line">            temp = sum_x * input_x</span><br><span class="line">            # 将temp 赋值给 sum_x</span><br><span class="line">            assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">            # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        config = tf.ConfigProto(</span><br><span class="line">            log_device_placement=True, allow_soft_placement=True</span><br><span class="line">        )</span><br><span class="line">        with tf.Session(config=config) as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">假设现在有两个GPU，我们代码运行的时候希望仅在第二个GPU上运行，并且仅在第二个GPU上分配内存 </span><br><span class="line">               --> 通过给定环境变量解决</span><br><span class="line">"""</span><br><span class="line"># os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "0,1"  # 允许当前代码使用第一块、第二块GPU</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "1"  # 允许当前代码使用第二块GPU</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "-1"  # 允许当前代码不允许使用GPU</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    factorial()</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow变量作用域:</p><p>通过tf.Variable我们可以创建变量，但是当模型复杂的时候，需要构建大量的变量集，这样会导致我们对于变量管理的复杂性，而且没法共享变量(存在多个相似的变量)。针对这个问题，可以通过TensorFlow提供的变量作用域机制来解决，在构建一个图的时候，就可以非常容易的使用共享命名过的变量。</p><p>Tensorflow中有两个作用域，一个是name_scope，另一个是variable_scope。<br>变量作用域机制在TensorFlow中主要通过两部分组成：<br>tf.get_variable：通过所给定的名字创建或者返回一个对应的变量<br>tf.variable_scope：为通过创建的变量或者操作Operation指定命名空间</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># sum_x = 0</span><br><span class="line"># for i in range(1, 5):</span><br><span class="line">#     sum_x += i</span><br><span class="line">#     print(sum_x)</span><br><span class="line">with g.c</span><br><span class="line">def sum1():</span><br><span class="line">    """</span><br><span class="line">    使用tf.assign实现一个累加器。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示被累加的值</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存累加的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=0.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行累加的操作</span><br><span class="line">        sum_x = sum_x + input_x</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                sum_x_ = sess.run(sum_x, feed_dict={input_x: i})</span><br><span class="line">                print(sum_x_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sum2():</span><br><span class="line">    """</span><br><span class="line">    使用tf.assign_add()  或者 tf.assign() 实现一个累加器。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示被累加的值</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存累加的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=0.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行累加的操作</span><br><span class="line">        # assign_add = tf.assign_add(ref=sum_x, value=input_x)</span><br><span class="line">        """</span><br><span class="line">        tf.assign(ref, value)</span><br><span class="line">            ref: 你要更新的值。</span><br><span class="line">            value: 累加的值。</span><br><span class="line">        """</span><br><span class="line">        temp = sum_x + input_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                sum_x_, _ = sess.run([sum_x, assign_opt], feed_dict={input_x: i})</span><br><span class="line">                print(sum_x_)</span><br><span class="line"></span><br><span class="line">def change_var_shape():</span><br><span class="line">    """</span><br><span class="line">    实现动态的更新变量的维度数目。需要设置tf.assign中的validate_shape=False</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个变量</span><br><span class="line">        x = tf.Variable(</span><br><span class="line">            initial_value=[[0, 2, 3, 4, 0]],</span><br><span class="line">            dtype=tf.float32,</span><br><span class="line">            validate_shape=True   # 设置为False时候，表示不进行初始值shape的验证</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 2、做一个矩阵合并的操作---沿着行进行合并。</span><br><span class="line">        temp = [0.0, 2.0, 3.0, 4.0, 0.0]</span><br><span class="line">        concat = tf.concat(values=[x, tf.expand_dims(temp, axis=0)], axis=0) # 必须沿着已经存在的轴进行拼接。</span><br><span class="line">        # tf.squeeze()  缩减tensor中维度为1的轴（需要指定）。</span><br><span class="line">        # 3、做一个赋值更新的操作</span><br><span class="line">        assign_opt = tf.assign(ref=x, value=concat, validate_shape=False)</span><br><span class="line"></span><br><span class="line">        # 二、执行会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            for _ in range(5):</span><br><span class="line">                _, x_ = sess.run([assign_opt, x])</span><br><span class="line">                print(x_)</span><br><span class="line">with control</span><br><span class="line"></span><br><span class="line">def factorial():</span><br><span class="line">    """</span><br><span class="line">    实现一个求解n阶乘的值，再乘以3的这样一个需求。</span><br><span class="line">    tf.control_dependencies()</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示一个数字</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行乘法的操作</span><br><span class="line">        temp = sum_x * input_x</span><br><span class="line">        # 将temp 赋值给 sum_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">            y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line">        该段代码的含义是：确保执行顺序为  assign_opt --> assign_opt1 --> y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt1]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # sum2()</span><br><span class="line">    # change_var_shape()</span><br><span class="line">    factorial()</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow变量作用域：</p><p>通过tf.Variable我们可以创建变量，但是当模型复杂的时候，需要构建大量的变量集，这样会导致我们对于变量管理的复杂性，而且没法共享变量(存在多个相似的变量)。针对这个问题，可以通过TensorFlow提供的变量作用域机制来解决，在构建一个图的时候，就可以非常容易的使用共享命名过的变量。<br>Tensorflow中有两个作用域，一个是name_scope，另一个是variable_scope。<br>变量作用域机制在TensorFlow中主要通过两部分组成：<br>tf.get_variable：通过所给定的名字创建或者返回一个对应的变量<br>tf.variable_scope：为通过创建的变量或者操作Operation指定命名空间</p><p>tf.get_variable方法在调用的时候，主要需要给定参数名称name，形状shape，数据类型dtype以及初始化方式initializer四个参数。该API底层执行的时候，根据variable score的属性reuse的值决定采用何种方式来获取变量。当reuse值为False的时候(不允许设置)，作用域就是创建新变量设置的，此时要求对应的变量不存在，否则报错；当reuse值为True的时候，作用域就是为重用变量所设置的，此时要求对应的变量必须存在，否则报错。当reuse的值为tf.AUTO_REUSE的时候，表示如果变量存在就重用变量，如果变量不存在，就创建新变量返回。(备注：reuse一般设置在variable score对象上)</p><p>tf.get_variable常用的initializer初始化器：</p><table><thead><tr><th><strong>初始化器</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>tf.constant_initializer(value)</td><td>初始化为给定的常数值value</td></tr><tr><td>tf.random_uniform_initializer(a, b)</td><td>初始化为从a到b的均匀分布的随机值</td></tr><tr><td>tf.random_normal_initializer(mean, stddev)</td><td>初始化为均值为mean、方差为stddev的服从高斯分布的随机值</td></tr><tr><td>tf.orthogonal_initializer(gini=1.0)</td><td>初始化一个正交矩阵，gini参数作用是最终返回的矩阵是随机矩阵乘以gini的结果</td></tr><tr><td>tf.identity_initializer(gini=1.0)</td><td>初始化一个单位矩阵，gini参数作用是最终返回的矩阵是随机矩阵乘以gini的结果</td></tr></tbody></table><p>tf.variable_score方法的作用就是定义一个作用域，定义在variable_score作用域中的变量和操作，会将variable score的名称作为前缀添加到变量/操作名称前，支持嵌套的作用域，添加前缀规则和文件目录路径的规则类似。<br>tf.variable_score参数如果给定的是一个已经存在的作用域对象的时候，那么构建变量的时候表示直接跳过当前作用域前缀，直接成为一个完全不同与现在的作用域(直接创建给定作用域下的变量)。但是构建操作的时候，还是和嵌套的方式一样，直接添加子作用域。<br>tf.variable_score参数中，可以给定当前作用域中默认的初始化器initializer，并且子作用域会直接继承父作用域的相关参数(是否重用、默认初始化器等)</p><p>TensorFlow中的name_score和variable_score是两个不同的东西，name_score的主要作用是为op_name前加前缀，variable_score是为get_variable创建的变量的名字加前缀。简单来讲：使用tf.Variable创建的变量受name_score和variable_score的的效果，会给变量添加前缀，但是使用tf.get_variable创建变量只受variable_score的效果。<br>name_score的主要作用就是：Tensorflow中常常会有数以千计的节点，在可视化的过程中很难一下子展示出来，因此用name_scope为变量划分范围，在可视化中，这表示在计算图中的一个层级。name_scope会影响op_name，不会影响用get_variable()创建的变量，而会影响通过Variable()创建的变量。<br>注意：variable_score内部会创建一个同名的name_score</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">def f1():</span><br><span class="line">    """</span><br><span class="line">    基于tf.Variable()创建一个变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 创建一个新的变量，哪怕名字相同。</span><br><span class="line">    w = tf.Variable(</span><br><span class="line">        initial_value=tf.random_normal(shape=[2], mean=0.0, stddev=1.0),</span><br><span class="line">        dtype=tf.float32, name='w'</span><br><span class="line">    )</span><br><span class="line">    return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f2(initializer=tf.random_normal_initializer(mean=0.0, stddev=1.0)):</span><br><span class="line">    """</span><br><span class="line">    基于tf.get_variable()获取或者创建变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    """</span><br><span class="line">    tf.get_variable(name,        # 变量名字，必须给定</span><br><span class="line">                 shape=None,     # 变量的形状</span><br><span class="line">                 dtype=None,     # 数据类型</span><br><span class="line">                 initializer=None,  # 该变量的初始值生成方式，也就是初始化器。</span><br><span class="line">                 regularizer=None,  # 正则化项</span><br><span class="line">                 trainable=True,    # 变量是否参与模型训练。</span><br><span class="line">                 collections=None,</span><br><span class="line">                 caching_device=None,</span><br><span class="line">                 partitioner=None,</span><br><span class="line">                 validate_shape=True,</span><br><span class="line">                 use_resource=None,</span><br><span class="line">                 custom_getter=None,</span><br><span class="line">                 constraint=None):</span><br><span class="line">        功能：基于给定的name从tensorflow内部获取相应的变量，如果name对应的变量已经存在，那么直接获取该变量，</span><br><span class="line">            如果不存在，直接创建一个新的变量。</span><br><span class="line">        注意：根据name获取变量重用，只支持tf.get_variable创建的变量。</span><br><span class="line">    """</span><br><span class="line">    w = tf.get_variable(</span><br><span class="line">        name='w', shape=[2], dtype=tf.float32, initializer=initializer</span><br><span class="line">    )</span><br><span class="line">    return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h1():</span><br><span class="line">    """</span><br><span class="line">    学习tf.get_variable()变量重用用法。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、用tf.Variable()创建2个变量</span><br><span class="line">    w11 = f1()</span><br><span class="line">    w12 = f1()</span><br><span class="line"></span><br><span class="line">    # 2、用tf.get_variable()创建变量</span><br><span class="line">    w21 = f2()</span><br><span class="line">    # fixme 需要设置一下，告诉tf名字相同可以重用。</span><br><span class="line">    tf.get_variable_scope().reuse_variables()</span><br><span class="line">    w22 = f2()</span><br><span class="line"></span><br><span class="line">    print(w11.name, w12.name, w21.name, w22.name)</span><br><span class="line">    print('w21 和 w22是同一个变量吗?:{}'.format(w21 == w22))</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22]))</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">1、学习 变量命名域 tf.varible_scope()用法</span><br><span class="line">2、学习 命名域 tf.name_scope() 用法</span><br><span class="line">3、学习 tf.trainable_variables() 的使用</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">tf.variable_scope(self,</span><br><span class="line">               name_or_scope,       # string类型 该变量命名域名字。 </span><br><span class="line">               default_name=None,   # 默认名字。如果参数name_or_scope 为空，那么使用该参数定义的名字。反之，则启用name_or_scope定义的名字</span><br><span class="line">               values=None,         # 传入的值</span><br><span class="line">               initializer=None,    # 变量命名域的初始化器</span><br><span class="line">               regularizer=None,    # 变量命名域的正则化项</span><br><span class="line">               caching_device=None,</span><br><span class="line">               partitioner=None,</span><br><span class="line">               custom_getter=None,</span><br><span class="line">               reuse=None,          # 决定该变量命名域的变量是否重用。</span><br><span class="line">               dtype=None,</span><br><span class="line">               use_resource=None,</span><br><span class="line">               constraint=None,</span><br><span class="line">               auxiliary_name_scope=True):</span><br><span class="line">               </span><br><span class="line">tf.name_scope(</span><br><span class="line">    name,      # 命名域的名字</span><br><span class="line">    default_name=None,  # 命名域默认的名字</span><br><span class="line">    values=None):     # 传入的tensor值。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def h2():</span><br><span class="line">    with tf.name_scope('ai13'):</span><br><span class="line">        with tf.variable_scope('t1'):</span><br><span class="line">            # 再次创建2个变量</span><br><span class="line">            w11 = f1()</span><br><span class="line">            w12 = f1()</span><br><span class="line"></span><br><span class="line">    # 父域定义的参数 同样也会影响子域。</span><br><span class="line">    with tf.variable_scope('t10', initializer=tf.constant_initializer(28.0)):</span><br><span class="line">        with tf.name_scope('ai14'):  # fixme tf.name_scope对tf.get_variable生成的变量无效</span><br><span class="line">            with tf.variable_scope('t2', reuse=tf.AUTO_REUSE):</span><br><span class="line">                w21 = f2(initializer=None)</span><br><span class="line">                w22 = f2()</span><br><span class="line">    # 做一个加法操作</span><br><span class="line">    with tf.name_scope('ai15'):</span><br><span class="line">        with tf.variable_scope('t5'):</span><br><span class="line">            rezult = tf.add(w11+w12+w21, w22, name='add_rezult')</span><br><span class="line"></span><br><span class="line">    print(w11.name, w12.name)</span><br><span class="line">    print('**'*50)</span><br><span class="line">    print(w21.name, w22.name)</span><br><span class="line">    print('**'*50)</span><br><span class="line">    print(rezult.name)</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22, rezult]))</span><br><span class="line"></span><br><span class="line">        # 基于tensor的名字直接从图中获取对应的tensor的值。</span><br><span class="line">        temp = tf.get_default_graph().get_tensor_by_name('t10/t2/w:0')</span><br><span class="line">        print(sess.run(temp))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h3():</span><br><span class="line">    """</span><br><span class="line">    学习tf.trainable_variables()使用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.name_scope('ai13'):</span><br><span class="line">        with tf.variable_scope('t1'):</span><br><span class="line">            # 再次创建2个变量</span><br><span class="line">            w11 = f1()</span><br><span class="line">            w12 = f1()</span><br><span class="line"></span><br><span class="line">    with tf.name_scope('ai14'):  # fixme tf.name_scope对tf.get_variable生成的变量无效</span><br><span class="line">        with tf.variable_scope('t2', reuse=tf.AUTO_REUSE):</span><br><span class="line">            w21 = f2(initializer=None)</span><br><span class="line">            w22 = f2()</span><br><span class="line">    # 做一个加法操作</span><br><span class="line">    with tf.name_scope('ai15'):</span><br><span class="line">        with tf.variable_scope('t5'):</span><br><span class="line">            rezult = tf.add(w11+w12+w21, w22, name='add_rezult')</span><br><span class="line"></span><br><span class="line">    # print(w11.name, w12.name)</span><br><span class="line">    # print('**'*50)</span><br><span class="line">    # print(w21.name, w22.name)</span><br><span class="line">    # print('**'*50)</span><br><span class="line">    # print(rezult.name)</span><br><span class="line">    # fixme 增加一段代码，展示如何获取指定的变量。</span><br><span class="line">    t_vars = tf.trainable_variables()</span><br><span class="line">    print(t_vars)</span><br><span class="line">    ai13_vars = [var for var in t_vars if var.name.startswith('ai13')]</span><br><span class="line">    print(ai13_vars)</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22, rezult]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h4():</span><br><span class="line">    """</span><br><span class="line">    展示tf.variable_scope() 中values参数的用法</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    default_graph = tf.Graph()</span><br><span class="line">    with default_graph.as_default():</span><br><span class="line">        w12 = f1()</span><br><span class="line"></span><br><span class="line">    graph1 = tf.Graph()</span><br><span class="line">    with graph1.as_default():</span><br><span class="line">        with tf.variable_scope('foo'):</span><br><span class="line">            w21 = f1()</span><br><span class="line"></span><br><span class="line">    graph2 = tf.Graph()</span><br><span class="line">    with graph2.as_default():</span><br><span class="line">        with tf.variable_scope('foo', values=[w12]):</span><br><span class="line">            w22 = f1()</span><br><span class="line"></span><br><span class="line">    print(w21.graph == default_graph)</span><br><span class="line">    print(w22.graph == default_graph)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    h4()</span><br></pre></td></tr></tbody></table></figure></div><p>模型持久化</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">模型持久化：就是将训练好的模型（权重 和 网络结构）保存到磁盘中。</span><br><span class="line">    1、可以用于部署。（服务器上训练---拷贝到 移动端进行预测）</span><br><span class="line">    2、进行断点继续训练。（大型模型训练 3--4天）</span><br><span class="line">    3、迁移学习。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line"># 变量的持久化</span><br><span class="line">def train():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 构建2个变量</span><br><span class="line">        v1 = tf.get_variable(</span><br><span class="line">            name='v1', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.constant_initializer(value=5.0)</span><br><span class="line">        )</span><br><span class="line">        v2 = tf.get_variable(</span><br><span class="line">            name='v2', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.random_normal_initializer(mean=0.0, stddev=5.0)</span><br><span class="line">        )</span><br><span class="line">        rezult = v1 + v2</span><br><span class="line">        print(rezult)</span><br><span class="line"></span><br><span class="line">        # fixme 1、构建一个持久化的对象</span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">        # 创建持久化文件路径</span><br><span class="line">        checkpoint_dir = './model/ai13'</span><br><span class="line">        # 创建该路径(不存在该路径的情况下，执行)</span><br><span class="line">        if not os.path.exists(checkpoint_dir):</span><br><span class="line">            # 创建路径</span><br><span class="line">            os.makedirs(checkpoint_dir)</span><br><span class="line">            print('成功创建路径:{}'.format(checkpoint_dir))</span><br><span class="line"></span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            print(sess.run([v1, v2, rezult]))</span><br><span class="line">            # [5.0, -4.2127123, 0.7872877]</span><br><span class="line"></span><br><span class="line">            # fixme 触发持久化的操作</span><br><span class="line">            files_name = 'model.ckpt'</span><br><span class="line">            save_files = os.path.join(checkpoint_dir, files_name)</span><br><span class="line">            saver.save(sess=sess, save_path=save_files)  # 执行持久化的</span><br><span class="line">            print('成功将变量持久化到文件：{}'.format(save_files))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def restore_variables():</span><br><span class="line">    """</span><br><span class="line">    从磁盘中恢复变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 构建2个变量</span><br><span class="line">        v1 = tf.get_variable(</span><br><span class="line">            name='v1', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.constant_initializer(value=5.0)</span><br><span class="line">        )</span><br><span class="line">        v2 = tf.get_variable(</span><br><span class="line">            name='v2', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.random_normal_initializer(mean=0.0, stddev=5.0)</span><br><span class="line">        )</span><br><span class="line">        rezult = v1 + v2</span><br><span class="line">        print(rezult)</span><br><span class="line"></span><br><span class="line">        # fixme 1、构建一个持久化的对象</span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">        # 创建持久化文件路径</span><br><span class="line">        checkpoint_dir = './model/ai13'</span><br><span class="line"></span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 不需要变量初始化操作了</span><br><span class="line"></span><br><span class="line">            # 做一个恢复模型的操作。</span><br><span class="line">            files_name = 'model.ckpt'</span><br><span class="line">            save_files = os.path.join(checkpoint_dir, files_name)</span><br><span class="line"></span><br><span class="line">            # fixme 直接恢复变量。</span><br><span class="line">            saver.restore(sess=sess, save_path=save_files)</span><br><span class="line">            print(sess.run([v1, v2, rezult]))</span><br><span class="line">            # [5.0, -4.2127123, 0.7872877]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # train()</span><br><span class="line">    restore_variables()</span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>感知器模型</title>
      <link href="/2020/01/13/%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/01/13/%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="感知器模型"><a class="markdownIt-Anchor" href="#感知器模型"></a> 感知器模型</h1><p>感知器是一种模拟人的神经元的一种算法模型，是一种研究单个训练样本的二元分类器，是SVM和人工神经网络(ANN, Artificial Neural Networks)的基础。<br>一个感知器接受几个二进制的输入，并产生一个二进制的输出（阶跃函数），通常的表达方式如下：<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/1_ys.png" class="lazyload" title="1_ys"></a></p><p>感知器可以看作是根据权重来做出决定的一个设备/单元，只要我们可以给定一个比较适合的权重以及阈值，那么感知器应该是能够对数据进行判断的/分类预测的.</p><h2 id="感知器神经元逻辑与and"><a class="markdownIt-Anchor" href="#感知器神经元逻辑与and"></a> 感知器神经元–逻辑与(and)</h2><p>单个神经元完成逻辑与功能:<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2_ys.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2_ys.png" class="lazyload" title="2"></a></p><h2 id="感知器神经元直观理解之逻辑或or"><a class="markdownIt-Anchor" href="#感知器神经元直观理解之逻辑或or"></a> 感知器神经元直观理解之逻辑或or</h2><p>单个神经元完成逻辑或功能：<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/3_ys.png" class="lazyload" title="3_ys"></a></p><h2 id="感知器神经元直观理解之非线性可分"><a class="markdownIt-Anchor" href="#感知器神经元直观理解之非线性可分"></a> 感知器神经元直观理解之非线性可分</h2><p>通过将P1与P2结合完成非运算</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/4_ys.png" class="lazyload" title="4_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/5_ys.png" class="lazyload" title="5_ys"></a></p><h1 id="神经网络-基本架构"><a class="markdownIt-Anchor" href="#神经网络-基本架构"></a> 神经网络-基本架构</h1><p>针对感知器网络的这种很难学习的问题（非线性），引入S型神经元来代替感知器，从而解决这个问题。</p><p>从感知器模型中，我们可以将单个神经元的计算过程看成下列两个步骤：<br>先计算权重w和输入值x以及偏置项b之间的线性结果值z：z=wx+b<br>然后对结果值z进行一个数据的sign函数(变种)转换，得到一个离散的0/1值: y=int((sign(z)+1)/2)</p><p>在S型神经元中，和感知器神经元的区别在于：<br>对于结果值z的转换，采用的不是sign函数进行转换，是采用平滑类型的函数进行转换，让输出的结果值y最终  是一个连续的，S型神经元转指使用的是sigmoid函数。</p><h2 id="神经网络来源之神经元"><a class="markdownIt-Anchor" href="#神经网络来源之神经元"></a> 神经网络来源之“神经元”</h2><p>输入：x1、x2、x3和截距+1；输出：函数hw,b(x)，其中w权重和b偏置项是参数<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/6_ys.png" class="lazyload" title="6_ys"></a></p><p>函数f被称为“激活函数”；常用/最好出现激活函数有sigmoid(逻辑回归函数)和tanh(双曲正切函数)</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/7_ys.png" class="lazyload" title="7_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/8.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/8.png" class="lazyload" title="7_ys"></a></p><h2 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h2><p>激活函数的主要作用是提供网络的非线性建模能力。如果没有激活函数，那么该网络仅能够表达线性映射，此时即便有再多的隐藏层，其整个网络跟单层神经网络也是等价的。因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。 激活函数的主要特性是：可微性、单调性、输出值的范围；</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16_ys.png" data-fancybox="group" data-caption="16_ys" class="fancybox"><img alt="16_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16_ys.png" class="lazyload" title="16_ys"></a></p><p>常见的激活函数：Sign函数、Sigmoid函数、Tanh函数、ReLU函数、Leaky-ReLU函数、ELU函数等</p><h1 id="神经网络"><a class="markdownIt-Anchor" href="#神经网络"></a> 神经网络</h1><p>神经网络主要由三个组成部分，第一个是架构（architecture）或称为拓扑结构（topology），描述神经元的层次与连接神经元的结构。第二个组成部分是神经网络使用的激励/激活函数。第三个组成部分是找出最优权重值的学习算法（SGD,BGD,MBGD）。</p><p>神经网络主要分为两种类型：前馈神经网络(Feedforward Neural Networks)是最常用的神经网络类型（如FC  CNN），一般定义为有向无环图，信号只能沿着最终输出的那个方向传播。另外一个是反馈神经网络(Feedback Neural Networks)，也称为递归神经网络(Recurent Neural Networks)，也就是网络中环。</p><h2 id="神经网络之浅层神经网络"><a class="markdownIt-Anchor" href="#神经网络之浅层神经网络"></a> 神经网络之浅层神经网络</h2><p>添加少量隐层的神经网络就叫做浅层神经网络；也叫作传统神经网络，一般为2隐层的神经网络(超过两隐层的话，效果会差很多).</p><p>深层网络面临问题：硬件，梯度消散（链式求导导致）</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10_ys.png" class="lazyload" title="7_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/9.png" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/9.png" class="lazyload" title="9"></a></p><p>链式求导：(反向)$ \frac{\partial Loss}{\partial w^0}=\frac{\partial Loss}{\partial \tilde{y}}*w^3 \frac{\partial \tilde{y}}{\partial h_3}*w^2\frac{\partial h_3}{\partial h^2}…$</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11_ys.png" data-fancybox="group" data-caption="11_ys" class="fancybox"><img alt="11_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11_ys.png" class="lazyload" title="11_ys"></a></p><h2 id="神经网络之非线性可分"><a class="markdownIt-Anchor" href="#神经网络之非线性可分"></a> 神经网络之非线性可分</h2><p>对线性分类器的与和或的组合可以完成非线性可分的问题；即通过多层的神经网络中加入激活函数的方式可以解决非线性可分的问题。</p><h2 id="神经网络之过拟合"><a class="markdownIt-Anchor" href="#神经网络之过拟合"></a> 神经网络之过拟合</h2><ol><li><p>理论上来讲，单隐层的神经网络可以逼近任何连续函数（只要隐层的神经元个数足够的多<一个神经元将数据集分为两类>）</p></li><li><p>虽然从数学表达上来讲，效果一样，但是在网络工程效果中，多隐层的神经网络效果要比单隐层的神经网络效果好</p></li><li><p>对于一些分类的问题来讲，三层的神经网络效果优于两层的神经网络，但是如果把层次不断增加(4,5,6,7…)，对于最终的效果不会产生太大的变化<br>提升隐层层数或者神经元个数，神经网络的“容量”会变大，那么空间表达能力会变强（模型的拟合能力变强），从而有可能导致过拟合的问题（解决：1.droppwt2.正则化3.减小模型复杂度）</p></li><li><p>对于视频/图片识别/文本/语音 等问题，传统的神经网络(全连接神经网络)不太适合</p></li></ol><h1 id="反向传播神经网络-bpnn"><a class="markdownIt-Anchor" href="#反向传播神经网络-bpnn"></a> 反向传播神经网络-BPNN</h1><pre><code>BP（梯度下降）</code></pre><p>梯度下降的数学推导</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13_ys.png" data-fancybox="group" data-caption="13_ys" class="fancybox"><img alt="13_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13_ys.png" class="lazyload" title="13_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14_ys.png" data-fancybox="group" data-caption="14_ys" class="fancybox"><img alt="14_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14_ys.png" class="lazyload" title="14_ys"></a></p><h2 id="反向传播-练习"><a class="markdownIt-Anchor" href="#反向传播-练习"></a> 反向传播-练习</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12_ys.png" data-fancybox="group" data-caption="12_ys" class="fancybox"><img alt="12_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12_ys.png" class="lazyload" title="12_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15_ys.jpg" data-fancybox="group" data-caption="15_ys" class="fancybox"><img alt="15_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15_ys.jpg" class="lazyload" title="15_ys"></a></p><p>![17 (4)_ys](/img/深度学习/17 (4)_ys.png)</p><p>![17 (1)_ys](/img/深度学习/17 (1)_ys.png)</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/20_ys.png" data-fancybox="group" data-caption="20_ys" class="fancybox"><img alt="20_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/20_ys.png" class="lazyload" title="20_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/19_ys.png" data-fancybox="group" data-caption="19_ys" class="fancybox"><img alt="19_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/19_ys.png" class="lazyload" title="19_ys"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">SGD：实际应用中用全部样本随机打乱取均值，如果每次在样本中随机去选择 成本很高。</span><br><span class="line">实际工作中大部分用到的是小批量梯度算法</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">案例：研究生学院录取数据，用梯度下降训练一个网络。</span></span><br><span class="line"><span class="string">数据有三个输入特征：GRE 分数、GPA 分数和本科院校排名（从 1 到 4）。排名 1 代表最好，排名 4 代表最差。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">pd.set_option(<span class="string">'display.max_columns'</span>, <span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">'display.width'</span>, <span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">admissions = pd.read_csv(<span class="string">'../datas/11.csv'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_explore</span><span class="params">(admissions)</span>:</span></span><br><span class="line">    print(admissions.head(n=<span class="number">10</span>))</span><br><span class="line">    print(admissions.info())         <span class="comment"># 查看是否有空值，以及数据类型</span></span><br><span class="line">    print(admissions.describe())     <span class="comment"># 再次可以看到是否有空值，以及值范围，需要考虑做数据变换。</span></span><br><span class="line">    print(<span class="string">'各个样本相应的数量为:{}'</span>.format(admissions[<span class="string">'admit'</span>].value_counts()))   <span class="comment"># 查看样本是否均衡</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">一、数据清理</span></span><br><span class="line"><span class="string">    1、分类变量哑编码</span></span><br><span class="line"><span class="string">    rank 是类别特征，其中的数字并不表示任何相对的值。排名第 2 并不是排名第 1 的两倍；</span></span><br><span class="line"><span class="string">    排名第 3 也不是排名第 2 的 1.5 倍。因此，我们需要用哑变量 来对 rank 进行编码。</span></span><br><span class="line"><span class="string">    把数据分成 4 个新列，用 0 或 1 表示。排名为 1 的行对应 rank_1 列的值为 1 ，其余三列的值为 0；</span></span><br><span class="line"><span class="string">    排名为 2 的行对应 rank_2 列的值为 1 ，其余三列的值为 0，以此类推。</span></span><br><span class="line"><span class="string">    2、连续变量标准化</span></span><br><span class="line"><span class="string">    把 GRE 和 GPA 数据标准化，变成均值为 0，标准偏差为 1。因为 sigmoid 函数会挤压很大或者很小的输入。</span></span><br><span class="line"><span class="string">    很大或者很小输入的梯度为 0，这意味着梯度下降的步长也会是 0。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_transform</span><span class="params">(admissions)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    一  rank代表学校等级（1--4），转成哑变量</span></span><br><span class="line"><span class="string">    1、 用pd.get_dummies 将rank列，转成哑变量，新变量名前缀为：prefix='rank'</span></span><br><span class="line"><span class="string">    2、将原数据集admissions 和 1 进行列拼接；</span></span><br><span class="line"><span class="string">    3、drop原始的rank列。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = pd.concat([admissions, pd.get_dummies(admissions[<span class="string">'rank'</span>], prefix=<span class="string">'rank'</span>)], axis=<span class="number">1</span>)</span><br><span class="line">    data = data.drop(<span class="string">'rank'</span>, axis=<span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    二、gre和gpa连续变量的标准化</span></span><br><span class="line"><span class="string">    标准做法：先拆分数据集--使用训练数据集的统计量 去标准化 验证和测试。   </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> [<span class="string">'gre'</span>, <span class="string">'gpa'</span>]:</span><br><span class="line">        mean, std = data[field].mean(), data[field].std()</span><br><span class="line">        data.loc[:, field] = (data[field] - mean) / std <span class="comment">#取field所有行</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    三、数据拆分：分成训练 和 测试数据集</span></span><br><span class="line"><span class="string">    1、设置随机数种子，确保大家执行和我们这里演示的结果一致；</span></span><br><span class="line"><span class="string">    2、使用np.random.choice，随机选择数据集中90% 数据的index</span></span><br><span class="line"><span class="string">    3.iloc，完全基于位置的索引</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 随机打乱，并将数据集拆分为  90%训练---10%测试数据集。</span></span><br><span class="line">    np.random.seed(<span class="number">42</span>)</span><br><span class="line">    sample = np.random.choice(data.index, size=int(len(data) * <span class="number">0.9</span>), replace=<span class="literal">False</span>)</span><br><span class="line">    train_data, test_data = data.iloc[sample], data.drop(sample)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    四、 将自变量（features）和目标值分离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    features_train, targets_train = train_data.drop(<span class="string">'admit'</span>, axis=<span class="number">1</span>), train_data[<span class="string">'admit'</span>]</span><br><span class="line">    features_test, targets_test = test_data.drop(<span class="string">'admit'</span>, axis=<span class="number">1</span>), test_data[<span class="string">'admit'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features_train.values, targets_train.values, features_test.values, targets_test.values</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    sigmoid激活函数</span></span><br><span class="line"><span class="string">    :param x:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gre_bp_answer</span><span class="params">(feature_train, target_train, feature_test, target_test)</span>:</span></span><br><span class="line">    <span class="comment"># 1、超参数</span></span><br><span class="line">    n_hidden = <span class="number">2</span> <span class="comment">#隐藏层节点个数</span></span><br><span class="line">    epochs = <span class="number">2000</span>  <span class="comment">#梯度下降迭代次数</span></span><br><span class="line">    learning_rate = <span class="number">0.06</span>  <span class="comment">#学习率</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取样本数量和 特征数量</span></span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、初始化模型权重</span></span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=<span class="number">0.0</span>, scale=<span class="number">0.1</span>, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># weights_hidden_2_output = np.random.normal(</span></span><br><span class="line">    <span class="comment">#     scale=0.1, size=n_hidden</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=<span class="number">0.1</span>, size=[n_hidden, <span class="number">1</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建梯度下降迭代次数的循环</span></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="comment"># 构建存储梯度值的delta_w</span></span><br><span class="line">        del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(feature_train, target_train):</span><br><span class="line">            <span class="comment"># 1、正向传播；</span></span><br><span class="line">            hidden_input = np.matmul(x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            <span class="comment"># hidden_output shape = (2,)</span></span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) <span class="comment"># shape = ()  是一个标量</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2、求误差</span></span><br><span class="line">            error = y_hat - y</span><br><span class="line">            <span class="comment"># 3、反向传播</span></span><br><span class="line">            <span class="comment"># 求输出层误差项</span></span><br><span class="line">            output_error_term = error * y_hat * (<span class="number">1</span>-y_hat)  <span class="comment"># 标量</span></span><br><span class="line">            <span class="comment"># 隐藏层误差</span></span><br><span class="line">            hidden_error = output_error_term * weights_hidden_2_output  <span class="comment"># (n_hidden,)</span></span><br><span class="line">            <span class="comment"># 隐藏层误差项</span></span><br><span class="line">            <span class="comment"># print(hidden_error.shape, hidden_output.shape)</span></span><br><span class="line">            hidden_error_term = hidden_error.reshape(<span class="number">-1</span>) * hidden_output *(<span class="number">1</span>-hidden_output) <span class="comment">#reshape 将其拉成一个向量与后面维度保持一致</span></span><br><span class="line">            <span class="comment"># (n_hidden,)</span></span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden += x[:, <span class="literal">None</span>] * hidden_error_term <span class="comment">#累加求和</span></span><br><span class="line">            del_weights_hidden_2_output += hidden_output[:, <span class="literal">None</span>] * output_error_term</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新模型权重</span></span><br><span class="line">        weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">        weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印模型损失</span></span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> last_loss <span class="keyword">and</span> last_loss < loss:</span><br><span class="line">                print(<span class="string">'警告：模型损失在上升, Train Loss:{}'</span>.format(loss))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'Epochs:{} - Train Loss:{}'</span>.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">  <span class="comment">#训练结束，使用测试数据集验证模型准确率</span></span><br><span class="line">        hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">        test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">        predictions = test_pred > <span class="number">0.5</span></span><br><span class="line">        accuracy = np.mean(predictions == target_test)</span><br><span class="line">        print(<span class="string">"Test Accuray:{:,.5f}"</span>.format(accuracy))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># data_explore(admissions)</span></span><br><span class="line">    features_train, targets_train, features_test, targets_test = data_transform(admissions)</span><br><span class="line">    <span class="comment"># print(features_train)</span></span><br><span class="line">    gre_bp_answer(features_train, targets_train, features_test, targets_test)</span><br></pre></td></tr></tbody></table></figure></div><h2 id="gre案例的伪代码bgd"><a class="markdownIt-Anchor" href="#gre案例的伪代码bgd"></a> GRE案例的伪代码（BGD）</h2><p>传入（train_features, train_target）<br>n_records, n_features = train_features.shape<br>hidden_nodes = 3（隐藏层节点数）<br>learning_rate = 0.01<br>初始化权重。 Winput2h , Wh2output （随机初始化）<br>Last_loss = None<br>epochs = 200（迭代次数）<br>for e in range(epochs):（所有样本训练一次=一个epochc）<br>delta_Winput2h,  delta_Wh2output = np.zeros(),   np.zeros()<br>for  X,y  in zip(train_features,  train_target):<br>#1、正向传播；<br>#2、获得损失(error)   用的MSE作为损失函数<br>#3、执行反向传播<br>#4、delta_Winput2h,  delta_Wh2output 进行累加<br>执行Winput2h , Wh2output 梯度下降。<br>if  e % 10==0:<br>执行正向传播，求出当前的损失，并且打印。<br>用测试数据集，做正向传播，并且求准确率。</p><p>注:zip函数用法</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,2,3]</span><br><span class="line"></span><br><span class="line">b = [4,5,6] </span><br><span class="line"></span><br><span class="line">c = [4,5,6,7,8] </span><br><span class="line"></span><br><span class="line">zipped = zip(a,b)     # 打包为元组的列表 </span><br><span class="line"> [(1, 4), (2, 5), (3, 6)] </span><br><span class="line"> >>> zip(a,c)              # 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] </span><br><span class="line"> zip(*zipped)          </span><br><span class="line"> # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式 [(1, 2, 3), (4, 5, 6)]</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">小批量梯度下降MBGD 一般选用2的n次方大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">案例：研究生学院录取数据，用梯度下降训练一个网络。</span><br><span class="line">数据有三个输入特征：GRE 分数、GPA 分数和本科院校排名（从 1 到 4）。排名 1 代表最好，排名 4 代表最差。</span><br><span class="line">"""</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">pd.set_option('display.max_columns', 1000)</span><br><span class="line">pd.set_option('display.width', 1000)</span><br><span class="line">pd.set_option('display.max_colwidth', 1000)</span><br><span class="line"></span><br><span class="line">admissions = pd.read_csv('../datas/11.csv')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def data_explore(admissions):</span><br><span class="line">    print(admissions.head(n=10))</span><br><span class="line">    print(admissions.info())         # 查看是否有空值，以及数据类型</span><br><span class="line">    print(admissions.describe())     # 再次可以看到是否有空值，以及值范围，需要考虑做数据变换。</span><br><span class="line">    print('各个样本相应的数量为:{}'.format(admissions['admit'].value_counts()))   # 查看样本是否均衡</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">一、数据清理</span><br><span class="line">    1、分类变量哑编码</span><br><span class="line">    rank 是类别特征，其中的数字并不表示任何相对的值。排名第 2 并不是排名第 1 的两倍；</span><br><span class="line">    排名第 3 也不是排名第 2 的 1.5 倍。因此，我们需要用哑变量 来对 rank 进行编码。</span><br><span class="line">    把数据分成 4 个新列，用 0 或 1 表示。排名为 1 的行对应 rank_1 列的值为 1 ，其余三列的值为 0；</span><br><span class="line">    排名为 2 的行对应 rank_2 列的值为 1 ，其余三列的值为 0，以此类推。</span><br><span class="line">    2、连续变量标准化</span><br><span class="line">    把 GRE 和 GPA 数据标准化，变成均值为 0，标准偏差为 1。因为 sigmoid 函数会挤压很大或者很小的输入。</span><br><span class="line">    很大或者很小输入的梯度为 0，这意味着梯度下降的步长也会是 0。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def data_transform(admissions):</span><br><span class="line">    """</span><br><span class="line">    一  rank代表学校等级（1--4），转成哑变量</span><br><span class="line">    1、 用pd.get_dummies 将rank列，转成哑变量，新变量名前缀为：prefix='rank'</span><br><span class="line">    2、将原数据集admissions 和 1 进行列拼接；</span><br><span class="line">    3、drop原始的rank列。</span><br><span class="line">    """</span><br><span class="line">    data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)</span><br><span class="line">    data = data.drop('rank', axis=1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    二、gre和gpa连续变量的标准化</span><br><span class="line">    标准做法：先拆分数据集--使用训练数据集的统计量 去标准化 验证和测试。</span><br><span class="line">    """</span><br><span class="line"></span><br><span class="line">    for field in ['gre', 'gpa']:</span><br><span class="line">        mean, std = data[field].mean(), data[field].std()</span><br><span class="line">        data.loc[:, field] = (data[field] - mean) / std</span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    三、数据拆分：分成训练 和 测试数据集</span><br><span class="line">    1、设置随机数种子，确保大家执行和我们这里演示的结果一致；</span><br><span class="line">    2、使用np.random.choice，随机选择数据集中90% 数据的index</span><br><span class="line">    """</span><br><span class="line">    # 随机打乱，并将数据集拆分为  90%训练---10%测试数据集。</span><br><span class="line">    np.random.seed(42)</span><br><span class="line">    sample = np.random.choice(data.index, size=int(len(data) * 0.9), replace=False)</span><br><span class="line">    train_data, test_data = data.iloc[sample], data.drop(sample)</span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    四、 将自变量（features）和目标值分离</span><br><span class="line">    """</span><br><span class="line">    features_train, targets_train = train_data.drop('admit', axis=1), train_data['admit']</span><br><span class="line">    features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']</span><br><span class="line"></span><br><span class="line">    return features_train.values, targets_train.values, features_test.values, targets_test.values</span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    """</span><br><span class="line">    sigmoid激活函数</span><br><span class="line">    :param x:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    return 1/(1+np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gre_bp_answer(feature_train, target_train, feature_test, target_test):</span><br><span class="line">    # 1、超参数</span><br><span class="line">    n_hidden = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    learning_rate = 0.06</span><br><span class="line"></span><br><span class="line">    # 获取样本数量和 特征数量</span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = None</span><br><span class="line"></span><br><span class="line">    # 2、初始化模型权重</span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=0.0, scale=0.1, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line">    # weights_hidden_2_output = np.random.normal(</span><br><span class="line">    #     scale=0.1, size=n_hidden</span><br><span class="line">    # )</span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=0.1, size=[n_hidden, 1]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 构建迭代次数的循环</span><br><span class="line">    for e in range(epochs):</span><br><span class="line">        # 构建存储梯度值的delta_w</span><br><span class="line">        del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        for x, y in zip(feature_train, target_train):</span><br><span class="line">            # 1、正向传播；</span><br><span class="line">            hidden_input = np.matmul(x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            # hidden_output shape = (2,)</span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) # shape = ()  是一个标量</span><br><span class="line"></span><br><span class="line">            # 2、求误差</span><br><span class="line">            error = y_hat - y</span><br><span class="line">            # 3、反向传播</span><br><span class="line">            # 求输出层误差项</span><br><span class="line">            output_error_term = error * y_hat * (1-y_hat)  # 标量</span><br><span class="line">            # 隐藏层误差</span><br><span class="line">            hidden_error = output_error_term * weights_hidden_2_output  # (n_hidden,)</span><br><span class="line">            # 隐藏层误差项</span><br><span class="line">            # print(hidden_error.shape, hidden_output.shape)</span><br><span class="line">            hidden_error_term = hidden_error.reshape(-1) * hidden_output *(1-hidden_output)</span><br><span class="line">            # (n_hidden,)</span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden += x[:, None] * hidden_error_term</span><br><span class="line">            del_weights_hidden_2_output += hidden_output[:, None] * output_error_term</span><br><span class="line"></span><br><span class="line">        # 更新模型权重</span><br><span class="line">        weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">        weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        # 打印模型损失</span><br><span class="line">        if e % 100 == 0:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**2)</span><br><span class="line"></span><br><span class="line">            if last_loss and last_loss < loss:</span><br><span class="line">                print('警告：模型损失在上升, Train Loss:{}'.format(loss))</span><br><span class="line">            else:</span><br><span class="line">                print('Epochs:{} - Train Loss:{}'.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">    #训练结束，使用测试数据集验证模型准确率</span><br><span class="line">    hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">    test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">    predictions = test_pred > 0.5</span><br><span class="line">    accuracy = np.mean(predictions == target_test)</span><br><span class="line">    print("Test Accuray:{:,.5f}".format(accuracy))</span><br><span class="line">def get_batches(feature_train, target_train, batch_size = 32):</span><br><span class="line">    """</span><br><span class="line">    构建批量数据的生成器</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param batch_size:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    for ii in range(0,len(feature_train), batch_size):</span><br><span class="line">        batch_x = feature_train[ii:ii+batch_size]</span><br><span class="line">        batch_y = target_train[ii:ii+batch_size]</span><br><span class="line">        yield batch_x,batch_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gre_bp_MBGD(feature_train, target_train, feature_test, target_test,batch_size = 128):</span><br><span class="line">    """</span><br><span class="line">    使用小批量梯度下降实现GRE</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param feature_test:</span><br><span class="line">    :param target_test:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、超参数</span><br><span class="line">    n_hidden = 4</span><br><span class="line">    epochs = 2000</span><br><span class="line">    learning_rate = 0.06</span><br><span class="line"></span><br><span class="line">    # 获取样本数量和 特征数量</span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = None</span><br><span class="line"></span><br><span class="line">    # 2、初始化模型权重</span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=0.0, scale=0.1, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=0.1, size=[n_hidden, 1]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 构建迭代次数的循环</span><br><span class="line"></span><br><span class="line">    for e in range(epochs):</span><br><span class="line">        # 构建存储梯度值的delta_w</span><br><span class="line">        # del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        # del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        for batch_x, batch_y in get_batches(feature_train, target_train, batch_size):</span><br><span class="line">            # 1、正向传播；</span><br><span class="line">            hidden_input = np.matmul(batch_x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            # hidden_output shape = (2,)</span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) # shape = ()  是一个标量</span><br><span class="line"></span><br><span class="line">            # 2、求误差</span><br><span class="line">            error = y_hat - batch_y[:,None]       #[N,1]</span><br><span class="line">            # 3、反向传播</span><br><span class="line">            # 求输出层误差项 [N,1]</span><br><span class="line">            output_error_term = error * y_hat * (1-y_hat)  # 标量</span><br><span class="line">            # 隐藏层误差[N,4]</span><br><span class="line">            hidden_error = np.matmul(output_error_term , weights_hidden_2_output.transpose())   # (n_hidden,)</span><br><span class="line">            # 隐藏层误差项</span><br><span class="line">            # print(hidden_error.shape, hidden_output.shape)</span><br><span class="line">            hidden_error_term = hidden_error * hidden_output *(1-hidden_output)</span><br><span class="line">            # (n_hidden,)</span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden =np.matmul(np.transpose(batch_x),hidden_error_term)/batch_size</span><br><span class="line"></span><br><span class="line">            del_weights_hidden_2_output = np.matmul(np.transpose(hidden_output),output_error_term)/batch_size</span><br><span class="line"></span><br><span class="line">            # 更新模型权重</span><br><span class="line">            weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">            weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        # 打印模型损失</span><br><span class="line">        if e % 100 == 0:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**2)</span><br><span class="line"></span><br><span class="line">            if last_loss and last_loss < loss:</span><br><span class="line">                print('警告：模型损失在上升, Train Loss:{}'.format(loss))</span><br><span class="line">            else:</span><br><span class="line">                print('Epochs:{} - Train Loss:{}'.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">    #训练结束，使用测试数据集验证模型准确率</span><br><span class="line">    hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">    test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">    predictions = test_pred > 0.5</span><br><span class="line">    accuracy = np.mean(predictions == target_test)</span><br><span class="line">    print("Test Accuray:{:,.5f}".format(accuracy))</span><br><span class="line">def get_batches(feature_train, target_train, batch_size = 32):</span><br><span class="line">    """</span><br><span class="line">    构建批量数据的生成器</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param batch_size:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    for ii in range(0,len(feature_train), batch_size):</span><br><span class="line">        batch_x = feature_train[ii:ii+batch_size]</span><br><span class="line">        batch_y = target_train[ii:ii+batch_size]</span><br><span class="line">        yield batch_x,batch_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # data_explore(admissions)</span><br><span class="line">    features_train, targets_train, features_test, targets_test = data_transform(admissions)</span><br><span class="line">    #print(features_train[:,None])</span><br><span class="line">    gre_bp_answer(features_train, targets_train, features_test, targets_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    gre_bp_MBGD(features_train, targets_train, features_test, targets_test, batch_si</span><br></pre></td></tr></tbody></table></figure></div><p>SGD:随机梯度下降：每次随机选择一样本，计算梯度值，并且更新模型权重。（基本不用）</p><p>BGD：计算所有样本的梯度平均值。然后技更新模型权重。</p><p>MBGD:小批量梯度下降。每次随机选择batch_size样本，计算梯度的平均值，再更新模型权重。（主要）</p><h1 id><a class="markdownIt-Anchor" href="#"></a> </h1></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>过拟合与正则化</title>
      <link href="/2020/01/13/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/"/>
      <url>/2020/01/13/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="过拟合"><a class="markdownIt-Anchor" href="#过拟合"></a> 过拟合</h1><p>图1，2：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/1_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/2_ys.png" class="lazyload"></a></p><p>1-3与2-3过拟合，代价函数等于0或者无限接近于0，但无法应用于新样本中.</p><p>图3：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/3_ys.png" class="lazyload"></a></p><p>当有很多特征变量时，已经不是多项式阶次的选择问题。当我们预测房价时，有许多特征变量与房价可能有关，但是当特征变量过多，训练样本过少时，则容易出现过拟合问题。</p><p>为了解决过拟合问题，有两个方法：</p><p>1.尽量减少选取变量的数量，如人工检查变量清单，并以此决定哪些变量更为重要，哪些特征变量应该保留，哪些应该舍弃。</p><p>这种方法可以有效防止过拟合的发生，缺点;舍弃一部分特征变量也舍弃了关于问题的一些信息。</p><p>2.正则化：保留所有特征变量但是减小量级<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\theta_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的大小，</p><h1 id="正则化"><a class="markdownIt-Anchor" href="#正则化"></a> 正则化</h1><p>图4：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/4_ys.png" class="lazyload"></a></p><p>当我们想让这个新函数尽可能小的时候，要使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>尽可能小，因为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>系数为1000，使整个函数变得非常大，当我们最小化新函数时，我们要使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub><mi mathvariant="normal">尽</mi><mi mathvariant="normal">可</mi><mi mathvariant="normal">能</mi><mi mathvariant="normal">者</mi><mi mathvariant="normal">接</mi><mi mathvariant="normal">近</mi><mn>0</mn></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4尽可能者接近0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">尽</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">者</span><span class="mord cjk_fallback">接</span><span class="mord cjk_fallback">近</span><span class="mord">0</span></span></span></span>，即消去<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，那么这个函数相当于二次函数加上了一些非常小的项。</p><p>这就是加入惩罚增大两个参数的结果，即正则化的思想：如果将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>4</mn></msub><msub><mi>θ</mi><mn>5</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\theta_1,\theta_2,\theta_3,\theta_4\theta_5...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span></span></span></span>都加上惩罚项，这么做就相当于去简化这个假设模型，参数越接近于0.结果表明，这些参数的数值越小，我们得到的函数就越平滑也越简单，越不容易出现过拟合问题，</p><p>图5：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/5_ys.png" class="lazyload"></a></p><p>在正则化中，修改代价函数（添加正则化项）来缩小所有参数（因为不知该选那些参数去缩小），此处求和从参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>开始没有给参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>添加惩罚项（约定俗成），对结果影响不大。</p><p>图6：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/6_ys.png" class="lazyload"></a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>作用，控制两个不同目标之间的取舍，第一个目标与函数第一项有关（更好的拟合训练集），第二个目标，保持参数尽量地小（与正则化目标有关）。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>即正则化参数作用是控制这辆两个目标之间的关系。即更好的拟合训练集和将参数控制的更小，保持假设模型简单避免出现过拟合。</p><p>图7:<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" title="7_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/7_ys.png" class="lazyload"></a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>过大会导致参数都接近于0，相当于只保留了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，用一条直线去拟合数据，导致欠拟合。</p><h1 id="l1与l2正则"><a class="markdownIt-Anchor" href="#l1与l2正则"></a> L1与L2正则</h1></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学公式：</title>
      <link href="/2020/01/10/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%9A/"/>
      <url>/2020/01/10/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%9A/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="数学公式"><a class="markdownIt-Anchor" href="#数学公式"></a> 数学公式：</h1><h3 id="jensen不等式"><a class="markdownIt-Anchor" href="#jensen不等式"></a> Jensen不等式</h3><p>如果函数f为凸函数，那么存在下列公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>≤</mo><mi>θ</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta x_1 +(1-\theta x_2))\leq  \theta f(x_1)+(1-\theta)f(x_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>若<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>θ</mi><mi>n</mi></msub><mo>≥</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\theta_1,\theta_2,...\theta_n\geq0,\theta_1+\theta_2+...+\theta_n=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，则<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>θ</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>≤</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta_1x_1+\theta_2x_2+...+\theta_nx_n)\leq\theta_1f(x_1)+\theta_2f(x_2)+...+\theta_nf(x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>,则f((E(x))≤E(f(x))</p><p>特别地，如果函数 f(x)是严格凸函数，当且仅当p(x=E(x))=1,即随机变量是常量时等号成立。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>θ</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta x_1 +(1-\theta x_1))=\theta f(x_1)+(1-\theta)f(x_1)=f(x_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><h1 id="em算法"><a class="markdownIt-Anchor" href="#em算法"></a> EM算法</h1><p>EM算法(Expectation Maximization Algorithm, 最大期望算法)是一种迭代类型的算法，是一种在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量。</p><p>EM算法(Expectation Maximization Algorithm, 最大期望算法)是一种迭代类型的算法，是一种在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量。</p><h2 id="em算法流程"><a class="markdownIt-Anchor" href="#em算法流程"></a> EM算法流程：</h2><p>1.初始化分布参数/模型参数</p><p>2.重复下列两个操作直到收敛：</p><p>E步骤：估计隐藏变量的概率分布期望函数；<br>M步骤：根据期望函数重新估计分布参数。</p><h2 id="em算法原理"><a class="markdownIt-Anchor" href="#em算法原理"></a> EM算法原理</h2><p>给定的m个训练样本{x(1),x(2),…,x(m)}，样本间独立，找出样本的模型参数θ，极大化模型分布的对数似然函数如下：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mtext> </mtext><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>i</mi></msup><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">{\underset {\theta}{\operatorname {arg\,max} }}\,\sum_{i=1}^{m}{log(P(x^{i};\theta))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7712119999999998em;vertical-align:-0.946548em;"></span><span class="mord"><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.153452em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.946548em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>假定样本数据中存在隐含数据z={z(1),z(2),…,z(k)}，此时极大化模型分布的对数似然函数如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>i</mi></msup><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msup><mi>z</mi><mo stretchy="false">(</mo></msup><mi>i</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mi>P</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mi mathvariant="normal">∣</mi><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mo separator="true">;</mo><mi>θ</mi></mrow><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msup><mi>z</mi><mo stretchy="false">(</mo></msup><mi>i</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mo separator="true">;</mo><mi>θ</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=arg\max_{\theta}L({\theta})=arg\max_{\theta}\sum_{i=1}^{m}{log(P(x^{i};\theta))}\\　　　　　　　　　=arg\max_{\theta}\sum_{i=1}^{m}{log(\sum_{z^(i)}{P(z^{i})P(x^{(i)}|z^{i});\theta})}\\　　　　　　=arg\max_{\theta}\sum_{i=1}^{m}{log(\sum_{z^(i)}{P(x^{(i)},z^{i});\theta})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.217827em;vertical-align:-1.56643em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.75857em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8220357142857143em;"><span style="top:-2.8220357142857138em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.56643em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.217827em;vertical-align:-1.56643em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.75857em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8220357142857143em;"><span style="top:-2.8220357142857138em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.56643em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span></span></span></span></span></span></p><p>令z的分布为Q(z;θ) ，并且Q(z;θ)≥0；那么有如下公式：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ｌ</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac></mrow></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>≥</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mi>a</mi><mi>b</mi></munderover><mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mrow></mrow><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Ｌ(\theta)=\sum_{i=1}^{m}{log\sum_{z}^{}{P(x,z;\theta)}}\\　　　　　　=\sum_{i=1}^{m}{log \sum_{z}^{}{Q(z;\theta ^{old})\frac{P(x,z;\theta)}{Q(z;\theta^{old})}}}\\　　　　=\sum_{i=1}^{m}{log(E_Q(  \frac{P(x,z;\theta)} {Q(z;\theta^{old})}  ))}\\　　　　\geq \sum_{i=1}^{m}{E_Q(log(  \frac{P(x,z;\theta)} {Q(z;\theta^{old} )}  ))}\\　　　　　　　=\sum_{a}^{b}{\sum_{z}^{}{ Q(z;\theta^{old} ) log(   \frac{P(x,z;\theta^{}{})} {Q(z;\theta^{old} )}  ) }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">Ｌ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.086118em;vertical-align:-1.250005em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.836113em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mord"></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span></span></p><h3 id="公式2详解"><a class="markdownIt-Anchor" href="#公式2详解"></a> 公式(2)详解：</h3><p>1.公式(1)得出的结论理论上可行，实践起来不成。主要是因为似然函数有“和的log”这一项，（公式（2）的前两步）log里面是一个和的形式，一求导这画面不要太美，直接强来你要面对 “两个正态分布的概率密度函数相加”做分母，“两个正态分布分别求导再相加”做分子的分数形式。m个这玩意加起来令它等于0，要求出关于θ的解析解，你对自己的数学水平想的不要太高</p><p>2.引入Jensen不等式:X是一个随机变量，f(X)是一个凸函数（二阶导数大或等于0），那么有：E(f(x))≥f(E(x))，当且仅当X是常数的时候等号成立，如果f（X）是凹函数，不等号反向。</p><p>3.直接最大化似然函数做不到，那么如果我们能找到似然函数的一个<strong>紧</strong>的下界一直优化它，并保证每次迭代能够使总的似然函数一直增大，其实也是一样的。怎么说？画个图你就明白了：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/1_ys.png" class="lazyload"></a></p><p>横坐标是参数，纵坐标是似然函数，首先我们初始化一个θ1，根据它求似然函数一个紧的下界，也就是图中第一条黑短线，黑短线上的值虽然都小于似然函数的值，但至少有一点可以满足等号（所以称为紧下界），最大化小黑短线我们就hit到至少与似然函数刚好相等的位置，对应的横坐标就是我们的新的θ2，如此进行，只要保证随着θ的更新，每次最大化的小黑短线值都比上次的更大，那么算法收敛，最后就能最大化到似然函数的极大值处。</p><p>来到公式2最后两步骤，我们找到了似然函数的一个下界，那么优化它是否就可以呢？不是的，上面说了必须保证这个下界是紧的，也就是至少有点能使等号成立。由Jensen不等式，等式成立的条件是随机变量是常数，具体到这里，就是：</p><p>根据Jensen不等式的特性，当下列式子的值为常数的时候，L(θ)函数才能取等号。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>c</mi><mo separator="true">,</mo><mi mathvariant="normal">∀</mi><mi mathvariant="normal">ｘ</mi><mi mathvariant="normal">．</mi><mi mathvariant="normal">∀</mi><mi mathvariant="normal">ｚ</mi></mrow><annotation encoding="application/x-tex">\\　　　　　　　\frac{P(x,z;\theta^{old})} {Q(z;\theta^{old} )} =c,\forallｘ．\forallｚ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="mspace newline"></span><span class="base"><span class="strut" style="height:2.462108em;vertical-align:-0.936em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∀</span><span class="mord cjk_fallback">ｘ</span><span class="mord cjk_fallback">．</span><span class="mord">∀</span><span class="mord cjk_fallback">ｚ</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ｑ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">,</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>c</mi></mfrac><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>c</mi><mo>⋅</mo><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mo>=</mo><mn>1</mn><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>c</mi><mo>⋅</mo><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mspace linebreak="newline"></mspace><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Ｑ(z,\theta^{old}) =\frac{P(x,z;\theta^{old})}{c}\\　　　　　　　　　　　　　=\frac{P(x,z;\theta^{old})}{c\cdot \sum_{z^i}^{} {Q(z^i;\theta^{old})}}　　　　　　　　　 \sum_{z^i}^{} {Q(z^i;\theta^{old})}=1\\=\frac{P(x,z;\theta^{old})}{ \sum_{z^i}^{} {c\cdot Q(z^i;\theta^{old})}}　　\\=\frac{P(x,z;\theta^{old})}{ \sum_{z^i}^{} {P(x,z^i;\theta^{old})}}　\\=\frac{P(x,z;\theta^{old})}{ P(x;\theta^{old})}\\=P(z|x;\theta^{old})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">Ｑ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.212108em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">c</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.872073em;vertical-align:-1.3459649999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000006em;"><span style="top:-1.804035em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3459649999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.511818em;vertical-align:-0.9857100000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.511818em;vertical-align:-0.9857100000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.462108em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>则可得：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi mathvariant="normal">Ｌ</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mo>≃</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=arg\max_{\theta}Ｌ(\theta)=arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{Q(z;\theta^{old})}log(\frac{P(x,z;\theta^{})}{Q(z;\theta^{old})})\\=arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{P(z|x;\theta^{old}log(\frac{P(x,z;\theta^{}}{P(z|x;\theta^{old})}))}\\ \simeq  arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{P(z|x;\theta^{old})log(P(x,z;\theta^{}))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">Ｌ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.46375em;vertical-align:0em;"></span><span class="mrel">≃</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span style="top:-2.413em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></span></p><p>此处我们化简去loga-logb中的logb,logb此处为常数</p><h2 id="em算法总结"><a class="markdownIt-Anchor" href="#em算法总结"></a> EM算法总结：</h2><p>条件：样本数据x={x1,x2,…,xm}，联合分布p(x,z;θ)，条件分布p(z|x;θ)，最大迭代次数J</p><ol><li>随机初始化模型参数θ的初始值θ0</li><li>开始EM算法的迭代处理：<br>E步：计算联合分布的条件概率期望</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mi>j</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mi>j</mi></msup><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><msup><mi>Q</mi><mi>j</mi></msup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q^j=[(z|x;\theta^j)  \\L(\theta)=\sum_{i=1}^{m}{}\sum_{z}^{}{Q^jlog(P(x,z;\theta))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.069104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.124664em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></span></p><p>​       M步：极大化L函数，得到θj+1</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta^{j+1}=arg\max_{\theta}L(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.874664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span></p><p>如果θj+1已经收敛，则算法结束，输出最终的模型参数θ，否则继续     迭代处理。</p><h2 id="ems算法收敛性证明"><a class="markdownIt-Anchor" href="#ems算法收敛性证明"></a> EMs算法收敛性证明</h2><h1 id="em算法举例"><a class="markdownIt-Anchor" href="#em算法举例"></a> EM算法举例</h1><p>假设现有两个装有不定数量黑球、白球的盒子，随机从盒子中抽取出一个白球的概率分布为p1和p2；为了估计这两个概率，每次选择一个盒子，有放回的连续随机抽取5个球，记录如下：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/2_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/3_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/4_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/5_ys.png" class="lazyload"></a></p><p>求解过程看如下推导:</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/6_ys.jpg" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/6_ys.jpg" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" title="7_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/7_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/8_ys.png" data-fancybox="group" data-caption="8_ys" class="fancybox"><img alt="8_ys" title="8_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/8_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/9_ys.png" data-fancybox="group" data-caption="9_ys" class="fancybox"><img alt="9_ys" title="9_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/9_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/10_ys.png" data-fancybox="group" data-caption="10_ys" class="fancybox"><img alt="10_ys" title="10_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/10_ys.png" class="lazyload"></a></p><h2 id="em算法收敛性证明"><a class="markdownIt-Anchor" href="#em算法收敛性证明"></a> EM算法收敛性证明</h2><p>详见PPT</p><h1 id="gmm算法"><a class="markdownIt-Anchor" href="#gmm算法"></a> GMM算法</h1><p>GMM(Gaussian Mixture Model, 高斯混合模型)是指该算法由多个高斯模型线性叠加混合而成。每个高斯模型称之为component。GMM算法描述的是数据的本身存在的一种分布。<br>GMM算法常用于聚类应用中，component的个数就可以认为是类别的数量。<br>假定GMM由k个Gaussian分布线性叠加而成，那么概率密度函数如下：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><msub><mi>π</mi><mi>k</mi></msub><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msub><mi>μ</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mrow><msubsup><mo>∑</mo><mrow></mrow><mrow></mrow></msubsup><mrow></mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(x)=\sum_{k=1}^{K}{p(k)p(x|k)}=\sum_{k=1}^{K}{π_kp(x;\mu_k,{\sum_{}^{}{}}_k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.330641em;vertical-align:-0.34941em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-1.7002899999999999em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span><span style="top:-2.5029em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.13669799999999993em;"><span style="top:-2.3505900000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34941em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>此处<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">π_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是符号，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mrow><msubsup><mo>∑</mo><mrow></mrow><mrow></mrow></msubsup><mrow></mrow></mrow><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mu_k,{\sum_{}^{}{}}_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.09941em;vertical-align:-0.34941em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-1.7002899999999999em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span><span style="top:-2.5029em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.13669799999999993em;"><span style="top:-2.3505900000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34941em;"><span></span></span></span></span></span></span></span></span></span>代表均值与协方差矩阵</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/11.png" data-fancybox="group" data-caption="11" class="fancybox"><img alt="11" title="11" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/11.png" class="lazyload"></a></p><h1 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h1><p>[<a href="https://www.cnblogs.com/bigmoyan/p/4550375.html" target="_blank" rel="noopener">【机器学习】EM算法详细推导和讲解</a>](<a href="https://www.cnblogs.com/bigmoyan/p/4550375.html" target="_blank" rel="noopener">https://www.cnblogs.com/bigmoyan/p/4550375.html</a>)</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯</title>
      <link href="/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
      <url>/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="涉及公式"><a class="markdownIt-Anchor" href="#涉及公式"></a> 涉及公式</h1><p>先验概率P(A)：在不考虑任何情况下，A事件发生的概率<br>条件概率P(B|A)：A事件发生的情况下，B事件发生的概率:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(AB)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>后验概率P(A|B)：在B事件发生之后，对A事件发生的概率的重新评估<br>全概率：如果A和A’构成样本空间的一个划分，那么事件B的概率为：A和A’的概率分别乘以B对这两个事件的概率之和。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(B)=P(A)*P(B|A)+P(A')*P(B|A')</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(B)=\sum_{i=1}^{n}{P(A_i)*(B|A_i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p><p>乘法定理：成立条件，A1A2…An全连接<a href="/img/beiyesi/pinghua/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/pinghua/1.png" class="lazyload"></a></p><p>A1无依赖，A2依赖于A1,A3依赖于A1A2</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>1</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>A</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mn>1</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>A</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(A_1A_2...A_n)=P(A_1)P(A_2|A_1)...P(A_n|A_1A_2...A_{n-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><h1 id="朴素贝叶斯算法"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法"></a> 朴素贝叶斯算法</h1><p>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。而朴素朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。</p><p><a href="/img/beiyesi/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/1.jpg" class="lazyload"></a></p><h2 id="分类问题综述"><a class="markdownIt-Anchor" href="#分类问题综述"></a> 分类问题综述</h2><p><strong>从数学角度来说，分类问题可做如下定义：已知集合</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>y</mi><mi>n</mi></msub><mi mathvariant="normal">和</mi><mi>I</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">C=y_1,y_2,......y_n和I=x_1,x_2,......x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>确定映射规则y=f()，<strong>使得任意</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">x_i\in I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>**有且仅有一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">y_i\in C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>**使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y_i\in f(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>成立</p><p>其中C叫做类别集合，其中每一个元素是一个类别，而I叫做项集合（<strong>特征集合</strong>），其中每一个元素是一个待分类项，f叫做分类器。<strong>分类算法的任务就是构造分类器f。</strong></p><p><strong>分类算法的内容是要求给定特征，让我们得出类别，这也是所有分类问题的关键。那么如何由指定特征，得到我们最终的类别，也是我们下面要讲的，每一个不同的分类算法，对应着不同的核心思想。</strong></p><h2 id="朴素贝叶斯分类"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类"></a> 朴素贝叶斯分类</h2><p>那么既然是朴素贝叶斯<strong>分类算法</strong>，它的核心算法又是什么呢？</p><p><strong>是下面这个贝叶斯公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(B)*P(A|B)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>换个表达形式就会明朗很多，如下：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(类别|特征)=\frac{P(类别)*P(特征|类别)}{P(特征)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mord">∣</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord">∣</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>我们最终求的p(类别|特征)即可！就相当于完成了我们的任务。</strong></p><h2 id="例题分析"><a class="markdownIt-Anchor" href="#例题分析"></a> <strong>例题分析</strong></h2><p><strong>下面我先给出例子问题。</strong></p><p><strong>给定数据如下：</strong></p><p><a href="/img/beiyesi/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/1.png" class="lazyload"></a></p><p><strong>现在给我们的问题是，如果一对男女朋友，男生想女生求婚，男生的四个特点分别是不帅，性格不好，身高矮，不上进，请你判断一下女生是嫁还是不嫁？</strong></p><p>这是一个典型的分类问题，<strong>转为数学问题就是比较p(嫁|(不帅、性格不好、身高矮、不上进))与p(不嫁|(不帅、性格不好、身高矮、不上进))的概率</strong>，谁的概率大，我就能给出嫁或者不嫁的答案！</p><p>这里我们联系到朴素贝叶斯公式：<a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" title="2" data-src="/img/beiyesi/2.png" class="lazyload"></a></p><p>我们需要求p(嫁|(不帅、性格不好、身高矮、不上进),这是我们不知道的，但是通过朴素贝叶斯公式可以转化为好求的三个量，<strong>p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)（至于为什么能求，后面会讲，那么就太好了，将待求的量转化为其它可求的值，这就相当于解决了我们的问题！）</strong></p><h2 id="朴素贝叶斯算法的朴素一词解释"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法的朴素一词解释"></a> <strong>朴素贝叶斯算法的朴素一词解释</strong></h2><p><strong>那么这三个量是如何求得？</strong></p><p>是根据已知训练数据统计得来，下面详细给出该例子的求解过程。</p><p>回忆一下我们要求的公式如下：</p><p><a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" title="2" data-src="/img/beiyesi/2.png" class="lazyload"></a></p><p>那么我只要求得p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)即可，好的，下面我分别求出这几个概率，最后一比，就得到最终结果。</p><p><strong>p(不帅、性格不好、身高矮、不上进|嫁) = p(不帅|嫁)*p(性格不好|嫁)*p(身高矮|嫁)*p(不上进|嫁)，那么我就要分别统计后面几个概率，也就得到了左边的概率！</strong></p><p>等等，为什么这个成立呢？学过概率论的同学可能有感觉了，这个等式成立的条件需要特征之间相互独立吧！</p><p><strong>对的！这也就是为什么朴素贝叶斯分类有朴素一词的来源，朴素贝叶斯算法是假设各个特征之间相互独立，那么这个等式就成立了！</strong></p><p><strong>但是为什么需要假设特征之间相互独立呢？</strong></p><p>1、我们这么想，假如没有这个假设，那么我们对右边这些概率的估计其实是不可做的，这么说，我们这个例子有4个特征，其中帅包括{帅，不帅}，性格包括{不好，好，爆好}，身高包括{高，矮，中}，上进包括{不上进，上进}，<strong>那么四个特征的联合概率分布总共是4维空间，总个数为2*3*3*2=36个。</strong></p><p><strong>24个，计算机扫描统计还可以，但是现实生活中，往往有非常多的特征，每一个特征的取值也是非常之多，那么通过统计来估计后面概率的值，变得几乎不可做，这也是为什么需要假设特征之间独立的原因。</strong></p><p>2、假如我们没有假设特征之间相互独立，那么我们统计的时候，就需要在整个特征空间中去找，比如统计p(不帅、性格不好、身高矮、不上进|嫁),</p><p><strong>我们就需要在嫁的条件下，去找四种特征全满足分别是不帅，性格不好，身高矮，不上进的人的个数，这样的话，由于数据的稀疏性，很容易统计到0的情况。 这样是不合适的。</strong></p><p>根据上面俩个原因，朴素贝叶斯法对条件概率分布做了条件独立性的假设，由于这是一个较强的假设，朴素贝叶斯也由此得名！这一假设使得朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p><p>好的，上面我解释了为什么可以拆成分开连乘形式。那么下面我们就开始求解！</p><p>我们将上面公式整理一下如下：<a href="/img/beiyesi/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" title="3" data-src="/img/beiyesi/3.png" class="lazyload"></a></p><p>下面我将一个一个的进行统计计算（<strong>在数据量很大的时候，根据中心极限定理，频率是等于概率的，这里只是一个例子，所以我就进行统计即可</strong>）。</p><p>p(嫁)=？</p><p>首先我们整理训练数据中，嫁的样本数如下：<a href="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" data-fancybox="group" data-caption="v2-82d69514c761c791c6eaf90dc0771b44_b" class="fancybox"><img alt="v2-82d69514c761c791c6eaf90dc0771b44_b" title="v2-82d69514c761c791c6eaf90dc0771b44_b" data-src="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" class="lazyload"></a></p><p><strong>则 p(嫁) = 6/12（总样本数） = 1/2</strong></p><p><strong>p(不帅|嫁) = 3/6 = 1/2</strong></p><p><strong>则p(性格不好|嫁)= 1/6</strong></p><p>p(矮|嫁) = 1/6**</p><p>p(不上进|嫁) = 1/6**</p><p><strong>下面开始求分母，p(不帅)，p（性格不好），p（矮），p（不上进）</strong></p><p><strong>不帅统计占4个，那么p（不帅）= 4/12 = 1/3</strong></p><p>性格不好占4个，那么p（性格不好） = 4/12 = 1/3</p><p>身高矮统计，占7个，那么p（身高矮） = 7/12</p><p>不上进统计所示，占4个，那么p（不上进） = 4/12 = 1/3</p><p><strong>到这里，要求p(不帅、性格不好、身高矮、不上进|嫁)的所需项全部求出来了，下面我带入进去即可，<a href="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" data-fancybox="group" data-caption="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" class="fancybox"><img alt="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" title="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" data-src="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" class="lazyload"></a></strong></p><p>= (1/2<em>1/6</em>1/6<em>1/6</em>1/2)/(1/3<em>1/3</em>7/12*1/3)</p><p><strong>下面我们根据同样的方法来求p(不嫁|不帅，性格不好，身高矮，不上进)，完全一样的做法，为了方便理解，我这里也走一遍帮助理解。首先公式如下：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" title="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload"></a></strong></p><p>下面我也一个一个来进行统计计算，这里与上面公式中，分母是一样的，于是我们分母不需要重新统计计算！</p><p>p(不嫁)=6/12 = 1/2</p><p>p（不帅|不嫁） = 1/6</p><p>p（性格不好|不嫁） =3/6 = 1/2</p><p>p（矮|不嫁） = 6/6 = 1</p><p>p（不上进|不嫁） = 3/6 = 1/2</p><p>那么根据公式：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" title="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload"></a></p><p>p (不嫁|不帅、性格不好、身高矮、不上进) = ((1/6<em>1/2</em>1<em>1/2)<em>1/2)/(1/3</em>1/3</em>7/12*1/3)</p><p><strong>很显然(1/6*1/2*1*1/2) > (1/2*1/6*1/6*1/6*1/2)</strong></p><p><strong>于是有p (不嫁|不帅、性格不好、身高矮、不上进)>p (嫁|不帅、性格不好、身高矮、不上进)</strong></p><p><strong>所以我们根据朴素贝叶斯算法可以给这个女生答案，是不嫁！！！！</strong></p><h2 id="朴素贝叶斯分类的优缺点"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类的优缺点"></a> <strong>朴素贝叶斯分类的优缺点</strong></h2><p>优点：</p><p>（1） 算法逻辑简单,易于实现</p><p>（2）分类过程中时空开销小</p><p>缺点：</p><p>理论上，<strong>朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong></p><p>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</p><h1 id="常用朴素贝叶斯分类模型"><a class="markdownIt-Anchor" href="#常用朴素贝叶斯分类模型"></a> 常用朴素贝叶斯分类模型</h1><p>依据特征值是连续还是离散选择</p><h2 id="高斯朴素贝叶斯"><a class="markdownIt-Anchor" href="#高斯朴素贝叶斯"></a> 高斯朴素贝叶斯</h2><p>Gaussian Naive Bayes是指当特征属性为连续值时，而且分布服从高斯分布，那么在计算P(x|y)的时候可以直接使用高斯分布的概率公式：假定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>∼</mo><mi>N</mi><mo stretchy="false">(</mo><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x_i |c)\sim N(\mu_{c,i},\sigma_{c,i}^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20888em;vertical-align:-0.394772em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><msub><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow></mfrac><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x_i |c)=\frac{1}{\sqrt{2π}\sigma_{c,i}}exp(-\frac{(x_i-\mu_{c,i})^2}{2\sigma_{c,i}^2})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.82764em;vertical-align:-0.6963999999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5510085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.912845em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span><span style="top:-2.872845em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.12715500000000002em;"><span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6463114999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.13124em;"><span style="top:-2.6264200000000004em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051142857142857em;"><span style="top:-2.177714285714286em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.50732em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6963999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span> ,其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\mu_{c,i},\sigma_{c,i}^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20888em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>分别是第c类样本和第i个属性上取值的均值和方差。</p><h2 id="伯努利朴素贝叶斯"><a class="markdownIt-Anchor" href="#伯努利朴素贝叶斯"></a> 伯努利朴素贝叶斯</h2><p>Bernoulli Naive Bayes是指当特征属性为连续值时，而且分布服从伯努利分布，那么在计算P(x|y)的时候可以直接使用伯努利分布的概率公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>k</mi></msub><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_k |y)=P(1|y)x_k+(1-P(1|y))(1-x_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>伯努利分布是一种离散分布，只有两种可能的结果。1表示成功，出现的概率为p；0表示失败，出现的概率为q=1-p；其中均值为E(x)=p，方差为Var(X)=p(1-p)</p><h2 id="多项式朴素贝叶斯引入平滑项"><a class="markdownIt-Anchor" href="#多项式朴素贝叶斯引入平滑项"></a> 多项式朴素贝叶斯（引入平滑项）</h2><p>Multinomial Naive Bayes是指当特征属性服从多项分布(特征是离散的形式的时候)，直接计算类别数目的占比作为先验概率和条件概率。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub><mo>+</mo><mi>α</mi></mrow><mrow><mi>N</mi><mo>+</mo><mi>k</mi><mo>∗</mo><mi>α</mi></mrow></mfrac><mspace linebreak="newline"></mspace><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi><mo separator="true">,</mo><mi>x</mi><mi>i</mi></mrow></msub><mo>+</mo><mi>α</mi></mrow><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub><mo>+</mo><msub><mi>n</mi><mi>i</mi></msub><mo>∗</mo><mi>α</mi></mrow></mfrac><mi mathvariant="normal">​</mi></mrow><annotation encoding="application/x-tex">P(y_k)=\frac{N_{yk}+\alpha}{N+k*\alpha}   \\p(x_i|y_k)=\frac{N_{yk,xi}+\alpha}{N_{yk}+n_i*\alpha}​</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.332438em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">​</span></span></span></span></span></p><p>N是总样本个数，k是总的类别个数，Nyk是类别为yk的样本个数，α为平滑值。<br><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{yk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是类别为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的样本个数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">n_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为特征属性<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的不同取值数目，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi mathvariant="normal">.</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{y.k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">.</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为类别<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中第i维特征的值为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的样本个数，α为平滑值。<br>当α=1时，称为Laplace平滑，当0<α<1时，称为Lidstone平滑，α=0时不做平滑；平滑的主要作用是可以克服条件概率为0的问题。(当存在0时，整个式子*0为0)</p><p>即，当某一特征属性为0时，我们通过分子+α来避免<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi mathvariant="normal">.</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{y.k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">.</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为0，即人为增加一样本，此时为确保公平，任一特征属性下都应该加1样本。<strong>平滑项(参考https://zhuanlan.zhihu.com/p/26329951)</strong></p><h1 id="多项式朴素贝叶斯案例理解平滑项作用举例"><a class="markdownIt-Anchor" href="#多项式朴素贝叶斯案例理解平滑项作用举例"></a> 多项式朴素贝叶斯案例理解(平滑项作用举例)</h1><p>（参考文章末尾附带PPT 13-16）</p><p><a href="/img/beiyesi/pinghua/1_ys.jpg" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/beiyesi/pinghua/1_ys.jpg" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/beiyesi/pinghua/2_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/beiyesi/pinghua/3_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/beiyesi/pinghua/4_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/beiyesi/pinghua/5_ys.png" class="lazyload"></a></p><h1 id="贝叶斯网络"><a class="markdownIt-Anchor" href="#贝叶斯网络"></a> 贝叶斯网络</h1><ol><li>把某个研究系统中涉及到的随机变量，根据是否条件独立绘制在一个有向图中，就形成了贝叶斯网络。</li><li>贝叶斯网络(Bayesian Network)，又称<strong>有向无环图模型</strong>(directed acyclic graphical model, DAG)，是一种概率图模型，根据概率图的拓扑结构，考察一组随机变量{X1,X2,…,Xn}及其N组条件概率分布(Conditional Probabililty Distributions, CPD)的性质。</li><li><strong>当多个特征属性之间存在着某种相关关系的时候，使用朴素贝叶斯算法就没法解决这类问题，那么贝叶斯网络就是解决这类应用场景的一个非常好的算法。</strong></li><li>一般而言，贝叶斯网络的有向无环图中的节点表示随机变量，可以是可观察到的变量，或隐变量，未知参数等等。连接两个节点之间的箭头代表两个随机变量之间的因果关系(也就是这两个随机变量之间非条件独立)，如果两个节点间以一个单箭头连接在一起，表示其中一个节点是“因”，另外一个是“果”，从而两节点之间就会产生一个条件概率值。</li><li>贝叶斯网络的关键方法是图模型，构建一个图模型我们需要把具有因果联系的各个变量用箭头连在一起。贝叶斯网络的有向无环图中的节点表示随机变量。连接两个节点的箭头代表此两个随机变量是具有因果关系的。</li><li>贝叶斯网络是模拟人的认知思维推理模式的，用一组条件概率以及有向无环图对不确定性因果推理关系建模</li></ol><p>最简单的一个贝叶斯网络：P(a,b,c ) = P(c|a.b)P(b|a)P(a)</p><p><a href="/img/beiyesi/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/beiyesi/4_ys.png" class="lazyload"></a></p><p>全连接贝叶斯网络：每一对节点都有边连接：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>2</mn></mrow><mi>n</mi></munderover><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_1,x_2...,x_n)=P(x_n|x_1,x_2...,x_n)...P(x_2|x_1)P(x_1) \\P(x_1,x_2...,x_n)=\prod_{i=2}^{n}P(x_i|x_1,x_2,...,x_{i-1})*P(x_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><a href="/img/beiyesi/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/beiyesi/5_ys.png" class="lazyload"></a></p><p>“正常”贝叶斯网络：<a href="/img/beiyesi/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/beiyesi/6_ys.png" class="lazyload"></a></p><ul><li></li><li>x6和x7在给定条件下独立</li><li>x1,x2,x3…x7的联合分布为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>5</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>6</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>7</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>4</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>5</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>6</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>4</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>7</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_1,x_2,x_3,x_4,x_5,x_6,x_7)=P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2,x_3) P(x_5|x_1,x_3) P(x_6|x_4) P(x_7|x_4,x_5)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li></ul><p>举例：详见文末PPT  29-30</p><h3 id="贝叶斯网络判定条件独立贝叶斯网络的结构形式"><a class="markdownIt-Anchor" href="#贝叶斯网络判定条件独立贝叶斯网络的结构形式"></a> 贝叶斯网络判定条件独立(贝叶斯网络的结构形式)</h3><p>1.head - to - head</p><p><a href="/img/beiyesi/1-1_ys.png" data-fancybox="group" data-caption="1-1_ys" class="fancybox"><img alt="1-1_ys" title="1-1_ys" data-src="/img/beiyesi/1-1_ys.png" class="lazyload"></a></p><p>在C未知的情况下，a和b被阻断(blocked)，是独立的</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><msubsup><mo>∑</mo><mi>c</mi><mrow></mrow></msubsup><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mi>c</mi><mrow></mrow></msubsup><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mrow><mo>⇒</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b,c)=P(a)P(b)P(c|a,b)\\\sum_{c}^{}{P(a,b,c)=\sum_{c}^{}{P(a)*P(b)*p(c|a,b)}}\Rightarrow P(a,b)=P(a)*P(b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">∣</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">∣</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span></p><p>2.head- to -tail</p><p><a href="/img/beiyesi/1-2_ys.png" data-fancybox="group" data-caption="1-2_ys" class="fancybox"><img alt="1-2_ys" title="1-2_ys" data-src="/img/beiyesi/1-2_ys.png" class="lazyload"></a></p><p>在C给定的条件下，a和b被阻断(blocked)是独立的:</p><p>P(a,b,c)=P(a)P(c|a)P(b|c)</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b|c)=P(a,b,c)|P(c) =\frac{P(a)P(c|a)P(b|c)}{P(c)}  = \frac{P(a,c)*P(b|c)}{P(c)}=P(a|c)*P(b|c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">a</span><span class="mclose mtight">)</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">a</span><span class="mclose mtight">)</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">b</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">a</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">b</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></p><p>c未知时，有：P(a,b,c)=P(a)*P(c|a)*P(b|c)，但无法推出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p><p>3.tail - to -tail<a href="/img/beiyesi/1-3_ys.png" data-fancybox="group" data-caption="1-3_ys" class="fancybox"><img alt="1-3_ys" title="1-3_ys" data-src="/img/beiyesi/1-3_ys.png" class="lazyload"></a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>⇒</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>∵</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">.</mi><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mspace linebreak="newline"></mspace><mo>∴</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">.</mi><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b,c)=P(c)P(b|c)P(a|c)\Rightarrow \frac{P(a,b,c)}{P(c)}=P(b|c)P(a|c)\\∵P(a.b|c) =\frac{P(a,b,c)}{P(c)}\\∴ P(a.b|c)  = P(a|c)P(b|c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.69224em;vertical-align:0em;"></span><span class="mrel amsrm">∵</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">.</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.69224em;vertical-align:0em;"></span><span class="mrel amsrm">∴</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">.</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></span></p><p>在C给定的条件下，a和b被阻断(blocked)是独立的</p><p>在c未知的时候，有：P(a,b,c)=P©*P(a|c)*P(b|c)，此时，没法得出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p><h1 id="本章节ppt与文字参考链接"><a class="markdownIt-Anchor" href="#本章节ppt与文字参考链接"></a> 本章节PPT与文字参考链接</h1><p><a href="https://zhuanlan.zhihu.com/p/26262151" target="_blank" rel="noopener">带你理解朴素贝叶斯分类算法</a></p><p><a href="https://zhuanlan.zhihu.com/p/26329951" target="_blank" rel="noopener">理解朴素贝叶斯分类的拉普拉斯平滑</a></p><p><a href="https://zhuanlan.zhihu.com/p/73415944" target="_blank" rel="noopener">贝叶斯网络，看完这篇我终于理解了(附代码)！</a></p><p><a href="/ppt/beiys.pptx">PPT下载</a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM算法总结</title>
      <link href="/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="感知机模型"><a class="markdownIt-Anchor" href="#感知机模型"></a> 感知机模型：</h1><p>感知器模型是SVM、神经网络、深度学习等算法的基础;感知器模型就是试图找到一条直线，能够把所有的“+1”类和“-1”类分隔开，如果是高维空间中，感知器模型寻找的就是一个超平面，能够把所有的二元类别分割开。感知器模型的前提是：数据是线性可分的。</p><p><a href="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" class="lazyload"></a></p><p>目标是找到一个超平面，即： <a href="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" class="lazyload"></a></p><p>感知器模型为: <a href="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" class="lazyload"></a></p><p>感知器模型正确分类（预测和实际类别一致）：yθx>0（y为实际值，θx为预测值），错误分类（预测和实际类别不一致）：yθx<0；所以我们可以定义我们的损失函数为：期望使分类错误的所有样本(k条样本)到超平面的距离之和最小。</p><p>即：<a href="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" class="lazyload"></a> (去绝对值符号，分类错误<0,分子加”—“)</p><p>简化损失函数：因为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）:</p><p>简化损失函数：因 为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存 在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）: <a href="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" class="lazyload"></a> (即 <a href="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" class="lazyload"></a> ,分子分母相抵消，模长对结果无影响)。</p><p>直接使用梯度下降法就可以对损失函数求解，不过由于这里的k是分类错误的样本点集合，不是固定的，所以我们不能使用批量梯度下降法(BGD)求解，只能使用随机梯度下降(SGD)或者小批量梯度下降(MBGD)；一般在感知器模型中使用SGD来求解。</p><hr><h1 id="svm支持向量机"><a class="markdownIt-Anchor" href="#svm支持向量机"></a> SVM(支持向量机)</h1><p>支持向量机(Support Vecor Machine, SVM)本身是一个二元分类算法，是对感知器算法模型的一种扩展，现在的SVM算法支持线性分类和非线性分类的分类应用，并且也能够直接将SVM应用于回归应用中，同时通过OvR或者OvO的方式我们也可以将SVM应用在多元分类领域中。在不考虑集成学习算法，不考虑特定的数据集的时候，在分类算法中SVM可以说是特别优秀的。</p><p><a href="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" class="lazyload"></a></p><p>在感知器模型中，算法是在数据中找出一个划分超平面，让尽可能多的数据分布在这个平面的两侧，从而达到分类的效果，但是在实际数据中这个符合我们要求的超平面是可能存在多个的。</p><p><a href="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" class="lazyload"></a></p><p>SVM思想：在感知器模型中，我们可以找到多个可以分类的超平面将数据分开，并且优化时希望所有的点(预测正确的点)都离超平面尽可能的远，但是实际上离超平面足够远的点基本上都是被正确分类的，所以这个是没有意义的；反而比较关心那些离超平面很近的点，这些点比较容易分错。所以说我们<strong>只要让离超平面比较近的点尽可能的远离这个超平面</strong>，那么我们的模型分类效果应该就会比较不错。SVM其实就是这个思想。</p><p><a href="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" class="lazyload"></a></p><p>名词概念：</p><ul><li>线性可分(Linearly Separable)：在数据集中，如果可以找出一个超平面，将两组数据分开，那么这个数据集叫做线性可分数据。</li><li>线性不可分(Linear Inseparable)：在数据集中，没法找出一个超平面，能够将两组数据分开，那么这个数据集就叫做线性不可分数据。</li><li>分割超平面(Separating Hyperplane)：将数据集分割开来的直线/平面叫做分割超平面。</li><li>支持向量(Support Vector)：离分割超平面最近的那些点叫做支持向量。</li><li>间隔(Margin)：支持向量数据点到分割超平面的距离称为间隔。</li></ul><p>支持向量到超平面的距离为：在SVM中支持向量到超平面的函数距离一般设置为1</p><p>∵ <a href="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" class="lazyload"></a></p><p>∵ <a href="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" class="lazyload"></a></p><p>∴ <a href="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" class="lazyload"></a></p><p>SVM模型是让所有的分类点在各自类别的支持向量远离超平面的一侧，同时要求支持向量尽可能的远离这个超平面，用数学公式表示如下：</p><p>W^{T}=(w_1,w_2,…,w_n)</p><p><a href="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>(s.t: 指”受限制于…“)</p><p><a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> (对偶问题）</p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>则SVM原始目标函数/损失函数为：</p><p><a href="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>将此时的目标函数和约束条件使用KKT条件转换为拉格朗日函数，从而转换为无约束的优化函数。</p><p><a href="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" class="lazyload"></a></p><p>引入拉格朗日乘子后，优化目标变成：</p><p><a href="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" class="lazyload"></a>g(x)小于等于0 当L取最大值 g(x)等于0 消去g(x) KKT条件分析</p><p>根据拉格朗日对偶化特性，将该优化目标转换为等价的对偶问题来求解，从而优化目标变成：</p><p><a href="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" class="lazyload"></a></p><p>所以对于该优化函数而言，可以先求优化函数对于w和b的极小值，然后再求解对于拉格朗日乘子β的极大值。</p><p>首先求让函数L极小化的时候w和b的取值，这个极值可以直接通过对函数L分别求w和b的偏导数得到：</p><p><a href="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" class="lazyload"></a></p><p>将求解出来的w和b带入优化函数L中，定义优化之后的函数如下：</p><p><a href="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" class="lazyload"></a></p><p>通过对w、b极小化后，我们最终得到的优化函数只和β有关，所以此时我们可以直接极大化我们的优化函数，得到β的值，从而可以最终得到w和b的值。β值的求解使用SMO算法</p><p><a href="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" class="lazyload"></a></p><p>假设存在最优解β*； 根据w、b和β的关系，可以分别计算出对应的w值和b值(一般使用所有支持向量的计算均值来作为实际的b值)；</p><p><a href="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" class="lazyload"></a></p><p>这里的(xs,ys)即支持向量，根据KKT条件中的对偶互补条件(松弛条件约束)，支持向量必须满足一下公式：</p><p><a href="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" class="lazyload"></a></p><p>2.线性可分SVM算法流程：</p><ul><li>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</li><li>构造约束优化问题；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" class="lazyload"></a></p><p>使用SMO算法求出上式优化中对应的最优解β*；</p><ul><li>找出所有的支持向量集合S;</li></ul><p><a href="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" class="lazyload"></a></p><ul><li>更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" class="lazyload"></a></p><ul><li>构建最终的分类器；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" class="lazyload"></a></p><h2 id="线性可分svm总结"><a class="markdownIt-Anchor" href="#线性可分svm总结"></a> 线性可分SVM总结</h2><p>\1. 要求数据必须是线性可分的；</p><p>\2. 纯线性可分的SVM模型对于异常数据的预测可能会不太准；</p><p>\3. 对于线性可分的数据，线性SVM分类器的效果非常不错。</p><h1 id="svm的软间隔模型"><a class="markdownIt-Anchor" href="#svm的软间隔模型"></a> SVM的软间隔模型</h1><p>线性可分SVM中要求数据必须是线性可分的，才可以找到分类的超平面，但是有的时候线性数据集中存在少量的异常点，由于这些异常点导致了数据集不能够线性划分；直白来讲就是：正常数据本身是线性可分的，但是由于存在异常点数据，导致数据集不能够线性可分；</p><p><a href="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" class="lazyload"></a></p><p>如果线性数据中存在异常点导致没法直接使用SVM线性分割模型的时候，我们可以通过引入软间隔的概念来解决这个问题；</p><p>硬间隔：可以认为线性划分SVM中的距离度量就是硬间隔，在线性划分SVM中，要求函数距离一定是大于1的，最大化硬间隔条件为：</p><p><a href="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" class="lazyload"></a></p><p>软间隔：SVM对于训练集中的每个样本都引入一个松弛因子(ξ)，使得函数距离加上松弛因子后的值是大于等于1；这表示相对于硬间隔，对样本到超平面距离的要求放松了。(引入松弛因子(ξ))</p><p><a href="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" class="lazyload"></a></p><p>松弛因子(ξ)越大，表示样本点离超平面越近，如果松弛因子大于1，那么表示允许该样本点分错，所以说加入松弛因子是有成本的，过大的松弛因子可能会导致模型分类错误，所以最终的目标函数就转换成为：</p><p><a href="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" class="lazyload"></a>注：函数中的C&amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;0是惩罚参数，是一个超参数，类似L1/L2 norm的参数；C越大表示对误分类的惩罚越大，也就是越不允许存在分错的样本；C越小表示对误分类的惩罚越小， 也就是表示允许更多的分错样本存在；C值的给定需要调参。</p><p>同线性可分SVM，根据KKT条件构造软间隔最大化的约束问题对应的拉格朗日函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" class="lazyload"></a></p><p>从而将我们的优化目标函数转换为：</p><p><a href="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" class="lazyload"></a></p><p>优化目标同样满足KKT条件，所以使用拉格朗日对偶将优化问题转换为等价的对偶问题：</p><p><a href="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" class="lazyload"></a></p><p>先求优化函数对于w、b、ξ的极小值，这个可以通过分别对优化函数L求w、b、ξ的偏导数得，从而可以得到w、b、ξ关于β和μ之间的关系。</p><p><a href="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" class="lazyload"></a></p><p>将w、b、ξ的值带入L函数中，就可以消去优化函数中的w、b、ξ，定义优化之后的函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" class="lazyload"></a></p><p>最终优化后的目标函数/损失函数和线性可分SVM模型基本一样，除了约束条件不同而已， 也就是说也可以使用SMO算法来求解。</p><p><a href="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" class="lazyload"></a></p><ul><li>在硬间隔最大化的时候，支持向量比较简单，就是离超平面的函数距离为1的样本点就是支持向量。</li><li>在软间隔中，根据KKT条件中的对偶互补条件: β(1-ξ-y(wx+b))=0和μ(-ξ)=0，以及C-β-μ=0；从而有：</li><li>当0<βi≤C的时候，并且ξi=0的样本点均是支持向量(即所有的0<βi<c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑 第二个kkt条件)< li></c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑></li><li>当0<βi<c对应的样本就是支持向量。< li></c对应的样本就是支持向量。<></li><li>注：软间隔和硬间隔中的支持向量的规则是一样的；</li><li><a href="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" class="lazyload"></a> 则x1是支持变量</li></ul><p><a href="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型算法流程"><a class="markdownIt-Anchor" href="#svm的软间隔模型算法流程"></a> SVM的软间隔模型算法流程：</h2><p>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</p><p>step 1:选择一个惩罚系数C>0，构造约束优化问题；</p><p><a href="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" class="lazyload"></a></p><ul><li>Step2:使用SMO算法求出上式优化中对应的最优解β*；</li><li>step3:找出所有的支持向量集合S;</li></ul><p><a href="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" class="lazyload"></a></p><ul><li>step4:更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" class="lazyload"></a></p><ul><li>step5:构建最终的分类器</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型总结"><a class="markdownIt-Anchor" href="#svm的软间隔模型总结"></a> SVM的软间隔模型总结</h2><ul><li>\1. 可以解决线性数据中携带异常点的分类模型构建的问题；</li><li>\2. 通过引入惩罚项系数(松弛因子)，可以增加模型的泛化能力，即鲁棒性；</li><li>\3. 如果给定的惩罚项系数C越小，表示在模型构建的时候，就允许存在越多的分类错误的样本， 也就表示此时模型的准确率会比较低；如果惩罚项系数越大，表示在模型构建的时候，就越不允许存在分类错误的样本，也就表示此时模型的准确率会比较高。</li></ul><h1 id="非线性可分svm"><a class="markdownIt-Anchor" href="#非线性可分svm"></a> 非线性可分SVM</h1><p>不管是线性可分SVM还是加入惩罚系数后的软间隔线性可分SVM其实都要求数据本身是线性可分的，对于完全不可以线性可分的数据，这两种算法模型就没法解决这个问题了</p><p><a href="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" class="lazyload"></a></p><p>结合多项式回归在处理非线性可分数据时候的作用，在SVM的线性不可分的数据上，如果将数据映射到高维空间中，那么数据就会变成线性可分的，从而就可以使用线性可分SVM模型或者软间隔线性可分SVM模型。也就是说，对于线性不可分SVM模型来讲，重点在于低维特征数据到高维特征数据之间的映射。</p><p>定义一个从低维特征空间到高维特征空间的映射函数Ф，非线性可分SVM的优化目标函数：</p><p><a href="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" class="lazyload"></a></p><p>可以看到的是，只需要将原来的低维空间中的两个向量的点积转换为高维空间中两个向量的点积即可。</p><p><strong>问题</strong>：这样一来问题就解决了吗？似乎是的：拿到非线性数据，就找一个映射，然后一股脑把原来的数据映射到新空间中，再做线性 SVM 即可。不过事实上没有这么简单！其实刚才的方法稍想一下就会发现有问题：在最初的例子里做了一个二阶多项式的转换，对一个二维空间做映射，选择的新空间是原始空间的所有一阶和二阶的组合，得到了5个维度；如果原始空间是三维，那么我们会得到9维的新空间；如果原始空间是n维，那么我们会得到一个n(n+3)/2维的新空间**；这个数目是呈爆炸性增长的，这给计算带来了非常大的困难，而且如果遇到无穷维的情况，就根本无从计算。**</p><p><strong>2.核函数</strong></p><p>假设函数Ф是一个从低维特征空间到高维特征空间的一个映射，那么如果存在函数K(x,z), 对于任意的低维特征向量x和z，都有：</p><p><a href="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" class="lazyload"></a></p><p>称函数K(x,z)为核函数(kernal function)：在低维空间上的计算值等价于向量做维度扩展后的点乘的结果。 核函数在解决线性不可分问题的时候，采取的方式是：使用低维特征空间上的计算来避免在高维特征空间中向量内积的恐怖计算量；也就是说此时SVM模型可以应用在高维特征空间中数据可线性分割的优点，同时又避免了引入这个高维特征空间恐怖的内积计算量。</p><p>即：用低维空间中少的内积的计算量来让模型具有高维空间中的线性可分的优点。</p><p><strong>例</strong>：，设两个向量<a href="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" class="lazyload"></a> 和<a href="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" class="lazyload"></a>，而即是到前面说的五维空间的映射，因此映射过后的内积为：</p><p><a href="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" class="lazyload"></a></p><p>而同时我们可以发现有一下公式</p><p><a href="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" class="lazyload"></a></p><p>可以发现两者之间非常相似，所以我们只要乘上一个相关的系数，就可以让这两个式子的值相等，这样不就将五维空间的一个内积转换为两维空间的内积的运算。</p><p>现有有两个两维的向量，进行二阶多项式扩展，然后进行内积计算，这个时候映射高维后计算的计算量为：11次乘法+4次加法；采用近似计算的计算量为：3次乘法+2次加法；采用加系数后的近似计算的计算量为：4次乘法+2次加法；</p><p><a href="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" class="lazyload"></a></p><h1 id="核函数总结"><a class="markdownIt-Anchor" href="#核函数总结"></a> 核函数总结</h1><p>\1. 核函数可以自定义；核函数必须是正定核函数，即Gram矩阵是半正定矩阵；</p><p>\2. 核函数的价值在于它的效果相当于将特征进行从低维到高维的转换，但核函数它是在低维空间上的计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算；</p><p>\3. 通过核函数，可以将非线性可分的数据转换为线性可分数据；</p><p><a href="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" class="lazyload"></a></p><h2 id="svr"><a class="markdownIt-Anchor" href="#svr"></a> SVR</h2><p>做回归用，了解即可</p><h1 id="坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"><a class="markdownIt-Anchor" href="#坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"></a> 坐标下降（上升）法原理(搬运自<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/u010626937/article/details/75044343">https://blog.csdn.net/u010626937/article/details/75044343</a>)</h1><p>假设要求解下面的优化问题：</p><p><a href="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" class="lazyload"></a></p><p>在这里，我们需要求解m个变量αi，一般来说是通过梯度下降（这里是求最大值，所以应该叫上升）等算法来求解，每一次迭代对所有m个变量αi也就是α向量进行一次性优化。（这里指的是一个向量的所有分量）。通过每次迭代中的误差调整α向量中每个元素的值。而坐标上升法（坐标上升与坐标下降可以看做是一对，坐标上升是用来求解max最优化问题，坐标下降用于求min最优化问题）的思想是每次迭代只调整一个变量αi的值，其他变量的值在这次迭代中固定不变。(这里指的是一个向量中的一个分量)。</p><p><a href="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" class="lazyload"></a></p><p>最里面语句的意思是固定除αi之外的所有αj(i不等于j)，这时W可看作只是关于αi的函数，那么直接对αi求导优化即可。这里我们进行最大化求导的顺序i是从1到m，可以通过更改优化顺序来使W能够更快地增加并收敛。如果W在内循环中能够很快地达到最优，那么坐标上升法会是一个很高效的求极值方法。</p><p>用个二维的例子来说明下坐标下降法：我们需要寻找f(x,y)=x2+xy+y2的最小值处的(x*, y*)，也就是下图的F*点的地方.</p><p><a href="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" class="lazyload"></a></p><p>假设我们初始的点是A（图是函数投影到xoy平面的等高线图，颜色越深值越小），我们需要达到F<em>的地方。那最快的方法就是图中黄色线的路径，一次性就到达了，其实这个是牛顿优化法，但如果是高维的话，这个方法就不太高效了（因为需要求解矩阵的逆，这个不在这里讨论）。我们也可以按照红色所指示的路径来走。从A开始，先固定x，沿着y轴往让f(x, y)值减小的方向走到B点，然后固定y，沿着x轴往让f(x, y)值减小的方向走到C点，不断循环，直到到达F</em>。反正每次只要我们都往让f(x, y)值小的地方走就行了，这样脚踏实地，一步步走，每一步都使f(x, y)慢慢变小，总有一天，皇天不负有心人的。到达F*也是时间问题。到这里你可能会说，这红色线比黄色线贫富差距也太严重了吧。因为这里是二维的简单的情况嘛。如果是高维的情况，而且目标函数很复杂的话，再加上样本集很多，那么在梯度下降中，目标函数对所有αi求梯度或者在牛顿法中对矩阵求逆，都是很耗时的。这时候，如果W只对单个αi优化很快的时候，坐标下降法可能会更加高效。</p><p>数学例题讲解</p><p>下面以如下的优化问题为例：</p><p><a href="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" class="lazyload"></a></p><p>在迭代的过程中，每次固定x2更新x1，在确定了x1的条件下，固定x1，更新x2。即每次迭代求解：</p><p><a href="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" class="lazyload"></a></p><p>也即求解</p><p><a href="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" class="lazyload"></a></p><p>，假设我们首先固定x2,来更新x1：</p><p><a href="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" class="lazyload"></a></p><p>再固定x1，得到：</p><p><a href="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" class="lazyload"></a></p><p>不断按照上述的过程，直到算法收敛。</p><h1 id="七-smo可略过"><a class="markdownIt-Anchor" href="#七-smo可略过"></a> 七、SMO（可略过）</h1><p>序列最小优化算法(Sequential minimal optimization, SMO)是一种用于解决SVM训练过程中所产生的优化问题的算法。 于1998年由John Platt发明。SMO的思想类似坐标上升算法，我们需要优化一系列的αα的值，我们每次选择尽量少的 <a href="https://www.zhihu.com/equation?tex=%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Calpha" class="lazyload"></a> 来优化，不断迭代直到函数收敛到最优值。</p><p>梯度提升算法采用增量完成迭代，SMO利用自身完成迭代，如 <a href="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" class="lazyload"></a> 。</p><p>目标函数：</p><p><a href="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" class="lazyload"></a></p><p>假定存在一个β*=(β1,β2,…,βm)是我们最终的最优解，那么根据KKT条件我们可以计算出w和b的最优解，如下：</p><p><a href="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" class="lazyload"></a></p><p>进而我们可以得到最终的分离超平面为:</p><p><a href="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" class="lazyload"></a></p><p>拉格朗日乘子法和KKT的对偶互补条件为：</p><p><a href="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" class="lazyload"></a></p><p>β、μ和C之间的关系为：</p><p><a href="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" class="lazyload"></a></p><p>根据这个对偶互补条件，我们有如下关系式：</p><p><a href="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" class="lazyload"></a></p><p>也就是说我们找出的最优的分割超平面必须满足下列的目标条件(g(x)):</p><p><a href="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" class="lazyload"></a></p><p>拉格朗日对偶化要求的两个限制的初始条件为：</p><p><a href="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" class="lazyload"></a></p><p>从而可以得到解决问题的思路如下：</p><ul><li>首先，初始化后一个β值，让它满足对偶问题的两个初始限制条件；</li><li>然后不断优化这个β值，使得由它确定的分割超平面满足g(x)目标条件；而且在优化过程中，始终保证β值满足初始限制条件。</li><li>备注：这个求解过程中，和传统的思路不太一样，不是对目标函数求最小值，而是让g(x)目标条件尽可能的满足。</li></ul><p>在这样一个过程中，到底如何优化这个β值呢？？？整理可以发现β值的优化必须遵循以下两个基本原则：</p><ul><li>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</li><li>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于1的，yg(x)结果越是小于1就表示违反g(x)目标条件就越多。</li></ul><p>或者换一种思路来理解，因为目标函数中存在m个变量，直接优化比较难，利用启发式的方法/EM算法的思想，每次优化的时候，只优化两个变量，将其它的变量看成常数项，这样SMO算法就将一个复杂的优化算法转换为一个比较简单的两变量优化问题了。</p><p><a href="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" class="lazyload"></a></p><p>认为β1、β2是变量，其它β值是常量，从而将目标函数转换如下(C是常数项)：</p><p><a href="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" class="lazyload"></a></p><p>由于 <a href="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" class="lazyload"></a> ,并且y2=1，也就是我们使用β2来表示β1的值：</p><p>将上式带入目标优化函数，就可以消去β1，从而只留下仅仅包含β2的式子。</p><p><a href="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" class="lazyload"></a>V1,V2</p><p><a href="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" class="lazyload"></a>消去beta1</p><p><a href="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" class="lazyload"></a></p><p>考虑β1和β2的取值限定范围，假定新求出来的β值是满足我们的边界限制的，即如下所示：</p><p><a href="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" class="lazyload"></a></p><p>当y1=y2的时候，β1+β2=k； 由于β的限制条件，我们可以得到：</p><p><a href="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" class="lazyload"></a></p><p><a href="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" class="lazyload"></a></p><p>可以发现SMO算法中，是选择两个合适的β变量做迭代，其它变量作为常量来进行优化的一个过程，那么这两个变量到底怎么选择呢???</p><p>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</p><p>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于等于1的，越是小于1违反g(x)目标条件就越多。</p><p>SMO算法在选择第一个β变量的时候，需要选择在训练集上违反KKT条件最严重的样本点。一般情况下，先选择0<β<c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。< p></c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。<></p><p><a href="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" class="lazyload"></a></p><p>在选择第一个变量β1后，在选择第二个变量β2的时候，希望能够按照优化后的β1和β2有尽可能多的改变来选择，也就是说让|E1-E2|足够的大，当E1为正的时候，选择最小的Ei作为E2；当E1为负的时候，选择最大的Ei作为E2。</p><p>备注：如果选择的第二个变量不能够让目标函数有足够的下降，那么可以通过遍历所有样本点来作为β2，直到目标函数有足够的下降，如果都没有足够的下降的话，那么直接跳出循环，重新选择β1；</p><p>在每次完成两个β变量的优化更新之后，需要重新计算阈值b和差值Ei。当0<β1new<c时，有：< p></c时，有：<></p><p><a href="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" class="lazyload"></a></p><p>化简可得：</p><p><a href="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" class="lazyload"></a></p><p>同样的当β2的取值为: 0<β2<c的时候，我们也可以得到< p></c的时候，我们也可以得到<></p><p><a href="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" class="lazyload"></a></p><p>最终计算出来的b为：</p><p><a href="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" class="lazyload"></a></p><p>当更新计算阈值b后，就可以得到差值Ei为：</p><p><a href="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一、1</title>
      <link href="/2020/01/06/%E4%B8%80%E3%80%811/"/>
      <url>/2020/01/06/%E4%B8%80%E3%80%811/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>一、1.感知机模型：感知器模型是SVM、神经网络、深度学习等算法的基础;感知器模型就是试图找到一条直线，能够把所有的“+1”类和“-1”类分隔开，如果是高维空间中，感知器模型寻找的就是一个超平面，能够把所有的二元类别分割开。感知器模型的前提是：数据是线性可分的。![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/v2-624de9659125f370026c972f21dcbb69_r.jpg)<a href="data:image/jpeg;base64,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" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="data:image/jpeg;base64,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" class="lazyload"></a>目标是找到一个超平面，即： [![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdb2.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation)感知器模型为: [![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdc1.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation(1))感知器模型正确分类（预测和实际类别一致）：yθx>0（y为实际值，θx为预测值），错误分类（预测和实际类别不一致）：yθx<0；所以我们可以定义我们的损失函数为：期望使分类错误的所有样本(k条样本)到超平面的距离之和最小。即：[![img](file:///C:/Users/52664/AppData/Local/Temp/enhtmlclip/YX01b7fdd1.png)](file://C:\Users\52664\AppData\Local\Temp\enhtmlclip\equation(2)) (去绝对值符号，分类错误<0,分子加”—“)</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/01/06/hello-world/"/>
      <url>/2020/01/06/hello-world/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
