<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>改进 AdaBoost 算法在信贷不平衡分类 -读后感</title>
      <link href="/2020/05/13/%E6%94%B9%E8%BF%9B-AdaBoost-%E7%AE%97%E6%B3%95%E5%9C%A8%E4%BF%A1%E8%B4%B7%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%88%86%E7%B1%BB--%E8%AF%BB%E5%90%8E%E6%84%9F/"/>
      <url>/2020/05/13/%E6%94%B9%E8%BF%9B-AdaBoost-%E7%AE%97%E6%B3%95%E5%9C%A8%E4%BF%A1%E8%B4%B7%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%88%86%E7%B1%BB--%E8%AF%BB%E5%90%8E%E6%84%9F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>为了控制信贷风险，需要有效的方法来正确识别信贷违约用户，即解决信贷分<br>类问题。然而，大部分信贷数据集为信贷不平衡数据集，因而控制信贷风险的关键在于解决信贷不平衡分类问题。</p><h1 id="研究背景与研究意义"><a class="markdownIt-Anchor" href="#研究背景与研究意义"></a> 研究背景与研究意义</h1><h2 id="研究背景"><a class="markdownIt-Anchor" href="#研究背景"></a> 研究背景</h2><pre><code>对于信贷风险的研究，重点在于通过合理有效的技术手段来判断某用户的某笔消费信贷业务是否会发生信贷违约，即对信贷违约事件发生的可能性进行度量。银行等相关机构在审批消费信贷业务时正需要这样的技术手段来审核用户的信用，从而降低或规避信贷风险。因此，为了正确识别出信贷违约用户，需要对用户进行分类，即构建有效的分类模型来处理信贷分类问题。实际上，银行等相关机构对用户进行分类时往往是将其归为**信贷履约用户或者信贷违约用户**，因而分类模型解决的主要是二分类问题，即**本文所指的信贷分类问题特指二分类问题。**</code></pre><p>​分类模型作为一种能够根据用户提供的信息对其信贷违约情况做出预测的工具，其构建需要依赖已有的信贷数据集，然而目前大部分信贷数据集属于<strong>信贷不平衡数据集</strong>。信贷不平衡数据集指的是数据集中能够及时还款的信贷履约用户数远远大于不能按时还款的信贷违约用户数。基于以上阐述，对于信贷分类问题的研究可以延伸为对于信贷不平衡分类问题的研究，即如何利用信贷不平衡数据集来构建分类模型，从而实现对用户的分类。分类模型作为一种能够根据用户提供的信息对其信贷违约情况做出预测的工具，其构建需要依赖已有的信贷数据集，然而目前大部分信贷数据集属于信贷不平衡数据集。信贷不平衡数据集指的是数据集中能够及时还款的信贷履约用户数远远大于不能按时还款的信贷违约用户数。基于以上阐述，对于信贷分类问题的研究可以延伸为对于信贷不平衡分类问题的研究，即如何利用信贷不平衡数据集来构建分类模型，从而实现对用户的分类。</p><p>​在传统 AdaBoost 算法中，弱分类器及其加权系数的多样性得不到保证，同时对不同类样本采取相同的样本权重更新策略，因而传统 AdaBoost算法不适用于信贷不平衡数据集的建模。因此，为了解决一系列的不平衡分类问题，基于采样和基于代价敏感的 AdaBoost 算法不断被提出，其中 SMOTEBoost 算法、RUSBoost算法以及 AdaCost 算法是较为经典的三种算法，但是在实际问题中，这三种算法还是存在一定的缺陷。</p><h2 id="研究意义"><a class="markdownIt-Anchor" href="#研究意义"></a> 研究意义</h2><p>​本文在对信贷分类问题进行研究时，重点关注了信贷数据集的不平衡性，认为信贷不平衡数据集会对分类模型造成不良影响。</p><p>​本文利用采样和代价敏感提出了一种新的改进 AdaBoost 算法，并详细论述了该算法的改进思路。本文的研究不仅丰富了数据挖掘理论模型，还拓宽9AdaBoost 算法的改进策略。</p><p>​本文利用 AdaBoost 算法来进行建模与分析，并将分类模型的重点放在信贷违约用户的识别上。本文可以帮助银行等相关机构筛选出不能按时归还本金和支付利息的用户，以便于及时掌握用户的信贷违约情况，从而降低在发生信贷违约时需要承担的损失，进而降低或规避信贷风险，节约运营成本。</p><h1 id="研究内容与研究方法12"><a class="markdownIt-Anchor" href="#研究内容与研究方法12"></a> 研究内容与研究方法<a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.2.png" data-fancybox="group" data-caption="1.2" class="fancybox"><img alt="1.2" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.2.png" class="lazyload" title="1.2"></a></h1><p>第一，以往的学者和研究人员在对信贷不平衡数据集进行建模分析时，大部分选择<br>从数据层面出发，即利用不同的采样方法来降低信贷不平衡数据集的不平衡比例。本文则选择从算法层面出发，在深入分析 AdaBoost 算法原理的基础上，基于采样和代价敏感对算法作出了改进，使得改进 AdaBoost 算法更加适用于信贷不平衡数据集，以期达到进一步提高信贷违约用户识别精度的目的。<br>第二，以往的学者和研究人员在 AdaBoost 算法的研究上，大部分选择直接对样本<br>权重更新过程作出修改。本文则首先将采样方法融入到 AdaBoost 算法中，再利用代价敏感思想改变算法的损失函数、样本权重的定义以及初始化样本权重，以此达到间接修改样本权重更新过程的目的。因而本文在 AdaBoost 算法的改进策略上实现了创新，提出了更加适用于不平衡分类问题的改进 AdaBoost 算法。</p><h1 id="文献综述"><a class="markdownIt-Anchor" href="#文献综述"></a> 文献综述</h1></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Boosting算法 AdaBoost 算法</title>
      <link href="/2020/05/12/Boosting%E7%AE%97%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E7%AB%8B%E7%AE%97%E6%B3%95-AdaBoost-%E7%AE%97%E6%B3%95/"/>
      <url>/2020/05/12/Boosting%E7%AE%97%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E7%AB%8B%E7%AE%97%E6%B3%95-AdaBoost-%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="bagging"><a class="markdownIt-Anchor" href="#bagging"></a> Bagging</h1><p>Bagging 指的是一种叫做「Bootstrap Aggregating」（自助聚合）的技术。其实质是选取 T 个 bootstrap 样本，在每个样本安装一个分类器，然后并行训练模型。通常，在随机森林中，决策树是并行训练的。然后，将所有分类器的结果平均化，得到一个 bagging 分类器</p><p>该过程可以通过以下方式来说明。让我们考虑 3 个分类器，它们生成一个分类结果，该结果可能是对的也可能是错的。如果我们绘制 3 个分类器的结果，会有一些区域代表分类器的结果是错误的。在下图中，这样的区域用红色表示：</p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.2.jpg" data-fancybox="group" data-caption="2.2" class="fancybox"><img alt="2.2" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.2.jpg" class="lazyload" title="2.2"></a></p><p>这个示例可以很好地起到说明作用，其中有一个分类器的结果是错误的，而另外两个分类器的结果是正确的。通过对分类器进行投票，你可以获得很高的分类准确率。但正如你可能会猜到的那样，bagging 机制有时并不能很好地起作用，这时所有的分类器都会在同一个区域内获得错误的分类结果。<a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.3.jpg" data-fancybox="group" data-caption="2.3" class="fancybox"><img alt="2.3" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.3.jpg" class="lazyload" title="2.3"></a></p><p>出于这个原因，对 boosting 方法背后的直观想法是：</p><ul><li>我们需要串行训练模型，而不是并行训练。</li><li>每个模型需要重点关注之前的分类器表现不佳的地方。</li></ul><h1 id="boosting-简介"><a class="markdownIt-Anchor" href="#boosting-简介"></a> <strong>Boosting 简介</strong></h1><h2 id="adaboost"><a class="markdownIt-Anchor" href="#adaboost"></a> AdaBoost：</h2><p>上述想法可以诠释为：</p><ul><li><p>在整个数据集上训练模型 h1</p></li><li><p>对 h1 表现较差的区域的数据加权，并在这些数据上训练模型 h2</p></li><li><p>对 h1 ≠ h2 的区域的数据加权重，并在这些数据上训练模型 h3</p></li><li><p>…</p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.1.png" data-fancybox="group" data-caption="2.1" class="fancybox"><img alt="2.1" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.1.png" class="lazyload" title="2.1"></a></p></li></ul><p>上图中被放大的点是被加权的样本，样本加权后，在下一次的学习中就会收到更多的关注。</p><p>也就是说提升算法对分类错误的样本更为关注，通过改变错误样本所占的权值来改变分类边界，从而一步步提升算法的准确度。</p><p>Boosting 方法会随着时间的推移，通过调整误差度量来训练一系列低性能算法，称之为弱学习器。弱学习器指的是那些误差率略低于 50% 的算法，如下图所示：</p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.4.jpg" data-fancybox="group" data-caption="2.4" class="fancybox"><img alt="2.4" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/2.4.jpg" class="lazyload" title="2.4"></a></p><h2 id="adaboost算法的直观理解"><a class="markdownIt-Anchor" href="#adaboost算法的直观理解"></a> <strong>Adaboost算法的直观理解</strong></h2><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.3.png" data-fancybox="group" data-caption="3.3" class="fancybox"><img alt="3.3" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.3.png" class="lazyload" title="3.3"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.4.png" data-fancybox="group" data-caption="3.4" class="fancybox"><img alt="3.4" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.4.png" class="lazyload" title="3.4"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.5.png" data-fancybox="group" data-caption="3.5" class="fancybox"><img alt="3.5" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.5.png" class="lazyload" title="3.5"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.6.png" data-fancybox="group" data-caption="3.6" class="fancybox"><img alt="3.6" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.6.png" class="lazyload" title="3.6"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.7.png" data-fancybox="group" data-caption="3.7" class="fancybox"><img alt="3.7" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.7.png" class="lazyload" title="3.7"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.8.png" data-fancybox="group" data-caption="3.8" class="fancybox"><img alt="3.8" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.8.png" class="lazyload" title="3.8"></a></p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.9.png" data-fancybox="group" data-caption="3.9" class="fancybox"><img alt="3.9" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.9.png" class="lazyload" title="3.9"></a></p><p><strong>融合分类器</strong></p><p>自然而然地，下一步就应该是将这些分类器融合成一个符号分类器。根据某个数据点处于分割线的哪一侧，将其分类为 0 或 1。该过程可以通过如下方式实现：<a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.0.jpg" data-fancybox="group" data-caption="3.0" class="fancybox"><img alt="3.0" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.0.jpg" class="lazyload" title="3.0"></a></p><p>你发现了可能提升分类器性能的方法吗？</p><p>通过为每个分类器加权，可以避免赋予不同的分类器相同的重要性。<a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.1.jpg" data-fancybox="group" data-caption="3.1" class="fancybox"><img alt="3.1" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.1.jpg" class="lazyload" title="3.1"></a></p><h1 id="随机森林"><a class="markdownIt-Anchor" href="#随机森林"></a> 随机森林</h1><p><a href="https://blog.csdn.net/qq_34106574/article/details/82016442" target="_blank" rel="noopener">https://blog.csdn.net/qq_34106574/article/details/82016442</a></p><p>随机森林中有许多的分类树。我们要将一个输入样本进行分类，我们需要将输入样本输入到每棵树中进行分类。打个形象的比喻：森林中召开会议，讨论某个动物到底是老鼠还是松鼠，每棵树都要独立地发表自己对这个问题的看法，也就是每棵树都要投票。该动物到底是老鼠还是松鼠，要依据投票情况来确定，获得票数最多的类别就是森林的分类结果。森林中的每棵树都是独立的，99.9%不相关的树做出的预测结果涵盖所有的情况，这些预测结果将会彼此抵消。少数优秀的树的预测结果将会超脱于芸芸“噪音”，做出一个好的预测。将若干个弱分类器的分类结果进行投票选择，从而组成一个强分类器，这就是随机森林bagging的思想（关于bagging的一个有必要提及的问题：bagging的代价是不用单棵决策树来做预测，具体哪个变量起到重要作用变得未知，所以bagging改进了预测准确率但损失了解释性。</p><p>有了树我们就可以分类了，但是森林中的每棵树是怎么生成的呢？</p><p>每棵树的按照如下规则生成：</p><p>1）如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；</p><p>从这里我们可以知道：每棵树的训练集都是不同的，而且里面包含重复的训练样本（理解这点很重要）。</p><p><strong>为什么要随机抽样训练集？（add @2016.05.28）</strong></p><p>如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的，这样的话完全没有bagging的必要；</p><p><strong>为什么要有放回地抽样？*<em>（add @2016.05.28）*</em></strong></p><p>我理解的是这样的：如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是"有偏的"，都是绝对"片面的"（当然这样说可能不对），也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决，这种表决应该是"求同"，因此使用完全不同的训练集来训练每棵树这样对最终分类结果是没有帮助的，这样无异于是"盲人摸象"。</p><p>2）如果每个样本的特征维度为M，指定一个常数m<<m，随机地从m个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的；< p></m，随机地从m个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的；<></p><p>3）每棵树都尽最大程度的生长，并且没有剪枝过程。</p><p>一开始我们提到的随机森林中的“随机”就是指的这里的两个随机性。两个随机性的引入对随机森林的分类性能至关重要。由于它们的引入，使得随机森林不容易陷入过拟合，并且具有很好得抗噪能力（比如：对缺省值不敏感）。</p><p><strong>随机森林分类效果（错误率）与两个因素有关：</strong></p><ul><li>森林中任意两棵树的相关性：相关性越大，错误率越大；</li><li>森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。</li></ul><p>减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。</p><p>5 袋外错误率（oob error）</p><p>上面我们提到，构建随机森林的关键问题就是如何选择最优的m，要解决这个问题主要依据计算袋外错误率oob error（out-of-bag error）。</p><p>随机森林有一个重要的优点就是，没有必要对它进行交叉验证或者用一个独立的测试集来获得误差的一个无偏估计。它可以在内部进行评估，也就是说在生成的过程中就可以对误差建立一个无偏估计。</p><p>我们知道，在构建每棵树时，我们对训练集使用了不同的bootstrap sample（随机且有放回地抽取）。所以对于每棵树而言（假设对于第k棵树），大约有1/3的训练实例没有参与第k棵树的生成，它们称为第k棵树的oob样本。</p><p>而这样的采样特点就允许我们进行oob估计，它的计算方式如下：</p><p><strong>（note：以样本为单位）</strong></p><p>1）对每个样本，计算它作为oob样本的树对它的分类情况（约1/3的树）；</p><p>2）然后以简单多数投票作为该样本的分类结果；</p><p>3）最后用误分个数占样本总数的比率作为随机森林的oob误分率。</p><p>oob误分率是随机森林泛化误差的一个无偏估计，它的结果近似于需要大量计算的k折交叉验证。</p><h1 id="梯度提升迭代决策树gbdt"><a class="markdownIt-Anchor" href="#梯度提升迭代决策树gbdt"></a> <strong>梯度提升迭代决策树GBDT</strong></h1><p>GBDT也是Boosting算法的一种，但是和AdaBoost算法不同；区别如下：</p><p>AdaBoost算法是利用前一轮的弱学习器的误差来更新样本权重值，然后一轮一轮</p><p>的迭代；GBDT也是迭代，但是GBDT要求弱学习器必须是回归CART模型，而且</p><p>GBDT在模型训练的时候，是要求模型预测的样本损失尽可能的小。</p><p>• 备注：所有GBDT算法中，底层都是回归树。</p><p>GBDT直观理解</p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.2.png" data-fancybox="group" data-caption="3.2" class="fancybox"><img alt="3.2" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/3.2.png" class="lazyload" title="3.2"></a></p><p>GBDT的核心就在于：<strong>每一棵树学的是之前所有树结论和的残差</strong>，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学习。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于大数据的互联挖金融欺诈行为识别研究 阅读</title>
      <link href="/2020/05/12/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BA%92%E8%81%94%E6%8C%96%E9%87%91%E8%9E%8D%E6%AC%BA%E8%AF%88%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB%E7%A0%94%E7%A9%B6-%E9%98%85%E8%AF%BB/"/>
      <url>/2020/05/12/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BA%92%E8%81%94%E6%8C%96%E9%87%91%E8%9E%8D%E6%AC%BA%E8%AF%88%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB%E7%A0%94%E7%A9%B6-%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="绪论"><a class="markdownIt-Anchor" href="#绪论"></a> 绪论</h1><p>传统金融中，是以房产、固定资产为抵押物的抵押贷款，以及以应收账款、订单抵押的供应链金融 。而互联网金融中，为达到快速征信，快速办理，摆脱传统金融繁杂的手续过程，更多的是以个人信用为抵押的网络信用贷款。因此服务效率由低到高不断的提升，但是同时也对风险控制提出了更高的挑战、P2P网贷的最大特色是以个人信用为抵押，但事物都具有两面性，这也是该行业所面临的风险点。</p><p>当前互联网金融行业中，很多创新业务针对的客户源相对陌生，甚至未曾谋<br>面。基于目前国内尚未建立完善的个人信用征集、评价、跟踪体系，信用风险在<br>行业的发展过程中一直备受关注。</p><p>在互联网金融行业的信用风险中，欺诈行为占据很大一部分。甚至在市场中<br>出现了专门办理”欺诈“行为的代办公司。他们对网贷平台的审核流程十分熟悉，<br>专门对信用资质较差的用户提高信息包装、蓄意造假来帮助他们进行骗贷。所以<br>传统的征信模式很难在信息搜取时进行甄别。</p><h1 id="基于大数据的创新征信模式"><a class="markdownIt-Anchor" href="#基于大数据的创新征信模式"></a> 基于大数据的创新征信模式</h1><p>前世界最流行的美国个人信用消费评分 FICO 模型即利用大数据手段产生的。以当前最成熟的美国 FICO 信用评分体系为例，在其计算得到消费者最终信用评分前，会利用其 100 余万的数据样本，对客户信用资质、还款能力、道德品行等方面进行量化描述，利用大数据对用户充分了解，对这些指标加权计算总得分。国内同样有“芝麻信用分”等利用相应手段、技术产生的基于互联网、大数据的个人征信新模式。</p><h2 id="互联网征信与欺诈识别"><a class="markdownIt-Anchor" href="#互联网征信与欺诈识别"></a> 互联网征信与欺诈识别</h2><p>信用评分在一定程度上可以反应用户的信用资质，不仅能够挑选出优质客户，<br>也能同时鉴别信用资质较差的用户。传统征信中，是利用征信手段了解客户是否<br>拥有信贷的资格，但很难鉴别劣质或蓄意欺诈客户。欺诈人员利用其对信贷流程<br>的研究，将过程中需要的个人信息虚假包装，从而进行骗贷。将但在互联网环境<br>下，用户的各种行为数据为识别用户是否具有欺诈风险提供了可能。尤其在基于<br>大数据的基础上，我们可以从更多的维度、特征来对客户进行信用评分，依靠互<br>联网征信来达到对欺诈行为预测的目的。无论欺诈人员进行过何种包装，他在互<br>联网中都会留下痕迹，这对利用还联网征信来进行欺诈识别提供了依据和可能性。<br>而如何利用大数据环境下，做创新型征信，从而更有利、更准确的识别欺诈<br>行为也是本文的研究重点。</p><h2 id="互联网行为数据与个人信用的关系"><a class="markdownIt-Anchor" href="#互联网行为数据与个人信用的关系"></a> 互联网行为数据与个人信用的关系</h2><p>于用户的互联网行为涉及其生活的方方面面、反映了其在社交、消费等方面的个人特征，因此收集用户的互联网行为数据并结合“5C”模型可以对授信申请人进行互联网用户行为层面上的信用评估。</p><h3 id="互联网用户行为数据"><a class="markdownIt-Anchor" href="#互联网用户行为数据"></a> 互联网用户行为数据</h3><p>用户的互联网行为有两个层面上的意义：在微观层面上，互联网用户行为是<br>指用户在互联网上具体的操作行为，例如点击次数、浏览次数、浏览时长、发布<br>内容等；在宏观层面上，互联网行为是指用户在互联网上使用不同类型的应用、<br>从而满足其自身某种需求的行为，例如观看视频、网络购物等。对前者的研究主<br>要针对具体的某个互联网应用，本文的研究主要着眼于宏观层面上的互联网用户<br>行为，以探求互联网用户行为与用户信用评估的关系。互联网价值的本质是服务，<br>而互联网服务的载体是各类互联网应用（见表 2.1）。因此，互联网用户在互联网<br>上的任何活动都可以具体对应到某个互联网应用上，这种现象称为互联网的应用<br>化。</p><p><a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.jpg" class="lazyload" title="1"></a></p><h3 id="个人信用的5c模型"><a class="markdownIt-Anchor" href="#个人信用的5c模型"></a> 个人信用的“5C模型”</h3><p>“5C”系统是从品质、能力、资本、担保、条件五个方面评估顾客或客户的<br>信用品质，从而确定风险程度，是金融机构对客户进行风险评估的常用方法之一。<br>其具体含义如下：</p><ol><li><p>品质(Character)：是评估用户信用资质的关键指标，代表客户的还款意愿，直接决定了应收账款是否能如期如数归还，因此一般认为信用评估最为重要的因素是品质；<br>2．能力(Capacity)：代表用户的还款能力，即其流动资产的数量和质量以及与流动负债的比例，通常以用户的已有的信用还款记录等信息为依据进行评判。<br>3．资本(Capital)：代表用户的财务状况和财务实力，用来描述顾客在偿还借款时可能的财务背景，例如客户的负债比率、流动比率、有形资产净值等财务指标。<br>4．抵押(Collateral)：代表用户无力支付款项或拒付款项时能被抵偿贷款的固定资产，这对于信用级别较低、资质较差或没有信用记录的用户非常重要。<br>5．条件(Condition)：代表可能影响用户还款情况的背景与环境，如客户出现经济困难、财务危机时的还款记录，以描述用户在特殊情况下的偿还可能。</p><h3 id="互联网用户行为对个人信用的反映"><a class="markdownIt-Anchor" href="#互联网用户行为对个人信用的反映"></a> 互联网用户行为对个人信用的反映</h3><p>通过上述分析我们可以发现，互联网用户行为及其所反映的用户特质与“5C”模型之间是有相关关系的。以互联网用户行为中的网络购物为例，用户在互联网上的网络购物行为数据反映了其经济能力，这对应“5C”模型中的“资本”；此外用户在经济不景气时期的消费记录还能反映其在“5C”模型中的“条件”，长期消费记录也能反映出用户的“品质”和“能力”。因此互联网用户行为能够反映用户的信用水平，是互联网征信机构在评估顾客或客户的信用品质时可以加以利用的信息。</p></li></ol><h2 id="互联网征信的优势"><a class="markdownIt-Anchor" href="#互联网征信的优势"></a> 互联网征信的优势</h2><h3 id="数据来源多"><a class="markdownIt-Anchor" href="#数据来源多"></a> 数据来源多</h3><p>传统征信数据主要来自金融领域财务数据、政府公开信息以及电信和水电煤<br>气账单等信息，而在大数据征信体系中，数据源更加广泛，数据种类更丰富，数<br>据的时效性也更强。大数据征信主要采集的不是传统的信贷数据，而是包括社交<br>媒体的关系数据、电商平台的交易数据、第三方支付的消费数据、各种移动 APP<br>的地理位置信息等在内的、更加多样的数据。这些数据可以反映信息主体的行为<br>特征、消费习惯以及社会关系等特征，并据此对用户进行信用风险评估。</p><h3 id="覆盖人群广"><a class="markdownIt-Anchor" href="#覆盖人群广"></a> 覆盖人群广</h3><h3 id="评估方法多样"><a class="markdownIt-Anchor" href="#评估方法多样"></a> 评估方法多样</h3><p>基于庞大数据库和机器学习等技术的支持，大数据征信的预测及决策精度可<br>达到 85％。传统征信方法主要关注用户的历史财务信息，致力于深度挖掘用户<br>的信用历史。而大数据征信体系利用的是授信对象现阶段的信息数据，获取其实<br>时的行为特征，并在此基础上预测其未来的履约能力。大数据征信体系不仅使用<br>多维度的变量（变量库中的变量个数可多达几千甚至上万个），还运用神经网络、<br>机器学习等先进的数据挖掘方法。这不仅能大大提高信用评估的决策效率，还能<br>明显降低用户的风险违约率。</p><h3 id="应用领域丰富"><a class="markdownIt-Anchor" href="#应用领域丰富"></a> 应用领域丰富</h3><p>由于体制和技术的限制等原因，传统征信的征信结果主要应用于金融领域，<br>而数据来源广泛、数据量庞大的大数据征信却可将信用评估结果应用于社会生活中需要用户信用履约的各个领域:例如租房、租车、订酒店、办签证等各个场景。</p><h3 id="征信成本低"><a class="markdownIt-Anchor" href="#征信成本低"></a> 征信成本低</h3><p>传统征信方法由于其方式的老化，当征信对象数量不断上升时，其成本也会<br>随之增长。但互联网征信模式则不然:互联网征信的成本主要集中在前期投入（例<br>如购置设备、建立数据库、建立模型等）方面，后期只需对征信平台进行必要的<br>维护，成本相对固定，因此不会随着用户数量的增长而显著提高。这显示出了互<br>联网征信规模效应的特点，相比传统征信而言更有利于征信机构的长期运营与发<br>展。</p><h2 id="互联网征信可能存在的问题"><a class="markdownIt-Anchor" href="#互联网征信可能存在的问题"></a> 互联网征信可能存在的问题</h2><p>用户隐私与信息安全</p><p>信用评估模型的准确性</p><p>互联网征信所使用的数据体量庞大，且变量之间没有必然的因果联系。如何处理这些杂乱无章的数据、如何并基于数以千计的变量规模建立模型、如何解释并应用这些模型，这些都是互联网征信的核心问题。这不仅需要强大的数据处理和模型开发能力，还需要在实践中不断检验并优化。此外，随之而来的还有对计算机存储及计算能力的挑战。</p><p>征信机构的独立性</p><h1 id="基于大数据的用户分类方法探究"><a class="markdownIt-Anchor" href="#基于大数据的用户分类方法探究"></a> 基于大数据的用户分类方法探究</h1><h2 id="11"><a class="markdownIt-Anchor" href="#11"></a> <a href="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.1.png" data-fancybox="group" data-caption="1.1" class="fancybox"><img alt="1.1" data-src="../img/%E9%9D%A2%E8%AF%95/%E9%8A%80%E8%A1%8C/1.1.png" class="lazyload" title="1.1"></a></h2></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python中join的用法</title>
      <link href="/2020/05/07/python%E4%B8%ADjoin%E7%9A%84%E7%94%A8%E6%B3%95/"/>
      <url>/2020/05/07/python%E4%B8%ADjoin%E7%9A%84%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>python笔记</p><h1 id="python中join的用法"><a class="markdownIt-Anchor" href="#python中join的用法"></a> python中join的用法</h1><p>Python中有join()和os.path.join()两个函数，具体作用如下：<br>join()：  连接字符串数组。将字符串、元组、列表中的元素以指定的字符(分隔符)连接生成一个新的字符串<br>os.path.join()： 将多个路径组合后返回</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#对序列进行操作（分别使用'| '与'*'作为分隔符）</span></span><br><span class="line"></span><br><span class="line"><span class="meta">>>> </span>fruit = [<span class="string">'apple'</span>,<span class="string">'banana'</span>,<span class="string">'pear'</span>,<span class="string">'grape'</span>,<span class="string">'orange'</span>]</span><br><span class="line"><span class="meta">>>> </span><span class="string">'*'</span>.join(fruit)</span><br><span class="line"><span class="string">'apple*banana*pear*grape*orange'</span></span><br><span class="line"></span><br><span class="line">SyntaxError: invalid syntax</span><br><span class="line"><span class="meta">>>> </span><span class="string">'|'</span>.join(fruit)</span><br><span class="line"><span class="string">'apple|banana|pear|grape|orange'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#对字符串进行操作</span></span><br><span class="line"><span class="meta">>>> </span>fruit = <span class="string">"apple banana pear grape orange"</span></span><br><span class="line"><span class="meta">>>> </span><span class="string">" "</span>.join(fruit)</span><br><span class="line"><span class="string">'a p p l e   b a n a n a   p e a r   g r a p e   o r a n g e'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#对元组进行操作</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">>>> </span>fruit = (<span class="string">'apple'</span>,<span class="string">'banana'</span>,<span class="string">'pear'</span>,<span class="string">'grape'</span>,<span class="string">'orange'</span>)</span><br><span class="line"><span class="meta">>>> </span><span class="string">"#"</span>.join(fruit)</span><br><span class="line"><span class="string">'apple#banana#pear#grape#orange'</span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#对字典进行操作</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">>>> </span>fruit = {<span class="string">'apple'</span>:<span class="number">3</span>,<span class="string">'banana'</span>:<span class="number">9</span>,<span class="string">'pear'</span>:<span class="number">6</span>,<span class="string">'grape'</span>:<span class="number">3</span>,<span class="string">'orange'</span>:<span class="number">8</span>}</span><br><span class="line"></span><br><span class="line"><span class="meta">>>> </span><span class="string">':'</span>.join(fruit)</span><br><span class="line"><span class="string">'pear:grape:banana:apple:orange'</span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#合并目录</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">>>> </span><span class="keyword">import</span> os</span><br><span class="line"><span class="meta">>>> </span>os.path.join(<span class="string">'a/'</span>,<span class="string">'b/'</span>,<span class="string">'c/'</span>)</span><br><span class="line"><span class="string">'a/b/c/'</span></span><br></pre></td></tr></tbody></table></figure></div><h2 id="oslistdir"><a class="markdownIt-Anchor" href="#oslistdir"></a> os.listdir()</h2><p>os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。</p><p>它不包括 <strong>.</strong> 和 <strong>…</strong> 即使它在文件夹中。</p><p>只支持在 Unix, Windows 下使用。</p><h1 id="numpysavez"><a class="markdownIt-Anchor" href="#numpysavez"></a> numpy.savez</h1><h1 id="numpy中数据的常用的保存与读取方法"><a class="markdownIt-Anchor" href="#numpy中数据的常用的保存与读取方法"></a> <a href="https://www.cnblogs.com/wushaogui/p/9142019.html" target="_blank" rel="noopener">Numpy中数据的常用的保存与读取方法</a></h1><p>numpy.savez(file, *args, **kwds)</p><blockquote><p>file:文件名/文件路径<br>*args:要存储的数组,可以写多个,如果没有给数组指定Key,Numpy将默认从’arr_0’,'arr_1’的方式命名<br>kwds:(可选参数,默认即可)</p></blockquote><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">>>> </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="comment">#生成数据 </span></span><br><span class="line"><span class="meta">>>> </span>x=np.arange(<span class="number">10</span>) </span><br><span class="line"><span class="meta">>>> </span>x </span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]) </span><br><span class="line"><span class="meta">>>> </span>y=np.sin(x) </span><br><span class="line"><span class="meta">>>> </span>y </span><br><span class="line">array([ <span class="number">0.</span>        ,  <span class="number">0.84147098</span>,  <span class="number">0.90929743</span>,  <span class="number">0.14112001</span>, <span class="number">-0.7568025</span> , </span><br><span class="line">       <span class="number">-0.95892427</span>, <span class="number">-0.2794155</span> ,  <span class="number">0.6569866</span> ,  <span class="number">0.98935825</span>,  <span class="number">0.41211849</span>]) </span><br><span class="line">        </span><br><span class="line"><span class="comment">#数据保存 </span></span><br><span class="line"><span class="meta">>>> </span>np.save(<span class="string">'save_xy'</span>,x,y) </span><br><span class="line"> </span><br><span class="line"><span class="comment">#读取保存的数据 </span></span><br><span class="line"><span class="meta">>>> </span>npzfile=np.load(<span class="string">'save_xy.npz'</span>) </span><br><span class="line"><span class="meta">>>> </span>npzfile  <span class="comment">#是一个对象,无法读取 </span></span><br><span class="line"><numpy.lib.npyio.npzfile object at <span class="number">0x7f63ce4c8860</numpy.lib.npyio.npzfile></span>> <br><span class="line"> </span><br><span class="line"><span class="comment">#按照组数默认的key进行访问 </span></span><br><span class="line"><span class="meta">>>> </span>npzfile[<span class="string">'arr_0'</span>] </span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]) </span><br><span class="line"><span class="meta">>>> </span>npzfile[<span class="string">'arr_1'</span>] </span><br><span class="line">array([ <span class="number">0.</span>        ,  <span class="number">0.84147098</span>,  <span class="number">0.90929743</span>,  <span class="number">0.14112001</span>, <span class="number">-0.7568025</span> , </span><br><span class="line">       <span class="number">-0.95892427</span>, <span class="number">-0.2794155</span> ,  <span class="number">0.6569866</span> ,  <span class="number">0.98935825</span>,  <span class="number">0.41211849</span>])</span><br></pre></td></tr></tbody></table></figure></div><p>工作态度，请假;软件对比的rufurensi ，实现完硬件 去跑网络，用软件去跑结果 和硬件跑的结果去做对比，python去写，第一步 卷积，把一个完整的卷积，yolov3</p><p>输入 608*608 ,这个月，</p><p>pycharm调试：<a href="https://blog.csdn.net/s740556472/article/details/90054266" target="_blank" rel="noopener">https://blog.csdn.net/s740556472/article/details/90054266</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习在网络攻击检测中的应用</title>
      <link href="/2020/04/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>/2020/04/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="机器学习在网络攻击检测中的应用"><a class="markdownIt-Anchor" href="#机器学习在网络攻击检测中的应用"></a> 机器学习在网络攻击检测中的应用</h1><h1 id="研究现状"><a class="markdownIt-Anchor" href="#研究现状"></a> 研究现状</h1><p>研究现状：针对当前入侵检测系统的不足，许多专家学者提出了将数据挖掘技术与机器学习算法融入到入侵检测系统中的方案</p><p>主要有：1.利用聚类技术减少支持向量的入侵检测系统</p><p>使用支持向量机一个很严重的问题就是极低的分类速度，分类速度是由支持向量的数量决定的。基于经过聚类的SVM是一种新的减少支持向量的方法。此方法利用k-means聚类技术将所有的数据聚成K类，然后利用SVM对每一类分别进行训练。K值为此类中支持向量数量的上界。</p><p>2.无监督的异常检测系统</p><p>在实际应用中，大部分原始的网络数据没有经过标注的。通过人工方式进行海量数据标注过于耗费人力。无监督的异常检测系统近些年已经成为研究的热点，他们不需要任何标注好的数据，大大降低了对训练数据集的要求，聚类算法是一种电行的无监督异常检测方法，这种方法通常假设数据集包含大量的正常数据和少量的异常数据，并且正常数据与异常数据存在本质的不同，</p><h1 id="目前存在的问题"><a class="markdownIt-Anchor" href="#目前存在的问题"></a> 目前存在的问题</h1><p>1.高速环境下的检测问题</p><p>对于入侵检测而言，对网络数据包进行重组可以保证必须的检测能力，比如对网络中的IP碎片包进行重组并加以分析可以避免IP碎片欺骗。但是这需要耗费更多的计算能力。</p><p>2.交换式网络环境下的检测问题</p><p>传统的网络入侵检测技术必须要添加一些硬件措施才能监控交换式网络，这回产生性能和通用性的实际问题。</p><p>3.加密的问题</p><p>如果网络中的数据包或者特征字符串没有经过加密，通过与知识库中的特征进行匹配，网络入侵检测技术可以发现入侵活动，但是如果网络上传输的数据呗加密，网络入侵检测系统无法正常工作。</p><p>此外还有虚假报警问题，误报、漏报率高（阈值确定），欠缺主动防御能力</p><h1 id="入侵检测系统"><a class="markdownIt-Anchor" href="#入侵检测系统"></a> 入侵检测系统</h1><h2 id="入侵检测系统的基本组成"><a class="markdownIt-Anchor" href="#入侵检测系统的基本组成"></a> 入侵检测系统的基本组成</h2><p>1.数据收集器</p><p>主要负责收集数据。探测器将网络数据包，日志文件等这些关键的网络数据收集起来发送至检测器进行处理</p><p>2.检测器</p><p>3.知识库</p><p>将审计数据的数据特征存放在知识库中，入侵检测系统将网络中新的审计数据的数据特征与知识库中的已知数据特征进行匹配分析从而判断此审计数据是否属于入侵行为</p><p>4.控制器</p><p>根据报警信号，人工活自动做出反映动作。</p><h2 id="入侵检测系统的原理及作用"><a class="markdownIt-Anchor" href="#入侵检测系统的原理及作用"></a> 入侵检测系统的原理及作用</h2><p>入侵检测系统主要工作包括监视，分析用户以及系统活动，对系统构造和弱点进行审计，识别反应已知攻击的活动模式并进行报警，对异常行为模式进行统计分析，评估重要系统和数据文件的完整性，以及审计跟踪管理操作系统并违法安全策略的用户行为，通过完成这些主要工作，可以实现对计算机系统的实时保护。</p><p>入侵检测利用<strong>模式匹配算法</strong>将当前待检测的网络数据同系统的知识库进行比较，根据匹配的结果来判断当前数据是否属于入侵行为。然后根据检测结果作出响应。<a href="/img/%E9%9D%A2%E8%AF%95/8.png" data-fancybox="group" data-caption="8" class="fancybox"><img alt="8" title="8" data-src="/img/%E9%9D%A2%E8%AF%95/8.png" class="lazyload"></a></p><h3 id="扩展-kmp匹配算法"><a class="markdownIt-Anchor" href="#扩展-kmp匹配算法"></a> 扩展： KMP匹配算法</h3><p>一个基本事实是，当空格与 D 不匹配时，你其实是已经知道前面六个字符是 “ABCDAB”。KMP 算法的想法是，设法利用这个已知信息，不要把 “搜索位置” 移回已经比较过的位置，而是继续把它向后移，这样就提高了效率。怎么做到这一点呢？可以针对模式串，设置一个跳转数组int next[]</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmp_match</span><span class="params">(s, p)</span>:</span></span><br><span class="line">    m = len(s)</span><br><span class="line">    n = len(p)</span><br><span class="line">    cur = <span class="number">0</span>  <span class="comment"># 起始指针cur</span></span><br><span class="line">    table = partial_table(p)</span><br><span class="line">    <span class="keyword">while</span> cur <= m - n:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            <span class="keyword">if</span> s[i + cur] != p[i]:</span><br><span class="line">                cur += max(i - table[i - <span class="number">1</span>], <span class="number">1</span>)  <span class="comment"># 有了部分匹配表,我们不只是单纯的1位1位往右移,可以一次移动多位</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部分匹配表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partial_table</span><span class="params">(p)</span>:</span></span><br><span class="line">    <span class="string">'''partial_table("ABCDABD") -> [0, 0, 0, 0, 1, 2, 0]'''</span></span><br><span class="line">    prefix = set()</span><br><span class="line">    postfix = set()</span><br><span class="line">    ret = [<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(p)):</span><br><span class="line">        prefix.add(p[:i])</span><br><span class="line">        print(prefix)</span><br><span class="line">        postfix = {p[j:i + <span class="number">1</span>] <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, i + <span class="number">1</span>)}</span><br><span class="line">        ret.append(len((prefix & postfix <span class="keyword">or</span> {<span class="string">''</span>}).pop()))</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></tbody></table></figure></div><h1 id="聚类分析概述"><a class="markdownIt-Anchor" href="#聚类分析概述"></a> 聚类分析概述</h1><p>**在入侵检测中使用无监督聚类算法可以使系统训练未经标注的数据从而检测出更多从未出现过的入侵。**数据聚类现在已广泛应用于各个领域，由于数据库中收集了大量的数据，聚类分析已称为数据挖掘研究领域中一个非常活跃的研究课题。目前，将聚类分析方法应用于入侵检测系统，已成为研究的一大热点。</p><h1 id="特征选择"><a class="markdownIt-Anchor" href="#特征选择"></a> 特征选择</h1><p>每一种网络攻击数据都有某些特定的“身份”，即人们所说的“特征”，入侵检测系统就是通过提取这些攻击特征与规则库中已有的特征进行匹配，从而确定这条数据是否为攻击数据，然而并非每条网络数据都是攻击数据。即使某种数据是攻击数据，由于其含有许多不同的特征，并非每种特征都会对最终入侵检测系统对入侵的判别起关键作用，并且某些特征属于重复特征。上述都会造成入侵检测系统做无用功导致效率低下，同时某些特征甚至会干扰系统做出判断。因此需要对特征进行筛选和删减。进过特征选择后，入侵检测系统的工作量会有所减少，工作精度会大大提高，从而提高整个检测系统的效率与性能。</p><p>可通过计算特征的信息增益来判断系统的重要性，信息增益大的其对应的特征也重要。</p><h2 id="通过以下几种方式实现数据的约减"><a class="markdownIt-Anchor" href="#通过以下几种方式实现数据的约减"></a> 通过以下几种方式实现数据的约减：</h2><h3 id="数据过滤"><a class="markdownIt-Anchor" href="#数据过滤"></a> 数据过滤</h3><p>数据过滤的目的是直接减少入侵检测系统需要处理的数据的数量，一些对于入侵检测系统来说无用的数据可以在处理之前直接删除。有利用降低对存储空间的需求，减少处理时间提高系统的效率和检测率，然而，数据过滤可能删除某些有用的数据，谨慎使用。</p><h3 id="特征选择-2"><a class="markdownIt-Anchor" href="#特征选择-2"></a> 特征选择</h3><p>在复杂的分类领域中，某些能包含错误的联系的特征会阻碍检测进程。此外某些特征向系统加入的信息可能被其他特征所包含着，通常称这些特征为冗余特征。额外的冗余特征会增加运算时间，会影响入侵检测系统的检测率。特征的选择依赖于入侵检测系统的类型，比如，基于网络的入侵检测系统需要分析诸如数据包的目的IP地址，协议类型，链接时间等于网络相关的数据。</p><h3 id="数据聚类"><a class="markdownIt-Anchor" href="#数据聚类"></a> 数据聚类</h3><p>聚类可以被迎来寻找入侵检测中数据的隐藏模式以及重要特征。因为聚类存储的是类的特征而不是单个数据的特征，所以可以呗用做数据约减。</p><h2 id="特征选择的必要性"><a class="markdownIt-Anchor" href="#特征选择的必要性"></a> 特征选择的必要性</h2><p>在很多实际问题中，往往不容易找到那些最重要的特征，或者由于客观条件的限制无法对其进行有效的测量。另外人们在测量重要特征时，只要条件允许，总希望把特征选的尽可能的多一些，全面一些。另一方面，由于客观的需要，为了突出某些有用的信息抑制无用信息，有意加上一些比值、指数、或对数等综合计算特征。如果将数目很大的测量值全部直接用作分类特征，不但会印象分类效果，而且会消耗大量的计算时间，从而引发维数灾难问题。</p><p>**经过选择或变换处理，得到有效的分类特征；同时还要再确保一定的分类精度的前提之下，进行降维处理，**这两个方面对于提高真个入侵检测系统来说缺一不可。</p><p>基于</p><h3 id="特征选择在入侵检测中的应用"><a class="markdownIt-Anchor" href="#特征选择在入侵检测中的应用"></a> 特征选择在入侵检测中的应用</h3><p>入侵检测系统的首要要求是正确性，其次是实时性。随着网络高速发展，检测速度低、符合大、来不及处理网络中传输的海量数据以及对数据处理的效果不理想已经成为入侵检测系统急需解决的主要问题。检测速度和低检测率已成为入侵检测系统设置中的重要指标，如何开发出检测速度快、检测准确度高的轻量级入侵检测系统以确保检测的正确性，成为当前研究的特点。</p><p>对于入侵检测系统来说，提取和处理特征输出过多是导致速度以及检测质量下降的主要原因之一。所以在尽量保证分类精确度的前提下，利用特征选择来去除冗余特征并将能够明确反映系统状态信息特征的保留从而实现降维。</p><h2 id="特征选择算法"><a class="markdownIt-Anchor" href="#特征选择算法"></a> 特征选择算法</h2><p>信息增益是一种构建决策树的方法，因为他是可以决定决策树中属性的优先顺序，通过计算信息增益来决定在分类过程中起最重要作用的特征，对于每一个特定的攻击类型，拥有最高信息增益的特征被认为是与此功绩类型最相关的特征。</p><h2 id="高维特征向量的处理"><a class="markdownIt-Anchor" href="#高维特征向量的处理"></a> 高维特征向量的处理</h2><p>在实际的入侵检测系统中，大部分数据都具有高纬特性，在高维情况下，数据之间相似性的概念是不复存在的（欧氏距离计算量太大）</p><p>在特征空间中，任意数据点可以与两个聚类中心构成一个三角形区域，计算这个三角形区域的面积，将此面积作为数据点的新的特征向量的一个分量，这个可以有效提高分类器的性能，</p><h1 id="融合无监督学习与有监督学习"><a class="markdownIt-Anchor" href="#融合无监督学习与有监督学习"></a> 融合无监督学习与有监督学习</h1><p>以往的入侵检测系统通常只采用两种机器学习方法中的一种，近些年混合两种机器学习方法的入侵检测系统已经逐渐成为研究的特点，融合两种机器学习算法对入侵检测系统性能的提升是非常有好处的。比如，人们经常先使用某种聚类方法对训练数据提前进行聚类预处理，这样往往会减少支持向量的个数，有利于支持向量机的性能提升。所以可以采用将K-means聚类算法与SVM支持向量机融合在一起，以使整个检测系统打到理想检测效果</p><h2 id="基于三角形面积的支持向量机算法tasvm"><a class="markdownIt-Anchor" href="#基于三角形面积的支持向量机算法tasvm"></a> 基于三角形面积的支持向量机算法(TASVM)</h2><p>1.提取聚类中心。</p><p>2.利用三角形区域形成新特征向量。</p><p>3.利用欧几里得距离计算三角形周长。</p><p>4.利用Heron公式计算三角形面试</p><h2 id="新特征的形成"><a class="markdownIt-Anchor" href="#新特征的形成"></a> 新特征的形成</h2><p>根据前面的分析，由信息增益得到10个与最最终的分类结果最相关的特征，接着利用k-means聚类算法对这些经过处理的数据惊醒聚类再由数据点和聚类组合成一个三角形区域，将10个不同的三角形面积计算出后作为新的特征向量。<a href="/img/%E9%9D%A2%E8%AF%95/9.png" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" title="9" data-src="/img/%E9%9D%A2%E8%AF%95/9.png" class="lazyload"></a></p><h1 id="支持向量机"><a class="markdownIt-Anchor" href="#支持向量机"></a> 支持向量机</h1><p>利用分类算法SVM对得到的新特征数据进行分类和测试。</p><p>SVM的特点就是他是一种基于结构风险最小化准则的学习方法。SVN算法分类的准确性在众多领域都得到了很好的验证。在解决小样本、非线性及高维模式识别问题中SVM表现出许多特有优势。</p><h1 id="数据集"><a class="markdownIt-Anchor" href="#数据集"></a> 数据集</h1><p>KDD Cup 1999 数据集一共包括<strong>4种不同类型的攻击</strong>，按照攻击方式及目的可以分为四大类： DoS–拒绝服务攻击类型，Probing–扫描或者对其他系统漏洞的探测、U2R–非授权得到超级用户权限或者运行超级用户函数、R2L–从远程计算机惊醒非授权访问。</p><p><a href="/img/%E9%9D%A2%E8%AF%95/10.png" data-fancybox="group" data-caption="10" class="fancybox"><img alt="10" title="10" data-src="/img/%E9%9D%A2%E8%AF%95/10.png" class="lazyload"></a></p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>1.通过计算10%的所用数据集中所有特征的信息增益，得到了与最终分类与检测最为相关的10个特征，并将其他冗余特征删除，从而进一步提高分类的精确性。通过这一步，可以将原来的41维特征向量降至10维。</p><p>2.利用线性缩放统一连续型变量与离散型变量的取值范围，以便建立最终的特征向量。</p><p>3.使用K-means聚类算法将数据集聚成五类，提取出5个聚类中心。</p><p>4.对于每一个样本，从5个聚类中心中任意选出2个与此样本点构成一个三角形，这样会有10种不同的组合方式，计算这10个三角形的面积，将10个三角形面积作为这个样本点的新的特征向量，有利于提高分类器的性能。</p><p>5.利用十倍交叉验证在SVM中对实验数据进行训练与测试。</p><p>该文的入侵检测系统融合了无监督学习与有监督学习的机器学习算法，并对特征进行了选择，删除冗余特征，保存有用的特征，对特征向量进行降维，并对特征向量进行了新特征的表示。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>垃圾邮件过滤技术</title>
      <link href="/2020/04/16/%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF/"/>
      <url>/2020/04/16/%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="项目背景"><a class="markdownIt-Anchor" href="#项目背景"></a> 项目背景</h1><h2 id="垃圾邮件过滤概述"><a class="markdownIt-Anchor" href="#垃圾邮件过滤概述"></a> 垃圾邮件过滤概述</h2><p>随着互联网的蓬勃发展，电子邮件已经成为互联网上最普遍的通讯方式之一；据最新调查显示，2017Q3季度中国是世界最大垃圾邮件产生国和第二大受恶意邮件袭击的国家。垃圾邮件的内容主要包括欺诈邮件、新闻议程、钓鱼攻击邮件、站点宣传邮件、病毒邮件等等</p><h2 id="垃圾邮件的影响"><a class="markdownIt-Anchor" href="#垃圾邮件的影响"></a> 垃圾邮件的影响</h2><ul><li>占用网络带宽，造成邮件服务器拥塞，进而降低整个网络的运行效率。</li><li>骗取钱财，传播色情内容等。</li><li>携带病毒程序，可能导致接收邮件的机器/服务器感染病毒。</li></ul><h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1><h2 id="垃圾邮件过滤技术方案"><a class="markdownIt-Anchor" href="#垃圾邮件过滤技术方案"></a> 垃圾邮件过滤技术方案</h2><p>​       正确的识别垃圾邮件的技术难度比较大，常用的垃圾邮件过滤方式有：关键词法、校验码法、主题/源Email地址/IP地址/附件审计、白名单/黑名单机制、贝叶斯算法过滤等；<br>​        其中贝叶斯算法过滤垃圾邮件是一种基于统计学的过滤器，是建立在已有的统计结果之上的，所以贝叶斯算法过滤垃圾邮件模型属于一种有监督的分类算法。基于贝叶斯算法的过滤垃圾邮件也属于一种比较常用的算法模型。</p><h3 id="思路"><a class="markdownIt-Anchor" href="#思路"></a> 思路</h3><p>1.任务：监督学习还是无监督学习，二分类还是多分类，文本分类还是结构化分数据分类？短文本分类还是长文本分类？</p><p>2.数据:样本如何定义？什么样的数据作为特征？如果划分训练集和测试集？</p><p>3.特征:如何从原始数据中提取机器学习适用的特征？</p><p>4.模型：选择合适的模型；根据具体任务优化模型；调优模型；多模型融合；</p><h3 id="邮件数据格式"><a class="markdownIt-Anchor" href="#邮件数据格式"></a> 邮件数据格式</h3><p>数据集特征有：发件人，收件人，邮件发送时间，邮件的内容；</p><p><a href="/img/%E9%9D%A2%E8%AF%95/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" title="4" data-src="/img/%E9%9D%A2%E8%AF%95/4.png" class="lazyload"></a></p><p>邮件标签文件</p><p><a href="/img/%E9%9D%A2%E8%AF%95/5.png" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" title="5" data-src="/img/%E9%9D%A2%E8%AF%95/5.png" class="lazyload"></a></p><h3 id="需求分析"><a class="markdownIt-Anchor" href="#需求分析"></a> 需求分析</h3><p>任务：基于邮件内容、发件人、发件时间等相关内容，准确地、完整地识别出垃圾邮件和正常邮件；</p><ul><li>邮件数据有类别标签，属于监督学习类型。</li><li>二分类：垃圾邮件(1)，正常邮件(0)。</li><li>主要是非结构化的邮件文本数据，属于长文本分类问题</li></ul><h3 id="模型选择"><a class="markdownIt-Anchor" href="#模型选择"></a> 模型选择</h3><p>分类问题，所以可以选取的模型有：SVM,KNN,朴素贝叶斯，决策树，随机森林，GBDT</p><h3 id="数据清洗"><a class="markdownIt-Anchor" href="#数据清洗"></a> 数据清洗</h3><p>​       从原始数据中，将邮件数据转换称为结构化类型的数据，并且去掉其它不需要的字段信息，只需要保留发件人、收件人、发送时间、邮件内容这四部分的内容，对于这四个字段信息，如果这四个字段为空，那么将为空的属性设置为unknown。</p><h2 id="特征工程"><a class="markdownIt-Anchor" href="#特征工程"></a> 特征工程</h2><ol><li></li></ol><ul><li>发件人和收件人邮箱服务器提取，如果没有发件人或者收件人的邮件地址的，直接将该字段的值设置为unknown。</li><li>通过对服务器地址字段的分析，可以得出在最终的算法模型中，该特征属性不需要使用的结论</li></ul><ol start="2"><li></li></ol><ul><li>邮件发送时间提取，主要提取出来星期、小时、时间段(上午&下午&晚上&凌晨)等时间的表示字段信息。</li><li>通过对时间提取字段信息的分析，可以得到时间对于垃圾邮件的分类，作用不大，在后续的模型训练中可以不考虑该字段特征属性。同时从数据上我们也可以看出如果一个邮件没有发送时间，那么一定属于垃圾邮件，所以可以在最终模型中加入这个特征属性。</li></ul><ol start="3"><li></li></ol><p>中文分词 ： 利用开源的分词工具jeba分词处理</p><ol start="4"><li></li></ol><ul><li><p>信息量特征</p></li><li><p>正常邮件的内容长度一般都在一定范围内，即不会太长也不会太短；但是一般情况下，邮件的内容越短，那么该邮件就越有可能是垃圾邮件。</p></li><li><p>信号量：值越大，就越有可能是属于垃圾邮件。</p></li></ul><p><a href="/img/%E9%9D%A2%E8%AF%95/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" title="2" data-src="/img/%E9%9D%A2%E8%AF%95/2.png" class="lazyload"></a></p><p>​         x表示文本长度<br>​         L1和L2为调节因子，在该项目中，分别设置为500和10000<br>​         B1和B2为信息量平滑因子，在该项目中，全部设置为1</p><h2 id="模型效果评估"><a class="markdownIt-Anchor" href="#模型效果评估"></a> 模型效果评估</h2><p>在进行垃圾邮件过滤的时候，即需要注意垃圾邮件的拦截率(召回率)，也需要注意正常邮件被当成垃圾邮件的错判率(精确率), 在当前项目中，我们主要考虑召回率这个指标。</p><p><a href="/img/%E9%9D%A2%E8%AF%95/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" title="3" data-src="/img/%E9%9D%A2%E8%AF%95/3.png" class="lazyload"></a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">召</mi><mi mathvariant="normal">回</mi><mi mathvariant="normal">率</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>A</mi><mrow><mi>A</mi><mo>+</mo><mi>C</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(召回率)=\frac{A}{A+C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">召</span><span class="mord cjk_fallback">回</span><span class="mord cjk_fallback">率</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.275662em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">A</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><h1 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h1><h2 id="数据清洗-2"><a class="markdownIt-Anchor" href="#数据清洗-2"></a> 数据清洗</h2><p>步骤1.处理索引文件，处理结果如：’/028/239’: ‘0’, ‘/028/240’: ‘0’, ‘/028/241’: ‘1’,</p><p>2.处理邮件的文件内容，提取收件人，发件人，日期，内容信息，并合并</p><p>3.将邮件对应标签添加到文件内容后 文件内容，0  文件内容，1</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、索引文件(分类标签)读取，该文件中分为两列</span></span><br><span class="line"><span class="comment"># 第一列：分类标签是否为垃圾邮件（是：spam、否：ham）；</span></span><br><span class="line"><span class="comment"># 第二列：存放邮件对应文件夹路径，两列之间通过空格分割</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_index_file</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    type_dict = {<span class="string">"spam"</span>: <span class="string">"1"</span>, <span class="string">"ham"</span>: <span class="string">"0"</span>}  <span class="comment"># 用字典存放垃圾邮件的分类标签</span></span><br><span class="line">    index_file = open(file_path)</span><br><span class="line">    index_dict = {}</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> index_file:  <span class="comment"># 按行循环读取文件</span></span><br><span class="line">            arr = line.split(<span class="string">" "</span>)  <span class="comment"># 用“空格”进行分割</span></span><br><span class="line">            <span class="comment"># pd.read_csv("full/index",sep=" ")      #pandas来写与上面等价</span></span><br><span class="line">            <span class="keyword">if</span> len(arr) == <span class="number">2</span>:  <span class="comment"># 分割完之后如果长度是2</span></span><br><span class="line">                key, value = arr  <span class="comment">##分别将spam  ../data/178/129赋值给key与value</span></span><br><span class="line">            <span class="comment"># 添加到字段中</span></span><br><span class="line">            value = value.replace(<span class="string">"../data"</span>, <span class="string">""</span>).replace(<span class="string">"\n"</span>, <span class="string">""</span>)  <span class="comment"># 替换</span></span><br><span class="line">            <span class="comment"># 字典赋值，字典名[键]=值，lower()将所有的字母转换成小写</span></span><br><span class="line">            index_dict[value] = type_dict[key.lower()]  <span class="comment">#</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        index_file.close()</span><br><span class="line">    <span class="keyword">return</span> index_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、邮件的文件内容数据读取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="comment"># 读操作，邮件数据编码为"gb2312",数据读取有异常就ignore忽略</span></span><br><span class="line">    file = open(file_path, <span class="string">"r"</span>, encoding=<span class="string">"gb2312"</span>, errors=<span class="string">"ignore"</span>)</span><br><span class="line">    content_dict = {}</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        is_content = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> file:  <span class="comment"># 按行读取</span></span><br><span class="line">            line = line.strip()  <span class="comment"># 每行的空格去掉用strip()</span></span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">"From:"</span>):</span><br><span class="line">                content_dict[<span class="string">"from"</span>] = line[<span class="number">5</span>:]</span><br><span class="line">            <span class="keyword">elif</span> line.startswith(<span class="string">"To:"</span>):</span><br><span class="line">                content_dict[<span class="string">"to"</span>] = line[<span class="number">3</span>:]</span><br><span class="line">            <span class="keyword">elif</span> line.startswith(<span class="string">"Date:"</span>):</span><br><span class="line">                content_dict[<span class="string">"data"</span>] = line[<span class="number">5</span>:]</span><br><span class="line">            <span class="keyword">elif</span> <span class="keyword">not</span> line:</span><br><span class="line">                <span class="comment"># 邮件内容与上面信息存在着第一个空行，遇到空行时，这里标记为True以便进行下面的邮件内容处理</span></span><br><span class="line">                <span class="comment"># line文件的行为空时是False，不为空时是True</span></span><br><span class="line">                is_content = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理邮件内容（处理到为空的行时接着处理邮件的内容）</span></span><br><span class="line">            <span class="keyword">if</span> is_content:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">"content"</span> <span class="keyword">in</span> content_dict:</span><br><span class="line">                    content_dict[<span class="string">"content"</span>] += line</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    content_dict[<span class="string">"content"</span>] = line</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        file.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> content_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、邮件数据处理(内容的拼接,并用逗号进行分割)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_file</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    content_dict = read_file(file_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行处理(拼接),get()函数返回指定键的值，指定键的值不存在用指定的默认值unkown代替</span></span><br><span class="line">    result_str = content_dict.get(<span class="string">"from"</span>, <span class="string">"unkown"</span>).replace(<span class="string">","</span>, <span class="string">""</span>).strip() + <span class="string">","</span></span><br><span class="line">    result_str += content_dict.get(<span class="string">"to"</span>, <span class="string">"unkown"</span>).replace(<span class="string">","</span>, <span class="string">""</span>).strip() + <span class="string">","</span></span><br><span class="line">    result_str += content_dict.get(<span class="string">"data"</span>, <span class="string">"unkown"</span>).replace(<span class="string">","</span>, <span class="string">""</span>).strip() + <span class="string">","</span></span><br><span class="line">    result_str += content_dict.get(<span class="string">"content"</span>, <span class="string">"unkown"</span>).replace(<span class="string">","</span>, <span class="string">""</span>).strip()</span><br><span class="line">    <span class="keyword">return</span> result_str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、开始进行数据处理——函数调用</span></span><br><span class="line"><span class="comment">## os.listdir    返回指定的文件夹包含的文件或文件夹包含的名称列表</span></span><br><span class="line">index_dict = read_index_file(<span class="string">'./data/full/index'</span>)</span><br><span class="line">list0 = os.listdir(<span class="string">'./data/data'</span>)  <span class="comment"># list0是范围为[000-215]的列表</span></span><br><span class="line"><span class="comment"># print(list0)</span></span><br><span class="line"><span class="keyword">for</span> l1 <span class="keyword">in</span> list0:  <span class="comment"># l1:循环000--215</span></span><br><span class="line">    l1_path = <span class="string">'./data/data/'</span> + l1  <span class="comment"># l1_path   ../data/data/215</span></span><br><span class="line">    print(<span class="string">'开始处理文件夹:'</span> + l1_path)</span><br><span class="line">    list1 = os.listdir(l1_path)</span><br><span class="line">    print(list1)</span><br><span class="line">    write_file_path = <span class="string">'./data/process01_'</span> + l1</span><br><span class="line">    <span class="keyword">with</span> open(write_file_path, <span class="string">"w"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> writer:</span><br><span class="line">        <span class="keyword">for</span> l2 <span class="keyword">in</span> list1:  <span class="comment"># l2:循环000--299</span></span><br><span class="line">            l2_path = l1_path + <span class="string">"/"</span> + l2  <span class="comment"># l2_path   ../data/data/215/000</span></span><br><span class="line">            <span class="comment"># 得到具体的文件内容后，进行文件数据的读取</span></span><br><span class="line">            index_key = <span class="string">"/"</span> + l1 + <span class="string">"/"</span> + l2  <span class="comment"># index_key:  /215/000</span></span><br><span class="line">            print(index_key)</span><br><span class="line">            <span class="keyword">if</span> index_key <span class="keyword">in</span> index_dict:</span><br><span class="line">                <span class="comment"># 读取数据</span></span><br><span class="line">                content_str = process_file(l2_path)</span><br><span class="line">                <span class="comment"># 添加分类标签（0、1）也用逗号隔开</span></span><br><span class="line">                content_str += <span class="string">","</span> + index_dict[index_key] + <span class="string">"\n"</span></span><br><span class="line">                <span class="comment"># 进行数据输出</span></span><br><span class="line">                writer.writelines(content_str)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再合并所有第一次构建好的内容</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./data/result_process01'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> writer:</span><br><span class="line">    <span class="keyword">for</span> l1 <span class="keyword">in</span> list0:</span><br><span class="line">        file_path = <span class="string">'./data/process01_'</span> + l1</span><br><span class="line">        print(<span class="string">"开始合并文件:"</span> + file_path)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(file_path, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">                writer.writelines(line)</span><br></pre></td></tr></tbody></table></figure></div><h2 id="特征工程-2"><a class="markdownIt-Anchor" href="#特征工程-2"></a> 特征工程</h2><h3 id="提取发件人邮箱地址与收件人邮箱地址"><a class="markdownIt-Anchor" href="#提取发件人邮箱地址与收件人邮箱地址"></a> 提取发件人邮箱地址与收件人邮箱地址</h3><p>map函数与lambda 匿名函数用法</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib as mpl</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">## 设置字符集，防止中文乱码</span><br><span class="line">mpl.rcParams['font.sans-serif'] = [u'simHei']</span><br><span class="line">mpl.rcParams['axes.unicode_minus'] = False</span><br><span class="line"></span><br><span class="line"># 1、文件数据读取</span><br><span class="line">df = pd.read_csv("./data/result_process01", sep=",", header=None,</span><br><span class="line">                 names=["from", "to", "date", "content", "label"])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># print(df.head())</span><br><span class="line"></span><br><span class="line"># 2(1)、特征工程1 =>提取发件人和收件人的邮件服务器地址</span><br><span class="line">def extract_email_server_address(str1):</span><br><span class="line">    it = re.findall(r"@([A-Za-z0-9]*\.[A-Za-z0-9\.]+)", str(str1))</span><br><span class="line">    print(it)</span><br><span class="line">    result = ""</span><br><span class="line">    if len(it) > 0:</span><br><span class="line">        result = it[0] #有重复出现问题</span><br><span class="line">    if not result:</span><br><span class="line">        result = "unknown"</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df["to_address"] = pd.Series(map(lambda str: extract_email_server_address(str), df["to"]))</span><br><span class="line">df["from_address"] = pd.Series(map(lambda str: extract_email_server_address(str), df["from"]))</span><br><span class="line">#print(df.head(2))</span><br><span class="line"></span><br><span class="line"># 2(2)、特征工程1 =>查看邮件服务器的数量</span><br><span class="line">print("=================to address================")</span><br><span class="line">print(df.to_address.value_counts().head(10))</span><br><span class="line">print("总邮件接收服务器类别数量为:" + str(df.to_address.unique().shape))</span><br><span class="line"></span><br><span class="line">print("=================from address================")</span><br><span class="line">print(df.from_address.value_counts().head(5))</span><br><span class="line">print("总邮件发送服务器类别数量为:" + str(df.from_address.unique().shape))</span><br><span class="line"></span><br><span class="line">from_address_df = df.from_address.value_counts().to_frame()</span><br><span class="line">len_less_10_from_adderss_count = from_address_df[from_address_df.from_address <= 10].shape</span><br><span class="line">print("发送邮件数量小于10封的服务器数量为:" + str(len_less_10_from_adderss_count))</span><br></pre></td></tr></tbody></table></figure></div><p>可以得处，数据集中总邮件发送服务器类别数量为1832，发送邮件数量小于10封的服务器数量为1827，该特征对结果影响很小，不需要使用</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 查看一下发送邮件最多的五个运营商所发送的所有邮件中的正常邮件和异常邮件的比例情况</span><br><span class="line">print("所有发送邮件情况")</span><br><span class="line">print(df.from_address.value_counts().head(5))</span><br><span class="line">print("所有的正常邮件的发送情况")</span><br><span class="line">print(df[df.label==0.0].from_address.value_counts().head(5))</span><br><span class="line">print("所有的异常邮件的发送情况")</span><br><span class="line">print(df[df.label==1.0].from_address.value_counts().head(5))</span><br></pre></td></tr></tbody></table></figure></div><p>所有发送邮件情况：</p><ul><li><p>unknown          498</p></li><li><p><a href="http://yahoo.co.jp" target="_blank" rel="noopener">yahoo.co.jp</a>      274</p></li><li><p><a href="http://hotmail.com" target="_blank" rel="noopener">hotmail.com</a>      244</p></li><li><p><a href="http://media.mit.edu" target="_blank" rel="noopener">media.mit.edu</a>    144</p></li><li><p><a href="http://lingo.com" target="_blank" rel="noopener">lingo.com</a>        119</p></li><li><p>Name: from_address, dtype: int64</p></li></ul><p>所有的正常邮件的发送情况</p><ul><li><p>unknown          185</p></li><li><p><a href="http://hotmail.com" target="_blank" rel="noopener">hotmail.com</a>       97</p></li><li><p><a href="http://yahoo.co.jp" target="_blank" rel="noopener">yahoo.co.jp</a>       87</p></li><li><p><a href="http://media.mit.edu" target="_blank" rel="noopener">media.mit.edu</a>     51</p></li><li><p><a href="http://lingo.com" target="_blank" rel="noopener">lingo.com</a>         40</p></li><li><p>Name: from_address, dtype: int64</p></li></ul><p>所有的异常邮件的发送情况</p><ul><li><p>unknown          313</p></li><li><p><a href="http://yahoo.co.jp" target="_blank" rel="noopener">yahoo.co.jp</a>      187</p></li><li><p><a href="http://hotmail.com" target="_blank" rel="noopener">hotmail.com</a>      147</p></li><li><p><a href="http://media.mit.edu" target="_blank" rel="noopener">media.mit.edu</a>     93</p></li><li><p><a href="http://lingo.com" target="_blank" rel="noopener">lingo.com</a>         79</p></li><li><p>Name: from_address, dtype: int64</p></li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 基于上一个的描述信息（上述只取了部分，具体下要求得全部情况去判断），我认为如果发送邮箱是：163.com、126.com、tom.com、12.com（假设）的情况下，那么邮件有很大可能属于垃圾邮件</span><br><span class="line"># 如果发送邮箱是：mail.tsinghua.edu.cn\mails.tsinghua.edu.cn\cernet.com ,那么邮件有很大可能是属于正常邮件的</span><br><span class="line"># 所以这里根据邮箱的发送运营商，构建一些新的特征属性 </span><br><span class="line">df['from_12'] = pd.Series(map(lambda s: int(s == '12.com'), df['from_address']))</span><br><span class="line">df['from_163'] = pd.Series(map(lambda s: int(s == '163.com'), df['from_address']))</span><br><span class="line">df['from_126'] = pd.Series(map(lambda s: int(s == '126.com'), df['from_address']))</span><br><span class="line">df['from_tom'] = pd.Series(map(lambda s: int(s == 'tom.com'), df['from_address']))</span><br><span class="line">df['from_unknown'] = pd.Series(map(lambda s: int(s == 'unknown'), df['from_address']))</span><br><span class="line">df['from_tsinghua'] = pd.Series(map(lambda s: int(s == 'mail.tsinghua.edu.cn' or s == 'mail.tsinghua.edu.cn'), df['from_address']))</span><br><span class="line">df['from_cernet'] = pd.Series(map(lambda s: int(s == 'cernet.com'), df['from_address']))</span><br><span class="line">df.head(2)</span><br></pre></td></tr></tbody></table></figure></div><h3 id="时间特征处理"><a class="markdownIt-Anchor" href="#时间特征处理"></a> 时间特征处理</h3><p>打印部分数据集中date列格式</p><p>0            Thu 1 Aug 1996 02:09:47 -0500<br>1           Tue 20 Aug 1996 11:43:05 -0400<br>2           Wed 21 Aug 1996 15:14:11 +1000<br>3           Wed 21 Aug 1996 15:14:14 +1000<br>4     Thu 19 Sep 1996 19:21:19 -0400 (EDT)<br>5           Tue 10 Sep 1996 12:47:21 +0700<br>6           Tue 17 Sep 1996 15:45:15 -0400<br>7           Fri 20 Sep 1996 18:59:32 -0540<br>8     Sat 21 Sep 1996 09:59:46 -0400 (EDT)<br>9           Mon 23 Sep 1996 02:56:50 -0540<br>10          Tue 24 Sep 1996 23:39:23 +0700<br>11    Thu 03 Oct 1996 13:47:49 -0500 (CDT)</p><p>发现date列数据集表述方式有多种，长度不同</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">dates = np.unique(list(map(<span class="keyword">lambda</span> t: str(t).strip(), df[<span class="string">'date'</span>])))<span class="comment">#Deduplication(去重数据)</span></span><br><span class="line">date_lengths = np.unique(list(map(<span class="keyword">lambda</span> t: len(t), dates)))<span class="comment">#Deduplication(去重复长度)</span></span><br><span class="line">print(<span class="string">"各个字符串长度:"</span>)<span class="comment">#</span></span><br><span class="line">print(date_lengths)</span><br><span class="line">print(<span class="string">"各个长度对应的时间格式:"</span>)</span><br><span class="line"><span class="keyword">for</span> length <span class="keyword">in</span> date_lengths:</span><br><span class="line">    print(np.unique(list(filter(<span class="keyword">lambda</span> t: len(str(t).strip()) == length, df[<span class="string">'date'</span>]))))</span><br></pre></td></tr></tbody></table></figure></div><p><a href="/img/%E9%9D%A2%E8%AF%95/6.png" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" title="6" data-src="/img/%E9%9D%A2%E8%AF%95/6.png" class="lazyload"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#3、特征工程2 =>邮件的时间提取，难点 正则匹配</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_email_date</span><span class="params">(str1)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(str1,str):  <span class="comment">#判断变量是否是str类型</span></span><br><span class="line">        str1 = str(str1)    <span class="comment">#str类型的强转</span></span><br><span class="line">    str_len = len(str1)</span><br><span class="line"> </span><br><span class="line">    week = <span class="string">""</span></span><br><span class="line">    hour = <span class="string">""</span></span><br><span class="line">    <span class="comment"># 0表示：上午[8,12]；1表示：下午[13,18]；2表示：晚上[19,23]；3表示：凌晨[0,7]</span></span><br><span class="line">    time_quantum = <span class="string">""</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> str_len < <span class="number">10</span>:</span><br><span class="line">        <span class="comment">#unknown</span></span><br><span class="line">        week = <span class="string">"unknown"</span></span><br><span class="line">        hour = <span class="string">"unknown"</span></span><br><span class="line">        time_quantum =<span class="string">"unknown"</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">elif</span> str_len == <span class="number">16</span>:</span><br><span class="line">        <span class="comment"># 2005-9-2 上午10:55</span></span><br><span class="line">        rex = <span class="string">r"(\d{2}):\d{2}"</span>  <span class="comment"># \d  匹配任意数字,这里匹配10:55</span></span><br><span class="line">        it = re.findall(rex,str1)</span><br><span class="line">        <span class="keyword">if</span> len(it) == <span class="number">1</span>:</span><br><span class="line">            hour = it[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            hour = <span class="string">"unknown"</span></span><br><span class="line">        week = <span class="string">"Fri"</span></span><br><span class="line">        time_quantum = <span class="string">"0"</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">elif</span> str_len == <span class="number">19</span>:</span><br><span class="line">        <span class="comment"># Sep 23 2005 1:04 AM</span></span><br><span class="line">        week = <span class="string">"Sep"</span></span><br><span class="line">        hour = <span class="string">"01"</span></span><br><span class="line">        time_quantum = <span class="string">"3"</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">elif</span> str_len == <span class="number">21</span>:</span><br><span class="line">        <span class="comment"># August 24 2005 5:00pm</span></span><br><span class="line">        week = <span class="string">"Wed"</span></span><br><span class="line">        hour = <span class="string">"17"</span></span><br><span class="line">        time_quantum = <span class="string">"1"</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#匹配一个字符开头，+表示至少一次  \d 表示数字   ？表示可有可无  *? 非贪婪模式</span></span><br><span class="line">        rex = <span class="string">r"([A-Za-z]+\d?[A-Za-z]*) .*?(\d{2}):\d{2}:\d{2}.*"</span></span><br><span class="line">        it = re.findall(rex,str1)</span><br><span class="line">        <span class="keyword">if</span> len(it) == <span class="number">1</span> <span class="keyword">and</span> len(it[<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            week = it[<span class="number">0</span>][<span class="number">0</span>][<span class="number">-3</span>:]</span><br><span class="line">            hour = it[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">            int_hour = int(hour)</span><br><span class="line">            <span class="keyword">if</span> int_hour < <span class="number">8</span>:</span><br><span class="line">                time_quantum = <span class="string">"3"</span></span><br><span class="line">            <span class="keyword">elif</span> int_hour < <span class="number">13</span>:</span><br><span class="line">                time_quantum = <span class="string">"0"</span></span><br><span class="line">            <span class="keyword">elif</span> int_hour < <span class="number">19</span>:</span><br><span class="line">                time_quantum = <span class="string">"1"</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                time_quantum = <span class="string">"2"</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            week = <span class="string">"unknown"</span></span><br><span class="line">            hour = <span class="string">"unknown"</span></span><br><span class="line">            time_quantum = <span class="string">"unknown"</span></span><br><span class="line">    week = week.lower()</span><br><span class="line">    hour = hour.lower()</span><br><span class="line">    time_quantum = time_quantum.lower()</span><br><span class="line">    <span class="keyword">return</span> (week,hour,time_quantum)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#数据转换</span></span><br><span class="line">data_time_extract_result = list(map(<span class="keyword">lambda</span> st:extract_email_date(st),df[<span class="string">"date"</span>]))</span><br><span class="line">df[<span class="string">"date_week"</span>] = pd.Series(map(<span class="keyword">lambda</span> t:t[<span class="number">0</span>],data_time_extract_result))</span><br><span class="line">df[<span class="string">"date_hour"</span>] = pd.Series(map(<span class="keyword">lambda</span> t:t[<span class="number">1</span>],data_time_extract_result))</span><br><span class="line">df[<span class="string">"date_time_quantum"</span>] = pd.Series(map(<span class="keyword">lambda</span> t:t[<span class="number">2</span>],data_time_extract_result))</span><br><span class="line">print(df.head(<span class="number">2</span>))</span><br><span class="line"> </span><br><span class="line">print(<span class="string">"=======星期属性字段描述======"</span>)</span><br><span class="line">print(df.date_week.value_counts().head(<span class="number">3</span>))</span><br><span class="line">print(df[[<span class="string">"date_week"</span>,<span class="string">"label"</span>]].groupby([<span class="string">"date_week"</span>,<span class="string">"label"</span>])[<span class="string">"label"</span>].count())</span><br><span class="line"> </span><br><span class="line">print(<span class="string">"=======小时属性字段描述======"</span>)</span><br><span class="line">print(df.date_hour.value_counts().head(<span class="number">3</span>))</span><br><span class="line">print(df[[<span class="string">'date_hour'</span>, <span class="string">'label'</span>]].groupby([<span class="string">'date_hour'</span>, <span class="string">'label'</span>])[<span class="string">'label'</span>].count())</span><br><span class="line"> </span><br><span class="line">print(<span class="string">"=======时间段属性字段描述======"</span>)</span><br><span class="line">print(df.date_hour.value_counts().head(<span class="number">3</span>))</span><br><span class="line">print(df[[<span class="string">"date_time_quantum"</span>,<span class="string">"label"</span>]].groupby([<span class="string">"date_time_quantum"</span>,<span class="string">"label"</span>])[<span class="string">"label"</span>].count())</span><br><span class="line"> </span><br><span class="line"><span class="comment">#添加是否有时间</span></span><br><span class="line">df[<span class="string">"has_date"</span>] = df.apply(<span class="keyword">lambda</span> c: <span class="number">0</span> <span class="keyword">if</span> c[<span class="string">"date_week"</span>] == <span class="string">"unknown"</span> <span class="keyword">else</span> <span class="number">1</span>,axis=<span class="number">1</span>)</span><br><span class="line">print(df.head(<span class="number">2</span>))</span><br></pre></td></tr></tbody></table></figure></div><p>通过对时间提取字段信息的分析，可以得到时间对于垃圾邮件的分类作用不大，在后续的模型训练中可以不考虑该字段的特征属性。同时从数据上我们也可以看出如果一个邮件没有发送时间，那么他极大概率是垃圾邮件，所有可以在最终模型加入这个特征属性，</p><h3 id="邮件内容文本特征数据处理"><a class="markdownIt-Anchor" href="#邮件内容文本特征数据处理"></a> 邮件内容文本特征数据处理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 将文本类型全部转换为str类型，然后进行分词操作</span></span><br><span class="line">df[<span class="string">'content'</span>] = df[<span class="string">'content'</span>].astype(<span class="string">'str'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'jieba_cut_content'</span>] = list(map(<span class="keyword">lambda</span> st: <span class="string">"  "</span>.join(jieba.cut(st)), df[<span class="string">'content'</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征工程四 ==> 邮件长度对是否是垃圾邮件的影响</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precess_content_length</span><span class="params">(lg)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> lg <= <span class="number">10</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">100</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">500</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">1000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">1500</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">2000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">5</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">2500</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">6</span></span><br><span class="line">    <span class="keyword">elif</span> lg <=  <span class="number">3000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">7</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">4000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">8</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">5000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">9</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">10000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">10</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">20000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">11</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">30000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">12</span></span><br><span class="line">    <span class="keyword">elif</span> lg <= <span class="number">50000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">13</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">14</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">'content_length'</span>] = pd.Series(map(<span class="keyword">lambda</span> st: len(st), df[<span class="string">'content'</span>]))</span><br><span class="line">df[<span class="string">'content_length_type'</span>] = pd.Series(map(<span class="keyword">lambda</span> st: precess_content_length(st), df[<span class="string">'content_length'</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看一个各个长度区间段中，正常邮件和异常邮件的样本数目</span></span><br><span class="line">df21 = df.groupby([<span class="string">'content_length_type'</span>, <span class="string">'label'</span>])[<span class="string">'label'</span>].agg([<span class="string">'count'</span>])</span><br><span class="line">print(df21)</span><br></pre></td></tr></tbody></table></figure></div><p>​                       count</p><p>content_length_type label</p><p>0                   0         11</p><p>​                1         16</p><p>1                   0         46</p><p>​                    1        115</p><p>2                   0        545</p><p>​                    1       1035</p><p>3                   0        490</p><p>​                    1        924</p><p>4                   0        452</p><p>​                    1        757</p><p>5                   0        242</p><p>​                    1        366</p><p>6                   0        129</p><p>​                    1        247</p><p>7                   0         97</p><p>​                    1        188</p><p>8                   0        187</p><p>​                    1        354</p><p>9                   0         54</p><p>​                    1        105</p><p>10                  0        149</p><p>​                    1        258</p><p>11                  0         23</p><p>​                    1         57</p><p>12                  0         19</p><p>​                    1         24</p><p>13                  0          2</p><p>​                    1          5</p><p>14                  0          7</p><p>​                      1         13</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">df2 = df21.reset_index()</span><br><span class="line"># 获取垃圾邮件的数据</span><br><span class="line">df3 = df2[df2.label == 1][['content_length_type', 'count']].rename(columns={'count':'c1'})</span><br><span class="line"># 获取正常邮件的数据</span><br><span class="line">df4 = df2[df2.label == 0][['content_length_type', 'count']].rename(columns={'count':'c2'})</span><br><span class="line"># 合并数据</span><br><span class="line">df5 = pd.merge(df3, df4)</span><br><span class="line"># 计算数据占比</span><br><span class="line">df5['c1_rage'] = df5.apply(lambda r: r['c1'] / (r['c1'] + r['c2']), axis=1)</span><br><span class="line">df5['c2_rage'] = df5.apply(lambda r: r['c2'] / (r['c1'] + r['c2']), axis=1)</span><br><span class="line">df5['c3_rage'] = df5.apply(lambda r: r['c2'] / r['c1'], axis=1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(df5.head(10))</span><br><span class="line"># 画图</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c1_rage'], label=u'垃圾邮件比例')</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c2_rage'], label=u'正常邮件比例')</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c3_rage'], label=u'正常邮件/垃圾邮件')</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.legend(loc = 0)</span><br><span class="line">plt.show()</span><br><span class="line">print(df5.head(10))</span><br><span class="line"></span><br><span class="line"># 画图</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c1_rage'], label=u'垃圾邮件比例')</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c2_rage'], label=u'正常邮件比例')</span><br><span class="line">plt.plot(df5['content_length_type'], df5['c3_rage'], label=u'正常邮件/垃圾邮件')</span><br><span class="line">plt.grid(True)</span><br><span class="line">plt.legend(loc = 0)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure></div><p>结果：content_length_type    c1   c2   c1_rage   c2_rage   c3_rage</p><p>0                    0    16   11  0.592593  0.407407  0.687500</p><p>1                    1   115   46  0.714286  0.285714  0.400000</p><p>2                    2  1035  545  0.655063  0.344937  0.526570</p><p>3                    3   924  490  0.653465  0.346535  0.530303</p><p>4                    4   757  452  0.626137  0.373863  0.597094</p><p>5                    5   366  242  0.601974  0.398026  0.661202</p><p>6                    6   247  129  0.656915  0.343085  0.522267</p><p>7                    7   188   97  0.659649  0.340351  0.515957</p><p>8                    8   354  187  0.654344  0.345656  0.528249</p><p>9                    9   105   54  0.660377  0.339623  0.514286<a href="/img/%E9%9D%A2%E8%AF%95/7.png" data-fancybox="group" data-caption="7" class="fancybox"><img alt="7" title="7" data-src="/img/%E9%9D%A2%E8%AF%95/7.png" class="lazyload"></a></p><p>信息量：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#6、特征工程之五 ==> 添加信号量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">precess_content_sema</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> x><span class="number">10000</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span>/np.exp(np.log10(x)-np.log10(<span class="number">500</span>))+np.log(abs(x<span class="number">-500</span>)+<span class="number">1</span>)-np.log(abs(x<span class="number">-10000</span>))+<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span>/np.exp(np.log10(x)-np.log10(<span class="number">500</span>))+np.log(abs(x<span class="number">-500</span>)+<span class="number">1</span>)+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">"content_sema"</span>] = list(map(<span class="keyword">lambda</span> st:precess_content_sema(st),df[<span class="string">"content_length"</span>]))</span><br><span class="line">print(df.head(<span class="number">2</span>))</span><br></pre></td></tr></tbody></table></figure></div><h3 id="特征筛选-写入文件"><a class="markdownIt-Anchor" href="#特征筛选-写入文件"></a> =特征筛选 写入文件</h3><p><a href="http://xn--df-623g5k.info" target="_blank" rel="noopener">通过df.info</a>()查看当前列信息</p><p><class ‘pandas.core.frame.dataframe’></class></p><p>RangeIndex: 6917 entries, 0 to 6916</p><p>Data columns (total 22 columns):</p><p>from                   6916 non-null object</p><p>to                     6889 non-null object</p><p>date                   6914 non-null object</p><p>content                6917 non-null object</p><p>label                  6917 non-null int64</p><p>to_address             6917 non-null object</p><p>from_address           6917 non-null object</p><p>from_12                6917 non-null int64</p><p>from_163               6917 non-null int64</p><p>from_126               6917 non-null int64</p><p>from_tom               6917 non-null int64</p><p>from_unknown           6917 non-null int64</p><p>from_tsinghua          6917 non-null int64</p><p>from_cernet            6917 non-null int64</p><p>date_week              6917 non-null object</p><p>date_hour              6917 non-null object</p><p>date_time_quantum      6917 non-null object</p><p>has_not_date           6917 non-null int64</p><p>jieba_cut_content      6917 non-null object</p><p>content_length         6917 non-null int64</p><p>content_length_type    6917 non-null int64</p><p>content_sema           6917 non-null float64</p><p>dtypes: float64(1), int64(11), object(10)</p><p>memory usage: 1.2+ MB</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 获取需要的列</span></span><br><span class="line"></span><br><span class="line">df.drop([<span class="string">"from"</span>, <span class="string">"to"</span>, <span class="string">"date"</span>, <span class="string">"content"</span>, </span><br><span class="line">         <span class="string">"to_address"</span>, <span class="string">"from_address"</span>, <span class="string">"date_week"</span>, </span><br><span class="line">         <span class="string">"date_hour"</span>, <span class="string">"date_time_quantum"</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.info()</span><br></pre></td></tr></tbody></table></figure></div><p><class ‘pandas.core.frame.dataframe’></class></p><p>RangeIndex: 6917 entries, 0 to 6916</p><p>Data columns (total 13 columns):</p><p>label                  6917 non-null int64</p><p>from_12                6917 non-null int64</p><p>from_163               6917 non-null int64</p><p>from_126               6917 non-null int64</p><p>from_tom               6917 non-null int64</p><p>from_unknown           6917 non-null int64</p><p>from_tsinghua          6917 non-null int64</p><p>from_cernet            6917 non-null int64</p><p>has_not_date           6917 non-null int64</p><p>jieba_cut_content      6917 non-null object</p><p>content_length         6917 non-null int64</p><p>content_length_type    6917 non-null int64</p><p>content_sema           6917 non-null float64</p><p>dtypes: float64(1), int64(11), object(1)</p><p>memory usage: 702.6+ KB</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#结果输出到CSV文件中</span></span><br><span class="line">df.to_csv(<span class="string">"../data/result_process02"</span>,encoding=<span class="string">"utf-8"</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure></div><h2 id="模型效果评估-2"><a class="markdownIt-Anchor" href="#模型效果评估-2"></a> 模型效果评估</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer,TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> TruncatedSVD  <span class="comment">#降维</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> BernoulliNB     <span class="comment">#伯努利分布的贝叶斯公式</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score,precision_score,recall_score</span><br><span class="line"> </span><br><span class="line"><span class="comment">## 设置字符集，防止中文乱码</span></span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>]=[<span class="string">u'simHei'</span>]</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#1、文件数据读取</span></span><br><span class="line">df = pd.read_csv(<span class="string">"../data/result_process02"</span>,encoding=<span class="string">"utf-8"</span>,sep=<span class="string">","</span>)</span><br><span class="line"><span class="comment">#如果有nan值，进行上删除操作</span></span><br><span class="line">df.dropna(axis=<span class="number">0</span>,how=<span class="string">"any"</span>,inplace=<span class="literal">True</span>)    <span class="comment">#删除表中含有任何NaN的行</span></span><br><span class="line">print(df.head())</span><br><span class="line">print(df.info())</span><br><span class="line"> </span><br><span class="line"><span class="comment">#2、数据分割</span></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(df[[<span class="string">"has_date"</span>,<span class="string">"jieba_cut_content"</span>,<span class="string">"content_sema"</span>]],</span><br><span class="line">                                                 df[<span class="string">"label"</span>],test_size=<span class="number">0.2</span>,random_state=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">"训练数据集大小:%d"</span> %x_train.shape[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">"测试数据集大小:%d"</span> %x_test.shape[<span class="number">0</span>])</span><br><span class="line">print(x_train.head())</span><br><span class="line"> </span><br><span class="line"><span class="comment">#3、开始模型训练</span></span><br><span class="line"><span class="comment">#3.1、特征工程，将文本数据转换为数值型数据,TF-idf + svd</span></span><br><span class="line">transformer = TfidfVectorizer(norm=<span class="string">"l2"</span>,use_idf=<span class="literal">True</span>)</span><br><span class="line">svd = TruncatedSVD(n_components=<span class="number">20</span>)     <span class="comment">#奇异值分解，降维</span></span><br><span class="line">jieba_cut_content = list(x_train[<span class="string">"jieba_cut_content"</span>].astype(<span class="string">"str"</span>))</span><br><span class="line">transformer_model = transformer.fit(jieba_cut_content)</span><br><span class="line">df1 = transformer_model.transform(jieba_cut_content)</span><br><span class="line">svd_model = svd.fit(df1)</span><br><span class="line">df2 = svd_model.transform(df1)</span><br><span class="line"> </span><br><span class="line">data = pd.DataFrame(df2)</span><br><span class="line">print(data.head())</span><br><span class="line">print(data.info())</span><br><span class="line"> </span><br><span class="line"><span class="comment">#3.2、数据合并</span></span><br><span class="line">data[<span class="string">"has_date"</span>] = list(x_train[<span class="string">"has_date"</span>])</span><br><span class="line">data[<span class="string">"content_sema"</span>] = list(x_train[<span class="string">"content_sema"</span>])</span><br><span class="line">print(<span class="string">"========数据合并后的data信息========"</span>)</span><br><span class="line">print(data.head())</span><br><span class="line">print(data.info())</span><br><span class="line"> </span><br><span class="line">t1 = time.time()</span><br><span class="line">nb = BernoulliNB(alpha=<span class="number">1.0</span>,binarize=<span class="number">0.0005</span>) <span class="comment">#贝叶斯分类模型构建</span></span><br><span class="line">model = nb.fit(data,y_train)</span><br><span class="line">t = time.time()-t1</span><br><span class="line">print(<span class="string">"贝叶斯模型构建时间为:%.5f ms"</span> %(t*<span class="number">1000</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment">#4.1 对测试数据进行转换</span></span><br><span class="line">jieba_cut_content_test = list(x_test[<span class="string">"jieba_cut_content"</span>].astype(<span class="string">"str"</span>))</span><br><span class="line">data_test = pd.DataFrame(svd_model.transform(transformer_model.transform(jieba_cut_content_test)))</span><br><span class="line">data_test[<span class="string">"has_date"</span>] = list(x_test[<span class="string">"has_date"</span>])</span><br><span class="line">data_test[<span class="string">"content_sema"</span>] = list(x_test[<span class="string">"content_sema"</span>])</span><br><span class="line">print(data_test.head())</span><br><span class="line">print(data_test.info())</span><br><span class="line"> </span><br><span class="line"><span class="comment">#4.2 对测试数据进行测试</span></span><br><span class="line">y_predict = model.predict(data_test)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#5、效果评估</span></span><br><span class="line">print(<span class="string">"准确率为:%.5f"</span> % precision_score(y_test,y_predict))</span><br><span class="line">print(<span class="string">"召回率为:%.5f"</span> % recall_score(y_test,y_predict))</span><br><span class="line">print(<span class="string">"F1值为:%.5f"</span> % f1_score(y_test,y_predict))</span><br></pre></td></tr></tbody></table></figure></div><p>上述是贝叶斯模型预测：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">nb = BernoulliNB(alpha=1.0,binarize=0.0005) #贝叶斯分类模型构建</span><br><span class="line">model = nb.fit(data,y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>SVM模型：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">svc = SVC(C = 1, kernel='rbf', degree=3, gamma=0.001)</span><br><span class="line">model = svc.fit(data, y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>随机森林：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">%%time</span><br><span class="line">forest = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=3, random_state=0)</span><br><span class="line">model = forest.fit(data, y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>KNN：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=2)</span><br><span class="line">model = knn.fit(data, y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>GNDT：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">%%time</span><br><span class="line">gb = GradientBoostingClassifier(learning_rate=0.01, n_estimators=100, max_depth=3, min_samples_split=50, loss='deviance', random_state=0)</span><br><span class="line">model = gb.fit(data, y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>决策树：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">%%time</span><br><span class="line">tree = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=0)</span><br><span class="line">model = tree.fit(data, y_train)</span><br></pre></td></tr></tbody></table></figure></div><p>​</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用python代码工具</title>
      <link href="/2020/03/12/%E5%B8%B8%E7%94%A8python%E4%BB%A3%E7%A0%81%E5%B7%A5%E5%85%B7/"/>
      <url>/2020/03/12/%E5%B8%B8%E7%94%A8python%E4%BB%A3%E7%A0%81%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>#批量更改文件名</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">from functools import cmp_to_key</span><br><span class="line"></span><br><span class="line">def compare(x, y):</span><br><span class="line">    stat_x = os.stat(path + "/" + x)</span><br><span class="line">    stat_y = os.stat(path + "/" + y)</span><br><span class="line">    if stat_x.st_ctime < stat_y.st_ctime:</span><br><span class="line">        return -1</span><br><span class="line">    elif stat_x.st_ctime > stat_y.st_ctime:</span><br><span class="line">        return 1</span><br><span class="line">    else:</span><br><span class="line">        return 0</span><br><span class="line">    </span><br><span class="line">path = r"C:\Users\T470\Desktop\TEST" # (路径需修改)</span><br><span class="line">fileList = os.listdir(path)</span><br><span class="line">fileList.sort(key=cmp_to_key(compare)) # 按存入文件夹时间排序</span><br><span class="line">print("修改前：" + str(fileList)) # 输出此文件夹中包含的所有文件名称</span><br><span class="line"></span><br><span class="line">currentpath = os.getcwd() # 得到进程当前工作目录</span><br><span class="line">os.chdir(path) # 将当前工作目录修改为待修改文件夹的位置</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中所有文件</span><br><span class="line">for i, fileName in enumerate(fileList):</span><br><span class="line">    os.rename(fileName, str(i+1) + '.jpg') # (文件名需修改) </span><br><span class="line"></span><br><span class="line">os.chdir(currentpath) # 改回程序运行前的工作目录</span><br><span class="line">sys.stdin.flush() # 刷新</span><br><span class="line">print("修改后：" + str(os.listdir(path))) # 输出修改后文件夹中包含的所有文件名称</span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机系统基础</title>
      <link href="/2020/03/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/03/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="计算机系统概述"><a class="markdownIt-Anchor" href="#计算机系统概述"></a> 计算机系统概述</h1><h2 id="为什么要学习计算机系统基础"><a class="markdownIt-Anchor" href="#为什么要学习计算机系统基础"></a> 为什么要学习计算机系统基础</h2><p><a href="E:%5Cwowli-up%5CHexo%5Csource%5Cimg%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%5C0-1.png" data-fancybox="group" data-caption="0-1" class="fancybox"><img alt="0-1" data-src="E:%5Cwowli-up%5CHexo%5Csource%5Cimg%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%5C0-1.png" class="lazyload" title="0-1"></a></p><p><strong>为什么要学习“计算机系统基础”呢？</strong></p><p>– <strong>为了编程序时少出错</strong></p><p>– <strong>为了在程序出错时很快找到出错的地方</strong></p><p>– <strong>为了明白程序是怎样在计算机上执行的</strong></p><p>– <strong>为了强化“系统思维”</strong></p><p>– <strong>为了更好地理解计算机系统，从而编写出更好的程序</strong></p><p>– <strong>为后续课程的学习打下良好基础</strong></p><p>– <strong>为了编写出更快的程序</strong></p><p>– <strong>为了更好地认识计算机系统</strong></p><h2 id="计算机基本组成与基本功能"><a class="markdownIt-Anchor" href="#计算机基本组成与基本功能"></a> 计算机基本组成与基本功能</h2><h3 id="冯诺依曼结构计算机模型"><a class="markdownIt-Anchor" href="#冯诺依曼结构计算机模型"></a> 冯·诺依曼结构计算机模型：</h3><p><a href="E:%5Cwowli-up%5CHexo%5Csource%5Cimg%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%5C0-2.png" data-fancybox="group" data-caption="0-2" class="fancybox"><img alt="0-2" data-src="E:%5Cwowli-up%5CHexo%5Csource%5Cimg%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%5C%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%5C0-2.png" class="lazyload" title="0-2"></a></p><h3 id="冯诺依曼结构的主要思想"><a class="markdownIt-Anchor" href="#冯诺依曼结构的主要思想"></a> <strong>冯·诺依曼结构的主要思想</strong></h3><ol><li>计算机应由运算器、控制器、存储器、输入设备和输出设备</li></ol><p>​       五个基本部件组成。</p><ol start="2"><li>各基本部件的功能是：</li></ol><p>​       <strong>存储器</strong>不仅能存放数据，而且也能存放指令，形式上两者没有区别，但计算机应能区分数据还是指令；</p><p>​       <strong>控制器</strong>应能自动取出指令来执行；</p><p>​       <strong>运算器</strong>应能进行加/减/乘/除四种基本算术运算，并且也能进行一些逻辑运算和附加运算；</p><p>​      操作人员可以通过<strong>输入设备、输出设备</strong>和主机进行通信。</p><ol start="3"><li><p>内部以<strong>二进制表示</strong>指令和数据。每条指令由操作码和地址码两部分组成。操作码指出操作类型，地址码指出操作数的地址。由一串指令组成程序。</p></li><li><p>采用**“存储程序**”工作方式。</p><h3 id="认识计算机中最基本的部件"><a class="markdownIt-Anchor" href="#认识计算机中最基本的部件"></a> <strong>认识计算机中最基本的部件</strong></h3><p>CPU：中央处理器；PC：程序计数器；MAR：存储器地址寄存器</p><p>ALU：算术逻辑部件；IR：指令寄存器；MDR：存储器数据寄存器</p><p>GPRs：通用寄存器组（由若干通用寄存器组成，早期就是累加器）</p></li></ol><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-3.png" data-fancybox="group" data-caption="0-3" class="fancybox"><img alt="0-3" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-3.png" class="lazyload" title="0-3"></a></p><h3 id="计算机是如何工作的"><a class="markdownIt-Anchor" href="#计算机是如何工作的"></a> <strong>计算机是如何工作的？</strong></h3><p><strong>程序由指令组成</strong></p><p>程序在执行前 数据和指令事先存放在存储器中，每条指令和每个数据都有地址，指令按序存放，指令由OP、ADDR字段组成，程序起始地址置PC</p><p><strong>开始执行程序</strong></p><p>第一步：根据PC取指令</p><p>（从5号架上取菜谱）</p><p>第二步：指令译码（看菜谱）</p><p>第三步：取操作数（从架上或盘中取原材料）</p><p>第四步：指令执行（洗、切、炒等具体操作）</p><p>第五步：回写结果（装盘或直接送桌）</p><p>第六步：修改PC的值（算出下一菜谱所在架子号6=5+1）</p><p>继续执行下一条指令（继续做下一道菜）</p><p><strong>指令和数据</strong></p><p>程序启动前，指令和数据都存放在存储器中，形式上没有差别， 都是0/1序列</p><p>• 采用”存储程序“工作方式：</p><p>– 程序由指令组成，程序被启动后，计算机能自动取出一条一条指令执行，在执行过程中无需人的干预。</p><p>• 指令执行过程中，指令和数据被从存储器取到CPU，存放在CPU内的寄存器中，指令在IR中，数据在GPR中。</p><p>指令中需给出的信息：</p><ol><li>操作性质（操作码）</li><li>（单目运算，双目运算） 源操作数1 或/和 源操作数2 （立即数、寄存器编号、存储地址）</li><li>目的操作数地址 （寄存器编号、存储地址）</li></ol><p>存储地址的描述与操作数的数据结构有关</p><p><strong>计算机的基本组成与基本功能</strong></p><p>• <strong>什么是计算机？</strong></p><p>–计算机是一种能对数字化信息进行自动、高速算术和逻辑运算的处理装置。</p><p>• <strong>计算机的基本部件及功能：</strong></p><p>–运算器（数据运算）：ALU、GPRs、标志寄存器等</p><p>–存储器（数据存储）：存储阵列、地址译码器、读写控制电 路</p><p>–总线（数据传送）：数据(MDR)、地址(MAR)和控制线</p><p>–控制器（控制）：对指令译码生成控制信号</p><p>• <strong>计算机实现的所有任务都是通过执行一条一条指令完成</strong></p><h2 id="程序开发和执行过程简介"><a class="markdownIt-Anchor" href="#程序开发和执行过程简介"></a> 程序开发和执行过程简介</h2><h3 id="最早的程序开发过程"><a class="markdownIt-Anchor" href="#最早的程序开发过程"></a> <strong>最早的程序开发过程</strong></h3><p>用<strong>机器语言</strong>编写程序，并记录在纸带或卡片上,穿孔表示0，未穿孔表示1</p><h3 id="用汇编语言开发程序"><a class="markdownIt-Anchor" href="#用汇编语言开发程序"></a> <strong>用汇编语言开发程序</strong></h3><p>优点：不会因为增减指令而需要修改其他指令.不需记忆指令编码，编写方便,可读性比机器语言强</p><h3 id="这带来新的问题"><a class="markdownIt-Anchor" href="#这带来新的问题"></a> <strong>这带来新的问题</strong></h3><p>人容易了，可机器不认识这些指令了！-需将汇编语言转换为机器语言用汇编程序转换</p><h3 id="进一步认识机器级语言"><a class="markdownIt-Anchor" href="#进一步认识机器级语言"></a> <strong>进一步认识机器级语言</strong></h3><p>汇编语言(源)程序由汇编指令构成</p><p><strong>汇编指令</strong>：用助记符和标号来表示的指令(与机器指令一一对应)</p><p><strong>指令</strong>：</p><p>​      <strong>包含操作码和操作数或其地址码</strong>（机器指令用二进制表示，汇编指令用符号表示）</p><p>​       <strong>描述：取（或存一个数） 两个数加（或减、乘、除、与、或等）</strong></p><p><strong>根据运算结果判断是否转移执行</strong></p><p><strong>结论</strong>：<strong>用汇编语言比机器语言好，但是，还是很麻烦！</strong></p><h3 id="用高级语言开发程序"><a class="markdownIt-Anchor" href="#用高级语言开发程序"></a> <strong>用高级语言开发程序</strong></h3><p><strong>随着技术的发展，出现了许多高级编程语言</strong></p><ol><li><p>它们与具体机器结构无关</p></li><li><p>面向算法描述，比机器级语言描述能力强得多</p></li><li><p>高级语言中一条语句对应几条、几十条甚至几百条指令</p></li><li><p>有“面向过程”和“面向对象”的语言之分</p></li><li><p>处理逻辑分为三种结构: 顺序结构、选择结构、循环结构</p></li><li><p>有两种转换方式：“编译”和“解释”</p><p>• 编译程序(Complier)：将高级语言源程序转换为机器级目 标程序，执行时只要启动目标程序即可</p><p>• 解释程序(Interpreter )：将高级语言语句逐条翻译成机器 指令并立即执行，不生成目标文件。</p></li></ol><h3 id="一个典型程序的转换处理过程0-4"><a class="markdownIt-Anchor" href="#一个典型程序的转换处理过程0-4"></a> <strong>一个典型程序的转换处理过程</strong><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-4.png" data-fancybox="group" data-caption="0-4" class="fancybox"><img alt="0-4" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-4.png" class="lazyload" title="0-4"></a></h3><h3 id="hello程序的数据流动过程0-5"><a class="markdownIt-Anchor" href="#hello程序的数据流动过程0-5"></a> <strong>Hello程序的数据流动过程</strong><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-5.png" data-fancybox="group" data-caption="0-5" class="fancybox"><img alt="0-5" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-5.png" class="lazyload" title="0-5"></a></h3><p><strong>数据经常在各存储部件间传送。故现代计算机大多采用“缓存”技术！</strong></p><p><strong>所有过程都是在CPU执行指令所产生的控制信号的作用下进行的。</strong></p><h3 id="不同层次语言之间的等价转换0-6"><a class="markdownIt-Anchor" href="#不同层次语言之间的等价转换0-6"></a> <strong>不同层次语言之间的等价转换</strong><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-6.png" data-fancybox="group" data-caption="0-6" class="fancybox"><img alt="0-6" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-6.png" class="lazyload" title="0-6"></a></h3><p><strong>任何高级语言程序最终通过执行若干条指令来完成！</strong></p><p><strong>开发和运行程序需什么支撑？<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-7_ys.png" data-fancybox="group" data-caption="0-7_ys" class="fancybox"><img alt="0-7_ys" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-7_ys.png" class="lazyload" title="0-7_ys"></a></strong></p><h2 id="计算机系统层次架构"><a class="markdownIt-Anchor" href="#计算机系统层次架构"></a> 计算机系统层次架构</h2><h3 id="早期计算机系统的层次"><a class="markdownIt-Anchor" href="#早期计算机系统的层次"></a> <strong>早期计算机系统的层次</strong></h3><h4 id="最早的计算机用机器语言编程"><a class="markdownIt-Anchor" href="#最早的计算机用机器语言编程"></a> 最早的计算机用机器语言编程</h4><p>机器语言称为第一代程序设计语言（First generation programming</p><p>language ，1GL ）<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-8.png" data-fancybox="group" data-caption="0-8" class="fancybox"><img alt="0-8" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-8.png" class="lazyload" title="0-8"></a></p><h4 id="后来用汇编语言编程"><a class="markdownIt-Anchor" href="#后来用汇编语言编程"></a> 后来用汇编语言编程</h4><p>汇编语言称为第二代程序设计语言（Second generation programming</p><p>language ，2GL ）<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-9.png" data-fancybox="group" data-caption="0-9" class="fancybox"><img alt="0-9" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-9.png" class="lazyload" title="0-9"></a></p><h3 id="现代传统计算机系统的层次"><a class="markdownIt-Anchor" href="#现代传统计算机系统的层次"></a> <strong>现代（传统）计算机系统的层次</strong></h3><h4 id="现代计算机用高级语言编程"><a class="markdownIt-Anchor" href="#现代计算机用高级语言编程"></a> <strong>现代计算机用高级语言编程</strong></h4><p>第三代程序设计语言（3GL）为过程式语言，编码时需要描述实现过程，即</p><p>“如何做”。第四代程序设计语言（4GL） 为非过程化语言，编码时只需说明</p><p>“做什么”， 不需要描述具体的算法实现细节。<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-10.png" data-fancybox="group" data-caption="0-10" class="fancybox"><img alt="0-10" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-10.png" class="lazyload" title="0-10"></a></p><p>语言处理系统包括：各种语言处理程序（如编译、汇编、链接）、运行时系统（如库函数，调试、优化等功能）</p><p>操作系统包括人机交互界面、 提供服务功能的内核例程</p><p><strong>可以看出：语言的发展是一个不断“抽象”的过程，因而，相应的计算机系统也不断有新的层次出现</strong></p><h3 id="计算机系统的不同用户"><a class="markdownIt-Anchor" href="#计算机系统的不同用户"></a> <strong>计算机系统的不同用户</strong></h3><ol><li>最终用户工作在由应用程序提供的最上面的抽象层</li><li>系统管理员工作在由操作系统提供的抽象层</li><li>应用程序员工作在由语言处理系统（主要有编译器和汇编器）的抽象层</li><li>语言处理系统建立在操作系统之上</li><li>系统程序员（实现系统软件）工作在ISA层次，必须对ISA非常了解</li><li>编译器和汇编器的目标程序由机器级代码组成</li><li>操作系统通过指令直接对硬件进行编程控制</li><li>ISA处于软件和硬件的交界面（接口）ISA是对硬件的抽象</li></ol><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-11.png" data-fancybox="group" data-caption="0-11" class="fancybox"><img alt="0-11" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-11.png" class="lazyload" title="0-11"></a></p><h3 id="指令集体系结构isa"><a class="markdownIt-Anchor" href="#指令集体系结构isa"></a> <strong>指令集体系结构（ISA）</strong></h3><p>ISA指Instruction Set Architecture，即指令集体系结构，有时简称为指令系统</p><p>ISA是一种规约（Specification），它规定了如何使用硬件</p><ol><li>可执行的指令的集合，包括指令格式、操作种类以及每种操作对应的操作数的相应规定；</li><li>指令可以接受的操作数的类型</li><li>操作数所能存放的寄存器组的结构，包括每个寄存器的名称、编号、长度和用途；</li><li>操作数所能存放的存储空间的大小和编址方式；</li><li>操作数在存储空间存放时按照大端还是小端方式存放；</li><li>指令获取操作数的方式，即寻址方式；</li><li>指令执行过程的控制方式，包括程序计数器（PC）、条件码定义等。</li></ol><p><strong>• ISA在通用计算机系统中是必不可少的一个抽象层，Why？</strong></p><p>没有它，软件无法使用计算机硬件！</p><p>没有它，一台计算机不能称为“通用计算机”</p><h3 id="isa和计算机组成organization即microarchitecture是何关系0-12"><a class="markdownIt-Anchor" href="#isa和计算机组成organization即microarchitecture是何关系0-12"></a> ISA和计算机组成（Organization，即MicroArchitecture）是何关系？<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-12.png" data-fancybox="group" data-caption="0-12" class="fancybox"><img alt="0-12" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-12.png" class="lazyload" title="0-12"></a></h3><h1 id="数据的表示和存储"><a class="markdownIt-Anchor" href="#数据的表示和存储"></a> 数据的表示和存储</h1><h2 id="数制和编码"><a class="markdownIt-Anchor" href="#数制和编码"></a> 数制和编码</h2><h3 id="转换的概念在数据表示中的反映"><a class="markdownIt-Anchor" href="#转换的概念在数据表示中的反映"></a> <strong>“转换”的概念在数据表示中的反映</strong></h3><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1.1.png" data-fancybox="group" data-caption="1.1" class="fancybox"><img alt="1.1" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1.1.png" class="lazyload" title="1.1"></a></p><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-2.png" data-fancybox="group" data-caption="1-2" class="fancybox"><img alt="1-2" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-2.png" class="lazyload" title="1-2"></a></p><h3 id="信息的二进制编码"><a class="markdownIt-Anchor" href="#信息的二进制编码"></a> <strong>信息的二进制编码</strong></h3><p><strong>机器级数据分两大类</strong></p><ol><li>数值数据：无符号整数、带符号整数、浮点数（实数） –</li><li>非数值数据：逻辑数（包括位串）、西文字符和汉字 •</li></ol><p>计算机内部所有信息都用二进制（即：0和1）进行编码 •</p><p><strong>用二进制编码的原因</strong></p><ol><li>制造二个稳定态的物理器件容易(电位高/低，脉冲有/无，正/负极)</li><li>二进制编码、计数、运算规则简单</li><li>正好与逻辑命题真/假对应，便于逻辑运算</li><li>可方便地用逻辑电路实现算术运算</li></ol><p>• 真值和机器数 ( 非常重要的概念！)</p><ol><li>机器数：用0和1编码的计算机内部的0/1序列 –</li><li>真值：真正的值，即：现实中带正负号的数</li></ol><p>例：unsigned short型变量x的真值是127，其机器数是多少？</p><p>127=27-1，其机器数为0000 0000 0111 1111</p><p><strong>机器数</strong></p><p>一个数在计算机中的二进制表示形式，叫做这个数的机器数。机器数是带符号的，在计算机用机器数的<strong>最高位</strong>存放符号，正数为0，负数为1。</p><p>比如，十进制中的数 +3 ，<strong>计算机字长为8位</strong>，转换成二进制就是0000 0011。如果是 -3 ，就是 100 00011 。</p><p>那么，这里的 0000 0011 和 1000 0011 就是机器数。</p><p><strong>真值</strong></p><p>因为第一位是符号位，所以机器数的形式值就不等于真正的数值。</p><p>例如上面的有符号数 1000 0011，其最高位1代表负，其真正数值是 -3，而不是形式值131（1000 0011转换成十进制等于131）。所以，为区别起见，<strong>将带符号位的机器数对应的真正数值</strong>称为<strong>机器数的真值</strong>。</p><p>例：0000 0001的真值 = +000 0001 = +1，1000 0001的真值 = –000 0001 = –1</p><h3 id="数值数据的表示"><a class="markdownIt-Anchor" href="#数值数据的表示"></a> <strong>数值数据的表示</strong></h3><p><strong>数值数据表示的三要素</strong></p><ol><li>进位计数制</li><li>定、浮点表示</li><li>如何用二进制编码</li></ol><p>即：要确定一个数值数据的值必须先确定这三个要素。</p><p>例如，20137564的值是多少？  答案：无法确定</p><p><strong>• 进位计数制</strong></p><p>–十进制、二进制、十六进制、八进制数及其相互转换</p><p><strong>• 定/浮点表示（解决小数点问题）</strong></p><ol><li>定点整数、定点小数</li><li>浮点数（可用一个定点小数和一个定点整数来表示）</li></ol><p><strong>• 定点数的编码</strong>（解决正负号问题）</p><p>原码、补码、反码、移码 （反码很少用）</p><h3 id="r进位计数制1-3"><a class="markdownIt-Anchor" href="#r进位计数制1-3"></a> <strong>R进位计数制</strong><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-3.png" data-fancybox="group" data-caption="1-3" class="fancybox"><img alt="1-3" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-3.png" class="lazyload" title="1-3"></a></h3><h3 id="八进制和十六进制"><a class="markdownIt-Anchor" href="#八进制和十六进制"></a> <strong>八进制和十六进制</strong></h3><p>日常生活中用十进制表示数值，计算机中用二进制表示所有信息！那为什么还要引入 八进制 / 十六进制呢？</p><p>​        八进制 / 十六进制是二进制的简便表示。便于阅读和书写！它们之间对应简单，转换容易。</p><p>​        在机器内部用二进制表示，在屏幕或其他设备上表示时，转换为八 进制/十六进制数，可缩短长度。</p><p>八进制：Octal （用后缀“O”表示） 十六进制：Hexadecimal （用后缀“H”，或前缀“0x”表示）</p><p>例：1010 1100 0100 0101 0001 0000 1000 1101B可写成</p><p>0xac45108d 0xAC45108D 或 ac45108dH AC45108DH</p><p>或 8进制：25421210215O</p><p>010 101 100 010 001 010 001 000 010 001 101</p><p>现代计算机系统多用十六进制表示机器数</p><h3 id="十进制数与r进制数之间的转换"><a class="markdownIt-Anchor" href="#十进制数与r进制数之间的转换"></a> <strong>十进制数与R进制数之间的转换</strong></h3><ol><li>R进制数 => 十进制数</li></ol><p>按“权”展开</p><p>(2)十进制数 => 二进制数，再将二进制转换为16或8进制</p><p>整数部分和小数部分分别转换</p><h3 id="举例十进制数与8进制数之间的转换"><a class="markdownIt-Anchor" href="#举例十进制数与8进制数之间的转换"></a> <strong>举例：十进制数与8进制数之间的转换</strong></h3><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-4.jpg" data-fancybox="group" data-caption="1-4" class="fancybox"><img alt="1-4" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-4.jpg" class="lazyload" title="1-4"></a></p><p>可能小数部分总得不到0，此时得到一个近似值</p><p>说明：现实中的精确值可能在机器内部无法用0和1精确表示！</p><h3 id="定点数和浮点数"><a class="markdownIt-Anchor" href="#定点数和浮点数"></a> <strong>定点数和浮点数</strong></h3><p>计算机中只有0和1，数值数据中的小数点怎么表示呢？</p><p>​       计算机中只能通过约定小数点的位置来表示</p><ol><li>小数点位置约定在固定位置的数称为定点数</li><li>小数点位置约定为可浮动的数称为浮点数</li></ol><p>定点小数用来表示浮点数的尾数部分</p><p>定点整数用来表示整数，分带符号整数和无符号整数</p><p>任何实数：X=(-1)s ×M×RE</p><p>其中，S取值为0或1，用来决定数X的符号；M是一个二进制定点小数，称为数X的尾数（mantissa）；E是一个二进制定点整数，称为数X的阶或指数（exponent）；R是基数（radix、base），可以为2、4和16等。 计算机中只要表示S、M和E三个信息，就能确定X的值，这称为浮点数</p><p><strong><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-5.png" data-fancybox="group" data-caption="1-5" class="fancybox"><img alt="1-5" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-5.png" class="lazyload" title="1-5"></a>结论：要解决数值数据的表示问题，只要解决定点数的编码问题！</strong></p><h2 id="定点数的编码表示"><a class="markdownIt-Anchor" href="#定点数的编码表示"></a> 定点数的编码表示</h2><p><a href="https://zhuanlan.zhihu.com/p/91967268" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/91967268</a></p><h3 id="补码-模运算modular运算"><a class="markdownIt-Anchor" href="#补码-模运算modular运算"></a> <strong>补码 - 模运算（modular运算）</strong></h3><p>重要概念：在一个模运算系统中，一个数与它除以“模”后的余数等价。</p><p>一个负数的补码等于模减该负数的绝对值。</p><p>对于某一确定的模，某数减去小于模的另一数，总可以用该数加上另一数负数的补码来代替。</p><p><strong>补码（modular运算）：+ 和– 的统一</strong></p><p>32位机器中，int、short、char型数据的机器数各占32位、16位、8位</p><h3 id="变形补码的表示"><a class="markdownIt-Anchor" href="#变形补码的表示"></a> <strong>变形补码的表示</strong></h3><p>补码定义：[X]补= <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.664392em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span> + X  （-<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.664392em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>≤X＜<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.664392em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>，mod <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.664392em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>）</p><p>• 正数：符号位（sign bit）为0，数值部分不变</p><p>• 负数：符号位为1，数值部分“各位取反，末位加1”</p><p><strong>变形补码：双符号，用于存放可能溢出的中间结果。</strong></p><h3 id="移码表示"><a class="markdownIt-Anchor" href="#移码表示"></a> <strong>移码表示</strong></h3><p><strong>什么是移码表示？</strong></p><p><strong>将每一个数值加上一个偏置常数（</strong> <strong>Excess / bias</strong>**）**</p><p>通常，当编码位数为n时，bias取<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">2^{n-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>或<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">2^{n-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>-1（如 IEEE 754）</p><p>为什么要用移码来表示指数（阶码）?</p><p>便于浮点数加减运算时的对阶操作（比较大小）</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1.01</mn><mo>∗</mo><msup><mn>2</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mn>1.11</mn><mo>∗</mo><msup><mn>2</mn><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">1.01*2^{-1}+1.11*2^{3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">1</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span>$              $1.01*2<sup>{-1+4}+1.11*2</sup>{3+4} $</p><p>补码：111<011 ?                          移码 ：011<000</p><p>​         (-1)    (3)                                      (3)     (7)</p><h2 id="c语言中的整数"><a class="markdownIt-Anchor" href="#c语言中的整数"></a> C语言中的整数</h2><h3 id="c语言支持的基本数据类型"><a class="markdownIt-Anchor" href="#c语言支持的基本数据类型"></a> <strong>C语言支持的基本数据类型</strong></h3><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-6.png" data-fancybox="group" data-caption="1-6" class="fancybox"><img alt="1-6" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-6.png" class="lazyload" title="1-6"></a></p><p><strong>整数类型分：无符号整数和带符号整数</strong></p><h3 id="无符号整数-unsigned-integer"><a class="markdownIt-Anchor" href="#无符号整数-unsigned-integer"></a> <strong>无符号整数 (Unsigned integer)</strong></h3><p>机器中字的位排列顺序有两种方式：</p><ol><li>高到低位从左到右：</li><li>高到低位从右到左：</li><li>Leftmost 和 rightmost 这 两 个 词 有 歧 义 ， 故 用</li><li>LSB(Least Significant Bit)来表示最低有效位，用MSB来表示最高有效位</li><li>– 高位到低位多采用从左往右排列</li></ol><p>• 一般在全部是正数运算且不出现负值结果的场合下，可使用无符号数表示。例如，地址运算，编号表示，等等</p><p>• 无符号整数的编码中没有符号位</p><p>• 能表示的最大值大于位数相同的带符号整数的最大值（Why？）</p><p>– 例如，8位无符号整数最大是255（1111 1111）</p><p>而8位带符号整数最大为127（0111 1111）</p><p>• 总是整数，所以很多时候就简称为“无符号数”</p><h3 id="带符号整数signed-integer"><a class="markdownIt-Anchor" href="#带符号整数signed-integer"></a> <strong>带符号整数（Signed integer）</strong></h3><p>计算机必须能处理正数(positive) 和负数(negative)，用MSB表示数符（0–正数，1–负数）</p><p>有三种定点编码方式</p><p>Signed and magnitude （原码）</p><p>​      定点小数，用来表示浮点数的尾数</p><p>Excess (biased) notion （移码）</p><p>​          定点整数，用于表示浮点数的阶（指数）</p><p>Two’s complement （补码）</p><p>​            50年代以来，所有计算机都用补码来表示带符号整数</p><p>• 为什么用补码表示带符号整数？</p><ol><li>补码运算系统是模运算系统，加、减运算统一</li><li>数0的表示唯一，方便使用</li><li>比原码多表示一个最小负数</li></ol><h3 id="c语言程序中的整数"><a class="markdownIt-Anchor" href="#c语言程序中的整数"></a> <strong>C语言程序中的整数</strong></h3><p>无符号数：unsigned int ( short / long)；带符号整数： int ( short / long)</p><p>常在一个数的后面加一个“u”或“U”表示无符号数</p><p>若同时有无符号和带符号整数，则C编译器将带符号整数强制转换为无符号数</p><p>编译器处理常量时默认的类型：<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-7.png" data-fancybox="group" data-caption="1-7" class="fancybox"><img alt="1-7" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-7.png" class="lazyload" title="1-7"></a></p><p>1）在有些32位系统上，C表达式-2147483648 < 2147483647的执行结</p><p>果为false。Why？</p><p>2）若定义变量“int i=-2147483648;”，则“i < 2147483647”的执行</p><p>结果为true。Why？</p><p>3）如果将表达式写成“-2147483647-1 < 2147483647”，则结果会怎样呢？Why？</p><p>1）2147483648已经超出了int的范围，会按照unsigned int进行比较,一元负运算符应用于无符号类型，仍为无符号类型</p><p>在ISO C90标准下 ，2147483648为unsigned int型，因此“-2147483648 < 2147483647”按无符号数比较，</p><p>10……0B比01……1B大，结果为false。在ISO C99标准下 ，2147483648为long long型，因此“-2147483648 < 2147483647”按带符号整数比较，10……0B比01……1B小，结果为true。</p><p>2）i < 2147483647 按int型数比较，结果为true。</p><p>3）-2147483647-1 < 2147483647 按int型比较，结果为true。<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-8.jpg" data-fancybox="group" data-caption="1-8" class="fancybox"><img alt="1-8" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-8.jpg" class="lazyload" title="1-8"></a></p><h2 id="浮点数的编码表示"><a class="markdownIt-Anchor" href="#浮点数的编码表示"></a> <strong>浮点数的编码表示</strong></h2><p><strong>实数类型分：单精度浮点、浮点双精度和扩展精度浮点<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-9.png" data-fancybox="group" data-caption="1-9" class="fancybox"><img alt="1-9" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-9.png" class="lazyload" title="1-9"></a></strong></p><h2 id="非数值数据的编码表示"><a class="markdownIt-Anchor" href="#非数值数据的编码表示"></a> <strong>非数值数据的编码表示</strong></h2><h3 id="西文字符的编码表示"><a class="markdownIt-Anchor" href="#西文字符的编码表示"></a> <strong>西文字符的编码表示</strong></h3><p>特点</p><ol><li>是一种拼音文字，用有限几个字母可拼写出所有单词</li><li>只需对有限个字母和数学符号、标点符号等辅助字符编码</li><li>所有字符总数不超过256个，使用7或8个二进位可表示</li></ol><p>• 表示（常用编码为7位ASCII码）</p><ol><li>十进制数字：0/1/2…/9</li><li>英文字母：A/B/…/Z/a/b/…/z</li><li>专用符号：+/-/%/*/&/……</li><li>控制字符（不可打印或显示）</li></ol><p>• 操作</p><p>​             字符串操作，如:传送/比较</p><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-10.png" data-fancybox="group" data-caption="1-10" class="fancybox"><img alt="1-10" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-10.png" class="lazyload" title="1-10"></a></p><h3 id="汉字及国际字符的编码表示"><a class="markdownIt-Anchor" href="#汉字及国际字符的编码表示"></a> <strong>汉字及国际字符的编码表示</strong></h3><p>汉字特点</p><ol><li>汉字是表意文字，一个字就是一个方块图形。</li><li>汉字数量巨大，总数超过6万字，给汉字在计算机内部的表示、</li><li>汉字的传输与交换、汉字的输入和输出等带来了一系列问题。</li></ol><p>编码形式</p><p>–有以下几种汉字代码：</p><ol><li>输入码：对汉字用相应按键进行编码表示，用于输入</li><li>内码：用于在系统中进行存储、查找、传送等处理</li><li>字模点阵或轮廓描述: 描述汉字字模点阵或轮廓，用于显示/打印</li></ol><h3 id="gb2312-80字符集"><a class="markdownIt-Anchor" href="#gb2312-80字符集"></a> <strong>GB2312-80字符集</strong></h3><p>由三部分组成</p><ol><li>字母、数字和各种符号，包括英文、俄文、日文平假名与片假名、罗马字母、汉语拼音等共687个</li><li>一级常用汉字，共3755个，按汉语拼音排列</li><li>二级常用汉字，共3008个 ，不太常用，按偏旁部首排列</li></ol><p>• 汉字的区位码</p><ol><li>码表由94行、94列组成，行号为区号，列号为位号，各占7位</li><li>指出汉字在码表中的位置，共14位，区号在左、位号在右</li></ol><p>汉字的国标码</p><ol><li>每个汉字的区号和位号各自加上32（20H），得到其“国标码”</li><li>国标码中区号和位号各占7位。在计算机内部，为方便处理与存储，前面添一个0，构成一个字节</li></ol><h3 id="汉字内码"><a class="markdownIt-Anchor" href="#汉字内码"></a> <strong>汉字内码</strong></h3><p>至少需2个字节才能表示一个汉字内码。为什么？</p><p>​                       –由汉字的总数（超过6万字）决定！</p><p>• 可在GB2312国标码的基础上产生汉字内码</p><p>为与ASCII码区别，将国标码的两个字节的第一位置“1”后得到一种汉字内码（可以有不同的编码方案）</p><p>例：汉字“大”在码表中位于第20行、第83列。因此区位码为0010100 1010011</p><p>，在区、位码上各加32得到两个字节编码，即00110100 01110011B=3473H。前面的34H和字符“4”的ACSII码相同，后面的73H和字符“s”的ACSII码相同，但是，将每个字节的最高位各设为“1”后，就得到其内码：B4F3H (1011010011110011B)，因而不会和ASCII码混淆。</p><h3 id="多媒体信息的表示"><a class="markdownIt-Anchor" href="#多媒体信息的表示"></a> <strong>多媒体信息的表示</strong></h3><p>图形、图像、音频、视频等信息在机器内部也用0和1表示</p><ol><li>图形用构建图形的直线或曲线的坐标点及控制点来描述，而这些 坐标点或控制点则用数值数据描述</li><li>图像用构成图像的点（像素）的亮度、颜色或灰度等信息来描述 ，这些亮度或颜色等值则用数值数据描述</li><li>音频信息通过对模拟声音进行采样、量化（用二进制编码）来获 得，因此量化后得到的是一个数值数据序列（随时间变化）</li><li>视频信息描述的是随时间变化的图像（每一幅图像称为一帧）</li><li>音乐信息（MIDI）通过对演奏的乐器、乐谱等相关的各类信息用 0和1进行编码来描述</li></ol><p>多媒体信息用一个复杂的数据结构来描述，其中的基本数据或者 是数值数据，或者是用0/1编码的非数值数据</p><h2 id="数据宽度和存储容量的单位"><a class="markdownIt-Anchor" href="#数据宽度和存储容量的单位"></a> <strong>数据宽度和存储容量的单位</strong></h2><h3 id="数据的基本宽度"><a class="markdownIt-Anchor" href="#数据的基本宽度"></a> <strong>数据的基本宽度</strong></h3><p>• 比特（bit，位）是计算机中处理、存储、传输信息的最小单位</p><p>• 二进制信息最基本的计量单位是“字节”(Byte)</p><p>​            –现代计算机中，存储器按字节编址</p><p>​            –字节是最小可寻址单位 (addressable unit )</p><p>​             –如果以字节为一个排列单位，则LSB表示最低有效字节，MSB</p><p>​               表示最高有效字节</p><p>• 除比特（位）和字节外，还经常使用“字”(word) 作为单位</p><p>–“字”和 “字长”的概念不同</p><p>IA-32中的“字”有多少位？  16位      字长多少位呢？ 32位</p><p>​      DWORD ：32位</p><p>​      QWORD：64位</p><p>“字”和 “字长”的概念不同</p><p>–“字长”指数据通路的宽度。</p><p>​              ”字长”等于CPU内部总线的宽度、运算器的位数、通用</p><p>​                寄存器的宽度（这些部件的宽度都是一样的）</p><p>–“字”表示被处理信息的单位，用来度量数据类型的宽度</p><p>–字和字长的宽度可以一样，也可不同</p><p>例1：对于x86体系结构，不管字长多少，定义“字”的宽度都为16位，而从386开始字长就是32位了。</p><p>例2：对于MIPS 32体系结构，其字和字长都是32位</p><h3 id="数据通路的宽度"><a class="markdownIt-Anchor" href="#数据通路的宽度"></a> <strong>数据通路的宽度</strong></h3><p>数据通路指CPU内部数据流经的路径以及路径上的部件，主要是CPU内部进行数据运算、存储和传送的部件，这些部件的宽度基本上要一致，才能相互匹配。<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-3.png" data-fancybox="group" data-caption="0-3" class="fancybox"><img alt="0-3" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/0-3.png" class="lazyload" title="0-3"></a></p><h3 id="程序中数据类型的宽度1-11"><a class="markdownIt-Anchor" href="#程序中数据类型的宽度1-11"></a> <strong>程序中数据类型的宽度<a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-11.png" data-fancybox="group" data-caption="1-11" class="fancybox"><img alt="1-11" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-11.png" class="lazyload" title="1-11"></a></strong></h3><p>从表中看出：同类型数据并不是所有机器都采用相同的宽度，分配的字节数</p><p>随ISA、机器字长和编译器的不同而不同。</p><p>例如，ANSI C标准未规定long double的确切精度，所以对于不同平台有不同的实现。有的是8字节，有的是10字节，有的是12字节或16字节。</p><h2 id="数据存储时的字节排列"><a class="markdownIt-Anchor" href="#数据存储时的字节排列"></a> <strong>数据存储时的字节排列</strong></h2><p>• 需要考虑以下问题：</p><p>–变量的地址是其最大地址还是最小地址？</p><p>​           最小地址，即x存放在100#~103#！</p><p>–多个字节在存储单元中存放的顺序如何？</p><p>​          大端方式/小端方式</p><h3 id="数据的存储和排列顺序"><a class="markdownIt-Anchor" href="#数据的存储和排列顺序"></a> <strong>数据的存储和排列顺序</strong></h3><p><a href="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-12.png" data-fancybox="group" data-caption="1-12" class="fancybox"><img alt="1-12" data-src="../img/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/1-12.png" class="lazyload" title="1-12"></a></p><h3 id="字节交换问题"><a class="markdownIt-Anchor" href="#字节交换问题"></a> <strong>字节交换问题</strong></h3><p>存放方式不同的机器间程序移植或数据通信时，会发生什么问题？</p><p>​      每个系统内部是一致的，但在系统间通信时可能会发生问题！</p><p>​       因为顺序不同，需要进行顺序转换</p><p>音、视频和图像等文件格式或处理程序都涉及到字节顺序问题</p><p>ex. Little endian: GIF, PC Paintbrush, Microsoft RTF,etc</p><p>Big endian: Adobe Photoshop, JPEG, MacPaint, etc</p><h1 id="运算电路基础"><a class="markdownIt-Anchor" href="#运算电路基础"></a> 运算电路基础</h1><h2 id="数字逻辑电路基础"><a class="markdownIt-Anchor" href="#数字逻辑电路基础"></a> 数字逻辑电路基础</h2></body></html>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -计算机体系架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于python实现CNN卷积层及卷积运算优化学习</title>
      <link href="/2020/03/04/%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0CNN%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%8A%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/03/04/%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0CNN%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%8F%8A%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E4%BC%98%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="推导过程"><a class="markdownIt-Anchor" href="#推导过程"></a> 推导过程：</h1><h2 id="符号说明"><a class="markdownIt-Anchor" href="#符号说明"></a> 符号说明：</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.5.png" data-fancybox="group" data-caption="7.5" class="fancybox"><img alt="7.5" title="7.5" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.5.png" class="lazyload"></a></p><h2 id="dnn反向传播原理"><a class="markdownIt-Anchor" href="#dnn反向传播原理"></a> DNN反向传播原理</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.1.jpg" data-fancybox="group" data-caption="7.1" class="fancybox"><img alt="7.1" title="7.1" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.1.jpg" class="lazyload"></a></p><h2 id="卷积层反向传播推导"><a class="markdownIt-Anchor" href="#卷积层反向传播推导"></a> 卷积层反向传播推导</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.2.jpg" data-fancybox="group" data-caption="7.2" class="fancybox"><img alt="7.2" title="7.2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.2.jpg" class="lazyload"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.3.jpg" data-fancybox="group" data-caption="7.3" class="fancybox"><img alt="7.3" title="7.3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.3.jpg" class="lazyload"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.4.jpg" data-fancybox="group" data-caption="7.4" class="fancybox"><img alt="7.4" title="7.4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7.4.jpg" class="lazyload"></a></p><h1 id="前向传播"><a class="markdownIt-Anchor" href="#前向传播"></a> 前向传播：</h1><h2 id="im2col的实现"><a class="markdownIt-Anchor" href="#im2col的实现"></a> im2col的实现</h2><p>im2col()：输入数据根据滤波器、步幅等展开的二维数组，每一行代表一条卷积输入数据</p><p>卷积就是卷积核跟图像矩阵的运算。卷积核是一个小窗口，记录的是权重。卷积核在输入图像上按步长滑动，每次操作卷积核对应区域的输入图像，将卷积核中的权值和对应的输入图像的值相乘再相加，赋给卷积核中心所对应的输出特征图的一个值。</p><p>im2col的作用就是优化卷积运算，如何优化呢，我们先学习一下这个函数的原理。<br>我们假设卷积核的尺寸为2×2，输入图像尺寸为3×3.im2col$做的事情就是对于卷积核每一次要处理的小窗，将其展开到新矩阵的一行（列），新矩阵的列（行）数，就是对于一副输入图像，卷积运算的次数（卷积核滑动的次数）</p><hr><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" title="4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/4.png" class="lazyload"></a></p><p>以最右侧一列为例，卷积核为2*2，所以新矩阵的列数就为4；步长为一，卷积核共滑动4次，行数就为4.</p><p>看到这里我就产生了一个疑问：我们把一个卷积核对应的值展开，到底应该展开为行还是列呢？卷积核的滑动先行后列还是相反？区别在哪？<br>这其实主要取决于我们使用的框架访存的方式。计算机一次性读取相近的内存是最快的，尤其是当需要把数据送到GPU去计算的时候，这样可以节省访存的时间，以达到加速的目的。不同框架的访存机制不一样，所以会有行列相反这样的区别。在caffe框架下，im2col是将一个小窗的值展开为一行，而在matlab中则展开为列。所以说，行列的问题没有本质区别，目的都是为了在计算时读取连续的内存。<br>这也解释了我们为什么要通过这个变化来优化卷积。如果按照数学上的步骤做卷积读取内存是不连续的，这样就会增加时间成本。同时我们注意到做卷积对应元素相乘再相加的做法跟向量内积很相似，所以通过im2col将矩阵卷积转化为矩阵乘法来实现。</p><h1 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h1><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im2col2</span><span class="params">(input_data, fh, fw, stride=<span class="number">1</span>, pad=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">     input_data--输入数据，shape为(batch_size,Channel,Height,Width)</span></span><br><span class="line"><span class="string">     fh -- 滤波器的height 3</span></span><br><span class="line"><span class="string">     fw --滤波器的width 3</span></span><br><span class="line"><span class="string">     stride -- 步幅 1</span></span><br><span class="line"><span class="string">     pad -- 填充 1</span></span><br><span class="line"><span class="string">     Returns :</span></span><br><span class="line"><span class="string">     col -- 输入数据根据滤波器、步幅等展开的二维数组，每一行代表一条卷积数据</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    N, C, H, W = input_data.shape   <span class="string">"[20,1,28,28]"</span></span><br><span class="line"></span><br><span class="line">    out_h = (H + <span class="number">2</span> * pad - fh) // stride + <span class="number">1</span>    <span class="string">"[28]"</span></span><br><span class="line">    out_w = (W + <span class="number">2</span> * pad - fw) // stride + <span class="number">1</span>     <span class="string">"[28]"</span></span><br><span class="line"></span><br><span class="line">    img = np.pad(input_data, [(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">0</span>), (pad, pad), (pad, pad)], <span class="string">"constant"</span>) </span><br><span class="line">     </span><br><span class="line">    <span class="string">"[30*30*1]"</span></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    col = np.zeros((N, out_h, out_w, fh * fw * C))  <span class="string">"fh * fw * C 负责存储每次参与卷积的参数"</span></span><br><span class="line">    print(col.shape)</span><br><span class="line">    <span class="comment"># 将所有维度上需要卷积的值展开成一行（列）,卷积次数为out_h*out_w*c,每次卷积内含参数量为（fh*fw*c）</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(out_h):</span><br><span class="line">        y_start = y * stride</span><br><span class="line">        y_end = y_start + fh</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(out_w):</span><br><span class="line">            x_start = x * stride</span><br><span class="line">            x_end = x_start + fw</span><br><span class="line">            col[:, y, x] = img[:, :, y_start:y_end, x_start:x_end].reshape(N, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    col = col.reshape(N * out_h * out_w, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> col</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">col2im2</span><span class="params">(col, out_shape, fh, fw, stride=<span class="number">1</span>, pad=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     col: 二维数组</span></span><br><span class="line"><span class="string">     out_shape-- 输出的shape，shape为(Number of example,Channel,Height,Width)</span></span><br><span class="line"><span class="string">     fh -- 滤波器的height</span></span><br><span class="line"><span class="string">     fw --滤波器的width</span></span><br><span class="line"><span class="string">     stride -- 步幅</span></span><br><span class="line"><span class="string">     pad -- 填充</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     Returns :</span></span><br><span class="line"><span class="string">     img -- 将col转换成的img ，shape为out_shape</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    N, C, H, W = out_shape</span><br><span class="line"></span><br><span class="line">    col_m, col_n = col.shape</span><br><span class="line"></span><br><span class="line">    out_h = (H + <span class="number">2</span> * pad - fh) // stride + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    out_w = (W + <span class="number">2</span> * pad - fw) // stride + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"out_h,out_w"</span>,out_h,out_w)</span><br><span class="line">    img = np.zeros((N, C, H, W))</span><br><span class="line">    <span class="comment">#img = np.pad(img,[(0,0),(0,0),(pad,pad),(pad,pad)],"constant")</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将col转换成一个filter</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(C):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> range(out_h):</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(out_w):</span><br><span class="line">                col_index = (c * out_h * out_w) + y * out_w + x</span><br><span class="line">                ih = y * stride</span><br><span class="line">                iw = x * stride</span><br><span class="line">                img[:, c, ih:ih + fh, iw:iw + fw] = col[col_index].reshape((fh, fw))</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></tbody></table></figure></div><p>测试：</p><p>输入input_data=[20,1,28,28];  fh=fw=3;采用SAME方式填充，则卷积的shape与input_data相同；</p><p>共卷积次数为15680次，每次卷积时input_data参与卷积的像素点数为9（卷积核为3*3）；所以col大小应为（15680，9）</p><p>程序输出结果：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">"测试"</span></span><br><span class="line">x=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">out = im2col2(x,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">print(out.shape)  “(<span class="number">15680</span>, <span class="number">9</span>)”</span><br></pre></td></tr></tbody></table></figure></div><h2 id="卷积层实现"><a class="markdownIt-Anchor" href="#卷积层实现"></a> 卷积层实现;</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Convolution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, W, fb, stride=<span class="number">1</span>, pad=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        W-- 滤波器权重，shape为(FN,NC,FH,FW),FN 为滤波器的个数</span></span><br><span class="line"><span class="string">        fb -- 滤波器的偏置，shape 为(1,FN)</span></span><br><span class="line"><span class="string">        stride -- 步长</span></span><br><span class="line"><span class="string">        pad -- 填充个数</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.W = W</span><br><span class="line">        self.fb = fb</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.pad = pad</span><br><span class="line"></span><br><span class="line">        self.col_X = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.col_W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.dW = <span class="literal">None</span></span><br><span class="line">        self.db = <span class="literal">None</span></span><br><span class="line">        self.out_shape = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#    self.out = None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input_X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        input_X-- shape为(m,nc,height,width)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.X = input_X</span><br><span class="line">        FN, NC, FH, FW = self.W.shape</span><br><span class="line"></span><br><span class="line">        m, input_nc, input_h, input_w = self.X.shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment"># 将输入数据展开成二维数组，shape为（m*out_h*out_w,FH*FW*C)</span></span><br><span class="line">        self.col_X = col_X = im2col2(self.X, FH, FW, self.stride, self.pad)</span><br><span class="line">        print(<span class="string">"self.col_X.shape"</span>,self.col_X .shape)</span><br><span class="line">        <span class="comment"># 将滤波器一个个按列展开(FH*FW*C,FN)       col_W.shape 15680,9 col_w 9,20  输出 15680，20</span></span><br><span class="line">        self.col_W = col_W = self.W.reshape(FN, <span class="number">-1</span>).T</span><br><span class="line">        out = np.dot(col_X, col_W) + self.fb</span><br><span class="line"></span><br><span class="line">        out = out.T <span class="comment">#     20，15680</span></span><br><span class="line"></span><br><span class="line">        out = out.reshape(m, FN, input_h, input_w)</span><br><span class="line">        self.out_shape = out.shape</span><br><span class="line">        print(<span class="string">"out.shape"</span>, out.shape)</span><br><span class="line">        <span class="keyword">return</span> out <span class="comment">#(20, 20, 28, 28)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, dz, learning_rate)</span>:</span></span><br><span class="line">        print(<span class="string">"==== Conv backbward ==== "</span>)</span><br><span class="line">        <span class="keyword">assert</span> (dz.shape == self.out_shape)</span><br><span class="line"></span><br><span class="line">        FN, NC, FH, FW = self.W.shape <span class="comment">#[20,1,28,28]</span></span><br><span class="line">        o_FN, o_NC, o_FH, o_FW = self.out_shape <span class="comment">#[20,20,28,28]</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"o_FN = {0}, o_NC = {1}, o_FH = {2}, o_FW = {3} "</span>.format(o_FN,o_NC,o_FH,o_FW))</span><br><span class="line"></span><br><span class="line">        col_dz = dz.reshape(o_NC, <span class="number">-1</span>)  <span class="comment">#col_dz  [20,15680]   dz[20, 20, 28, 28]</span></span><br><span class="line"></span><br><span class="line">        col_dz = col_dz.T</span><br><span class="line"></span><br><span class="line">        print(<span class="string">"self.col_X.T,col_dz"</span>,self.col_X.shape,col_dz.shape)</span><br><span class="line">        self.dW = np.dot(self.col_X.T, col_dz)  <span class="comment"># [15680,9]  [15680,20]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.db = np.sum(col_dz, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.dW = self.dW.T.reshape(self.W.shape)</span><br><span class="line">        self.db = self.db.reshape(self.fb.shape)</span><br><span class="line">        print(<span class="string">"dw.shape = {0},db.shape = {1} ,self.col_W={2}"</span>.format(self.dW.shape, self.db.shape,self.col_W.shape))</span><br><span class="line">        d_col_x = np.dot(col_dz, self.col_W.T)  <span class="comment"># shape is (m*out_h*out_w,FH,FW*C)</span></span><br><span class="line">        print(<span class="string">"d_col_x.shape= "</span>, d_col_x.shape)</span><br><span class="line">        dx = col2im2(d_col_x, self.X.shape, FH, FW, stride=<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">"dx.shape= "</span>,dx.shape)</span><br><span class="line">        <span class="keyword">assert</span> (dx.shape == self.X.shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新W和b</span></span><br><span class="line">        self.W = self.W - learning_rate * self.dW</span><br><span class="line">        self.fb = self.fb - learning_rate * self.db</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dx</span><br></pre></td></tr></tbody></table></figure></div><p>测试：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">数据载入</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">x=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)) <span class="comment">#测试集采用[20,1,28,28]</span></span><br><span class="line">w=np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">20</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))   <span class="comment">#卷积核采用通道数为1的3*3的卷积核，卷积次数为20</span></span><br><span class="line">b=x=np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">20</span>)) </span><br><span class="line">dz=np.random.uniform(<span class="number">0</span>,<span class="number">255</span>,(<span class="number">20</span>,<span class="number">20</span>,<span class="number">28</span>,<span class="number">28</span>))<span class="comment">#dz.shape与前向传播大小相同</span></span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">正向与反向传播测试</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = Convolution(w,b)</span><br><span class="line">test.forward(x)</span><br><span class="line">test.backward(dz,<span class="number">0.01</span>)</span><br></pre></td></tr></tbody></table></figure></div><p>forward()内部变量输出：</p><p>self.col_X.shape (15680, 9)</p><p>out.shape (20, 20, 28, 28)</p><p>与设计思想相符合</p><p>backward()内部变量输出输出值</p><p>dz.shape = (20, 20, 28, 28),col_dz.shape = (20, 15680)<br>dw.shape = (20, 1, 3, 3),db.shape = (1, 20)<br>d_col_x.shape=  (15680, 9)<br>dx.shape=  (20, 1, 28, 28)</p><h2 id="代码源文件"><a class="markdownIt-Anchor" href="#代码源文件"></a> 代码源文件</h2><p><a href="/code/%E5%9F%BA%E4%BA%8Epython%E5%AE%9E%E7%8E%B0%E5%8D%B7%E7%A7%AF%E5%B1%82.py">基于python实现卷积层.py</a></p><h2 id="tensflow实现卷积层"><a class="markdownIt-Anchor" href="#tensflow实现卷积层"></a> tensflow实现卷积层</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">def conv2d_answer():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        </span><br><span class="line">        # [N, height, width, channels] 4-D的tensors</span><br><span class="line">        #占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [30, 28, 28, 1], name='input_x') </span><br><span class="line">        </span><br><span class="line">        x = np.ones(shape=[30, 28, 28, 1])</span><br><span class="line"></span><br><span class="line">        #卷积核变量</span><br><span class="line">        filter_w = tf.get_variable(</span><br><span class="line">            'w', initializer=tf.truncated_normal(shape=[3, 3, 1, 20])</span><br><span class="line">        )</span><br><span class="line">        filter_b = tf.get_variable(</span><br><span class="line">            'b', initializer=tf.zeros(20)</span><br><span class="line">        )</span><br><span class="line">        strides = [1, 2, 2, 1]  # 标准的写法。</span><br><span class="line">        pad = 'VALID'</span><br><span class="line">    </span><br><span class="line">        conv_output = tf.nn.conv2d(</span><br><span class="line">            input=input_x, filter=filter_w, strides=strides, padding=pad</span><br><span class="line">        )</span><br><span class="line">        print(conv_output.get_shape())</span><br><span class="line">        conv_output = conv_output + filter_b</span><br><span class="line">        # print(conv_output)</span><br><span class="line">        # fixme 高级api</span><br><span class="line">        conv_output1 = tf.layers.conv2d(</span><br><span class="line">            inputs=input_x, kernel_size=7, filters=20, strides=2, padding='valid',</span><br><span class="line">            use_bias=True</span><br><span class="line">        )</span><br><span class="line">        print(conv_output1.get_shape())</span><br><span class="line">        # with tf.Session() as sess:</span><br><span class="line">        #     sess.run(tf.global_variables_initializer())</span><br><span class="line">        #     print(sess.run(conv_output, feed_dict={input_x: x}))</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    conv2d_answer()</span><br></pre></td></tr></tbody></table></figure></div><p>tensflow卷积层通过函数 tf.nn.conv2d 或者tf.layers.conv2d实现，</p><pre><code>"""    tf.nn.conv2d(input,    # 卷积的输入，必须是一个4-D tensor对象        filter,            # 滤波器        strides,           # 步幅        padding,           # 填充方式  string:  'SAME'   or  'VALID'        data_format="NHWC",   # 对输入数据格式的要求，[N, height, width, channels]； 也可以是另一种格式："NCHW"        dilations=[1, 1, 1, 1],         name=None)    """</code></pre><h2 id="caffe"><a class="markdownIt-Anchor" href="#caffe"></a> caffe</h2><p>在Caffe中是使用src/caffe/util/im2col.cu中的im2col和col2im来完成矩阵的变形和还原操作，即为上方python实现的代码，将卷积运算转化为矩阵相乘，提升了运算速度。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结：</h1><p>相比于现有框架，我的卷积运算部分还有待优化。实现了以矩阵相乘实现卷积运算，但是内存利用率低，可以用加速GEMM进行提高。</p><h1 id="探究如何优化卷积运算速度"><a class="markdownIt-Anchor" href="#探究如何优化卷积运算速度"></a> 探究：如何优化卷积运算速度</h1><p>提升卷积层运算速度，主要在于提高卷积的计算速度。</p><h2 id="朴素卷积naive-convolution"><a class="markdownIt-Anchor" href="#朴素卷积naive-convolution"></a> <strong>朴素卷积（Naive Convolution）</strong></h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line">'''Convolve `input` with `kernel` to generate `output`    </span><br><span class="line">input.shape = [input_channels, input_height, input_width]    </span><br><span class="line">kernel.shape = [num_filters, input_channels, kernel_height, kernel_width]    </span><br><span class="line">output.shape = [num_filters, output_height, output_width]</span><br><span class="line">'''</span><br><span class="line">for filter in 0..num_filters    </span><br><span class="line">    for channel in 0..input_channels        </span><br><span class="line">        for out_h in 0..output_height            </span><br><span class="line">            for out_w in 0..output_width                </span><br><span class="line">                for k_h in 0..kernel_height    </span><br><span class="line">                   for k_w in 0..kernel_width   </span><br><span class="line">                    output[filter, channel, out_h, out_h] +=   </span><br><span class="line">                    kernel[filter, channel, k_h, k_w] *    </span><br><span class="line">                    input[channel, out_h + k_h, out_w + k_w]</span><br></pre></td></tr></tbody></table></figure></div><p>涉及到了6个for嵌套循环，最内的循环进行了两次浮点运算（乘和加）。对于实验所使用的卷积层规模，它执行了8516万次，即该卷积需要1.7亿次浮点运算（170MFLOPs）。</p><p>内存访问同样需要时间：无法快速获取数据则无法快速处理数据。上述高度嵌套的for-loop使得数据访问非常艰难，从而无法充分利用缓存。</p><p>探究问题：如何访问正在处理的数据，以及这与数据存储方式有何关联。</p><p>逻辑上我们将矩阵/图像/张量看作是多维度的，但实际上它们存储在线性、一维的计算机内存中。我们必须定义一个惯例，来规定如何将多个维度展开到线性一维存储空间中，反之亦然。</p><p>大部分现代深度学习库使用行主序作为存储顺序。这意味着同一行的连续元素被存储在相邻位置。对于多维度而言，行主序通常意味着：在线性扫描内存时第一个维度的变化速度最慢。</p><h2 id="从卷积到矩阵相乘"><a class="markdownIt-Anchor" href="#从卷积到矩阵相乘"></a> <strong>从卷积到矩阵相乘</strong></h2><h3 id="采用矩阵相乘替换朴素卷积"><a class="markdownIt-Anchor" href="#采用矩阵相乘替换朴素卷积"></a> 采用矩阵相乘替换朴素卷积</h3><p>卷积是滤波器和输入图像块（patch）的点乘。如果我们将滤波器展开为2-D矩阵，将输入块展开为另一个2-D矩阵，则将两个矩阵相乘可以得到同样的数字。将图像块展开为矩阵的过程叫做im2col（image to column）。我们将图像重新排列为矩阵的列，每个列对应一个输入块，卷积滤波器就应用于这些输入块上。</p><p>在现实中，不同图像块之间通常会有重叠，因而im2col可能导致内存重叠。生成im2col 缓冲（im2col buffer）和过多内存（inflated memory）所花费的时间必须通过GEMM(矩阵乘优化)实现的加速来抵消。</p><h2 id="加速gemm"><a class="markdownIt-Anchor" href="#加速gemm"></a> <strong>加速GEMM</strong></h2><h3 id="缓存"><a class="markdownIt-Anchor" href="#缓存"></a> <strong>缓存</strong></h3><p>RAM是大的存储空间，但速度较慢。CPU缓存的速度要快得多，但其规模较小，因此恰当地使用CPU缓存至关重要。但是并不存在明确的指令：「将该数据加载到缓存」。该过程是由CPU自动管理的。</p><p>每一次从主内存中获取数据时，CPU会将该数据及其邻近的数据加载到缓存中，以便利用访问局部性（locality of reference）。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.1.jpg" data-fancybox="group" data-caption="1.1" class="fancybox"><img alt="1.1" title="1.1" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.1.jpg" class="lazyload"></a></p><p>你应该首先注意到我们访问数据的模式。我们按照下图A的形式逐行遍历数据，按照下图B的形式逐列遍历数据。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.2.jpg" data-fancybox="group" data-caption="1.2" class="fancybox"><img alt="1.2" title="1.2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.2.jpg" class="lazyload"></a></p><p>它们的存储也是行优先的，因此一旦我们找到 A[i, k]，则它在该行中的下一个元素A[i, k+1]已经被缓存了。接下来我们来看B中发生了什么：</p><ul><li>列的下一个元素并未出现在缓存中，即出现了缓存缺失（cache miss）。这时尽管获取到了数据，CPU也出现了一次停顿。</li><li>获取数据后，缓存同时也被 B 中同一行的其他元素填满。我们实际上并不会使用到它们，因此它们很快就会被删除。多次迭代后，当我们需要那些元素时，我们将再次获取它们。我们在用实际上不需要的值污染缓存。</li></ul><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.3.jpg" data-fancybox="group" data-caption="1.3" class="fancybox"><img alt="1.3" title="1.3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.3.jpg" class="lazyload"></a></p><p>我们需要重新修改loop，以充分利用缓存能力。如果数据被读取，则我们要使用它。这就是我们所做的第一项改变：循环重排序（loop reordering）。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">for i in 0..M:    </span><br><span class="line">    for j in 0..N:        </span><br><span class="line">        for k in 0..K:            </span><br><span class="line">            C[i, j] += A[i, k] * B[k, j]</span><br></pre></td></tr></tbody></table></figure></div><p>将i,j,k 循环重新排序为 i,k,j：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">for i in 0..M:    </span><br><span class="line">    for k in 0..K:        </span><br><span class="line">        for j in 0..N:</span><br></pre></td></tr></tbody></table></figure></div><p>乘/加的顺序对结果没有影响。而遍历顺序则变成了如下状态：</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.4.jpg" data-fancybox="group" data-caption="1.4" class="fancybox"><img alt="1.4" title="1.4" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.4.jpg" class="lazyload"></a></p><p>速度大大提升。</p><h3 id="平铺tiling"><a class="markdownIt-Anchor" href="#平铺tiling"></a> <strong>平铺（Tiling）</strong></h3><p>要想进一步改进重排序，我们需要考虑另一个缓存问题。</p><p>对于A中的每一行，我们针对B中所有列进行循环。而对于 B 中的每一步，我们会在缓存中加载一些新的列，去除一些旧的列。当到达A的下一行时，我们仍旧重新从第一列开始循环。我们不断在缓存中添加和删除同样的数据，即缓存颠簸（cache thrashing）。</p><p>如果所有数据均适应缓存，则颠簸不会出现。如果我们处理的是小型矩阵，则它们会舒适地待在缓存里，不用经历重复的驱逐。庆幸的是，我们可以将矩阵相乘分解为子矩阵。要想计算 C 的r×c平铺，我们仅需要A的r行和B的c列。接下来，我们将 C 分解为6x16的平铺：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C(x, y) += A(k, y) * B(x, k);</span><br><span class="line"></span><br><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for yo in 0..M/6:        </span><br><span class="line">    for yi in 6:            </span><br><span class="line">        for xi in 0..16:                </span><br><span class="line">            for k in 0..K:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><p>我们将x,y 维度分解为外侧的xo,yo和内侧的xi,yi。我们将为该6x16 block优化micro-kernel（即xi,yi），然后在所有block上运行micro-kernel（通过xo,yo进行迭代）。</p><h3 id="向量化-fma"><a class="markdownIt-Anchor" href="#向量化-fma"></a> <strong>向量化 & FMA</strong></h3><p>大部分现代CPU支持SIMD（Single Instruction Multiple Data，单指令流多数据流）。在同一个CPU循环中，SIMD可在多个值上同时执行相同的运算/指令（如加、乘等）。如果我们在4个数据点上同时运行SIMD指令，就会直接实现4倍的加速。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.5.jpg" data-fancybox="group" data-caption="1.5" class="fancybox"><img alt="1.5" title="1.5" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.5.jpg" class="lazyload"></a></p><p>因此，当我们计算处理器的峰值速度时，我们其实有些作弊，把该向量化性能作为峰值性能。对于向量等数据而言，SIMD用处多多，在处理此类数据时，我们必须对每一个向量元素执行同样的指令。但是我们仍然需要设计计算核心，以充分利用它。<br>计算峰值FLOPs时，我们所使用的第二个技巧是FMA（Fused Multiply-Add）。尽管乘和加是两种独立的浮点运算，但它们非常常见，有些专用硬件单元可以将二者融合为一，作为单个指令来执行。编译器通常会管理FMA的使用。<br>在英特尔CPU上，我们可以使用SIMD（AVX & SSE）在单个指令中处理多达8个浮点数。编译器优化通常能够独自识别向量化的时机，但是我们需要掌控向量化以确保无误。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for yo in 0..M/6:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        for yi in 6:                </span><br><span class="line">            for vectorized xi in 0..16:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><h3 id="多线程处理threading"><a class="markdownIt-Anchor" href="#多线程处理threading"></a> <strong>多线程处理（Threading）</strong></h3><p>到现在为止，我们仅使用了一个CPU内核。我们拥有多个内核，每个内核可同时执行多个指令。一个程序可被分割为多个线程，每个线程在单独的内核上运行。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8).parallel(yo)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16 in steps of 16:    </span><br><span class="line">for parallel yo in steps of 6:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        for yi in 6:                </span><br><span class="line">            for vectorized xi in 0..16 in steps of 8:                    </span><br><span class="line">                C(...) = ...*/</span><br></pre></td></tr></tbody></table></figure></div><p>你可能注意到，对于非常小的规模而言，性能反而下降了。这是因为工作负载很小，线程花费较少的时间来处理工作负载，而花费较多的时间同步其他线程。多线程处理存在大量此类问题。</p><h3 id="展开unrolling"><a class="markdownIt-Anchor" href="#展开unrolling"></a> <strong>展开（Unrolling）</strong></h3><p>循环使我们避免重复写同样代码的痛苦，但同时它也引入了一些额外的工作，如检查循环终止、更新循环计数器、指针运算等。如果手动写出重复的循环语句并展开循环，我们就可以减少这一开销。例如，不对1个语句执行8次迭代，而是对4个语句执行2次迭代。</p><p>这种看似微不足道的开销实际上是很重要的，最初意识到这一点时我很惊讶。尽管这些循环操作可能「成本低廉」，但它们肯定不是免费的。每次迭代2-3个额外指令的成本会很快累积起来，因为此处的迭代次数是数百万。随着循环开销越来越小，这种优势也在不断减小。</p><p>展开是几乎完全被编译器负责的另一种优化方式，除了我们想要更多掌控的micro-kernel。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">C.update().tile(x, y, xo, yo, xi, yi, 6, 16).reorder(xi, yi, k, xo, yo).vectorize(xi, 8).unroll(xi).unroll(yi)</span><br><span class="line">/*in pseudocode:for xo in 0..N/16:    </span><br><span class="line">for parallel yo:        </span><br><span class="line">    for k in 0..K:            </span><br><span class="line">        C(xi:xi+8, yi+0)            </span><br><span class="line">        C(xi:xi+8, yi+1)            </span><br><span class="line">        ...            </span><br><span class="line">        C(xi:xi+8, yi+5)            </span><br><span class="line">        C(xi+8:xi+16, yi+0)            </span><br><span class="line">        C(xi+8:xi+16, yi+1)            </span><br><span class="line">        ...            </span><br><span class="line">        C(xi+8:xi+16, yi+5)*/</span><br></pre></td></tr></tbody></table></figure></div><p>现在我们可以将速度提升到接近60 GFLOP/s。</p><h2 id="总结-2"><a class="markdownIt-Anchor" href="#总结-2"></a> <strong>总结</strong></h2><p>上述步骤涵盖一些性能加速最常用的变换。它们通常以不同方式组合，从而得到更加复杂的调度策略来计算同样的任务。</p><p>下面就是用Halide语言写的一个调度策略：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">matrix_mul(x, y) += A(k, y) * B(x, k);    </span><br><span class="line">out(x, y) = matrix_mul(x, y);</span><br><span class="line"></span><br><span class="line">out.tile(x, y, xi, yi, 24, 32)        </span><br><span class="line">  .fuse(x, y, xy).parallel(xy)        </span><br><span class="line">  .split(yi, yi, yii, 4)        </span><br><span class="line">  .vectorize(xi, 8)        </span><br><span class="line">  .unroll(xi)        </span><br><span class="line">  .unroll(yii);</span><br><span class="line"></span><br><span class="line"> matrix_mul.compute_at(out, yi)        </span><br><span class="line">   .vectorize(x, 8).unroll(y);</span><br><span class="line"></span><br><span class="line"> matrix_mul.update(0)        </span><br><span class="line">   .reorder(x, y, k)        </span><br><span class="line">   .vectorize(x, 8)        </span><br><span class="line">   .unroll(x)        </span><br><span class="line">   .unroll(y)        </span><br><span class="line">   .unroll(k, 2);</span><br></pre></td></tr></tbody></table></figure></div><ol><li>将out分解为32x24的平铺，然后将每个平铺进一步分解为8x24的子平铺。</li><li>使用类似的重排序、向量化和展开，在临时缓冲区（matrix_mul）计算8x24 matmul。</li><li>使用向量化、展开等方法将临时缓冲区matrix_mul 复制回out。</li><li>在全部32x24平铺上并行化这一过程</li></ol><h1 id="参考文章"><a class="markdownIt-Anchor" href="#参考文章"></a> 参考文章：</h1><p><a href="tps://zhuanlan.zhihu.com/p/66958390">通用矩阵乘（GEMM）优化与卷积计算</a></p><p><a href="https://zhuanlan.zhihu.com/p/85344625" target="_blank" rel="noopener">如何实现高速卷积？深度学习库使用了这些「黑魔法</a></p><p><a href="https://zhuanlan.zhihu.com/p/79584889" target="_blank" rel="noopener">手推DNN，CNN池化层，卷积层反向传播</a></p><h1 id="额外笔记"><a class="markdownIt-Anchor" href="#额外笔记"></a> 额外笔记：</h1><h2 id="same和valid"><a class="markdownIt-Anchor" href="#same和valid"></a> ”SAME”和“VALID”</h2><p>卷积之后的尺寸大小计算公式为：</p><ul><li>input_x  (FN,FC,FH,FW)</li><li>滤波器  Filter大小  (FN,FC,FH,FW)</li><li>Height与width  步长strides   S</li><li>Padding size P</li><li>求输出的shape: (FN,FC,FH,FW)</li></ul><p>我们可以得出输出大小</p><p>new_height = (input_height - filter_height + 2 * P)/S + 1<br>new_width = (input_width - filter_width + 2 * P)/S + 1</p><p>在实际操作时，我们还会碰到 **padding的两种方式 “SAME” 和 “VALID”，padding = “SAME”时，会在图像的周围填 “0”，padding = “VALID”则不需要，即 P=0。**一般会选“SAME”，以来减缓图像变小的速度，二来防止边界信息丢失</p><ol><li>padding = “VALID”：  P=0</li><li>padding = “SAME”：  kernel_size=1时，P=0；kernel_size=3时，P=1；kernel_size=5时，P=3，以此类推。</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogleNet 和ResNet</title>
      <link href="/2020/03/01/GoogleNet%20%E5%92%8CResNet/"/>
      <url>/2020/03/01/GoogleNet%20%E5%92%8CResNet/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>GoogleNet 和ResNet</p><p>GoogleNet ：</p><p>在同一层级上运行具备多个尺寸的滤波器,通过1x1，3x3和5x5、和池化层，提取了多尺度的特征,另外，在pooling层添加一个额外的并行pooling路径用于提高效率。</p><p>GoogelNet V1-V4</p><p>V1:</p><p>ResNet：</p><p>ResNet-bottleneck优化</p><p>ResNet中提出了一种bottleneck的结构块来代替常规的残差块，它借鉴了Inception网络中1x1 conv来缩减或扩张feature map维度<br>目的：不降低模型精度的前提下，降低参数量和计算量。</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/1.png" class="lazyload" title="1"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/2.png" class="lazyload" title="2"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/3.png" class="lazyload" title="3"></a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>学习率(Learning rate)的理解以及如何调整学习率</title>
      <link href="/2020/02/17/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/"/>
      <url>/2020/02/17/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h2 id="1什么是学习率learning-rate"><a class="markdownIt-Anchor" href="#1什么是学习率learning-rate"></a> 1.什么是学习率(Learning rate)？</h2><p>**学习率(Learning rate)**作为监督学习以及深度学习中重要的超参，其决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。<br>  这里以梯度下降为例，来观察一下不同的学习率对代价函数的收敛过程的影响（这里以代价函数为凸函数为例）：<br>  回顾一下梯度下降的代码：<br>  repeat{</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>j</mi></msub><mo>=</mo><msub><mi>θ</mi><mi>j</mi></msub><mo>−</mo><mi>α</mi><mfrac><mrow><mi mathvariant="normal">Δ</mi><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">Δ</mi><msub><mi>θ</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\theta_j = \theta_j -\alpha\frac{\Delta J(\theta)}{\Delta\theta_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.55232em;vertical-align:-0.5423199999999999em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.02778em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathdefault mtight" style="margin-right:0.09618em;">J</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>​            ｝</p><p>当学习率设置的<strong>过小</strong>时，收敛过程如下：</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/5.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" title="5" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/5.jpg" class="lazyload"></a></p><p>​     当学习率设置的<strong>过大</strong>时，收敛过程如下：<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.jpg" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" title="6" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.jpg" class="lazyload"></a></p><p>由上图可以看出来，当学习率设置的<strong>过小</strong>时，<strong>收敛过程将变得十分缓慢</strong>。而当学习率设置的<strong>过大</strong>时，<strong>梯度可能会在最小值附近来回震荡，甚至可能无法收敛</strong>。<br>  我们再来看一下学习率对<strong>深度学习</strong>模型训练的影响：<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.1.jpg" data-fancybox="group" data-caption="6.1" class="fancybox"><img alt="6.1" title="6.1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.1.jpg" class="lazyload"></a></p><p>可以由上图看出，固定学习率时，当到达收敛状态时，会在最优值附近一个<strong>较大的区域内</strong>摆动；而当随着迭代轮次的增加而减小学习率，会使得在收敛时，在最优值附近一个<strong>更小的区域</strong>内摆动。（之所以曲线震荡朝向最优值收敛，是因为在每一个mini-batch中都存在噪音）。<br>  因此，选择一个合适的学习率，对于模型的训练将至关重要。下面来了解一些学习率调整的方法。</p><hr><h2 id="2-学习率的调整"><a class="markdownIt-Anchor" href="#2-学习率的调整"></a> 2. 学习率的调整</h2><h3 id="21-离散下降discrete-staircase"><a class="markdownIt-Anchor" href="#21-离散下降discrete-staircase"></a> 2.1 离散下降(discrete staircase)</h3><p>对于<strong>深度学习</strong>来说，每 tt 轮学习，学习率减半。对于<strong>监督学习</strong>来说，初始设置一个较大的学习率，然后随着迭代次数的增加，减小学习率。</p><h3 id="22-指数减缓exponential-decay"><a class="markdownIt-Anchor" href="#22-指数减缓exponential-decay"></a> 2.2 指数减缓(exponential decay)</h3><p>对于<strong>深度学习</strong>来说，学习率按训练轮数增长指数差值递减。例如：</p><p>​<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.9</mn><msup><mn>5</mn><mrow><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></msup><mo>⋅</mo><msub><mi>α</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\alpha = 0.95^{epoch\_num}\cdot\alpha_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord"><span class="mord">5</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>​        又或者公式为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mfrac><mi>k</mi><msqrt><mrow><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\alpha = \frac{k}{\sqrt{epoch\_num}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.709708em;vertical-align:-0.8296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.5046085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9791307142857142em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span><span style="top:-2.951130714285714em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width="400em" height="1.5428571428571431em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.47744071428571444em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8296em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p><p>​ 其中epoch_num为当前epoch的迭代轮数。不过第二种方法会引入另一个超参 kk 。</p><h3 id="23-分数减缓1t-decay"><a class="markdownIt-Anchor" href="#23-分数减缓1t-decay"></a> 2.3 分数减缓(1/t decay)</h3><p>​  对于<strong>深度学习</strong>来说，学习率按照公式 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mfrac><mi>α</mi><mrow><mn>1</mn><mo>+</mo><mi>d</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>y</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>∗</mo><mi>e</mi><mi>p</mi><mi>o</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha = \frac{\alpha}{1+decay\_rate*epoch\_num}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2573919999999998em;vertical-align:-0.5619999999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.695392em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">e</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">h</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5619999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>变化， decay_rate控制减缓幅度。</p><h1 id="软饱和与梯度消散"><a class="markdownIt-Anchor" href="#软饱和与梯度消散"></a> 软饱和与梯度消散</h1><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.3.png" data-fancybox="group" data-caption="6.3" class="fancybox"><img alt="6.3" title="6.3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.3.png" class="lazyload"></a></p><h1 id="交叉熵损失函数"><a class="markdownIt-Anchor" href="#交叉熵损失函数"></a> 交叉熵损失函数</h1><p>通过最大似然估计的原理，我们可以得到，当似然函数最大的时候，似然函数中对应的模型参数是我们求解的最优参数；而在损失函数中，我们认为当损失函数最小的时候，损失函数中对应模型参数是我们求解的最优参数；故我们可以使用负的似然函数作为损失函数，这样我们可以得到Logistic回归的损失函数（交叉熵损失函数）</p><p>详见知乎：</p><p><a href="https://www.zhihu.com/search?type=content&q=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">https://www.zhihu.com/search?type=content&q=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0</a></p><h1 id="sotfmax-bp-推导"><a class="markdownIt-Anchor" href="#sotfmax-bp-推导"></a> <strong>sotfmax BP 推导</strong></h1><p><a href="https://zhuanlan.zhihu.com/p/25723112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25723112</a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mi>δ</mi><mfrac><mi>A</mi><mi>B</mi></mfrac></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mfrac><mrow><mi>δ</mi><mi>A</mi></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac><mi>B</mi><mo>−</mo><mi>A</mi><mfrac><mrow><mi>δ</mi><mi>B</mi></mrow><mrow><mi>δ</mi><mi>a</mi></mrow></mfrac></mrow><msup><mi>B</mi><mn>2</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">\frac{\delta\frac{A}{B}}{\delta a} =\frac{ \frac{\delta A}{\delta a}B -A\frac{\delta B }{\delta a}     }{B^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.506265em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.161265em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5508em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8720928571428572em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.51182em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.16682em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5508em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8800285714285714em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">A</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8800285714285714em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.4.png" data-fancybox="group" data-caption="6.4" class="fancybox"><img alt="6.4" title="6.4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.4.png" class="lazyload"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.5.png" data-fancybox="group" data-caption="6.5" class="fancybox"><img alt="6.5" title="6.5" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.5.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Canny边缘检测</title>
      <link href="/2020/02/13/Canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/"/>
      <url>/2020/02/13/Canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">title: Canny边缘检测-论鸡尾酒疗法</span><br><span class="line">tags:</span><br><span class="line">-数字图像处理</span><br><span class="line">categories: cv</span><br><span class="line">cover: /img/ML.png</span><br><span class="line">katex: true</span><br></pre></td></tr></tbody></table></figure></div><p>Canny 边缘检测算法被很多人认为是边缘检测的最优算法，为什么说它是最优算法呢？我们参考一下业界的评判标准：</p><ul><li><strong>低错误率:</strong> 标识出尽可能多的实际边缘，同时尽可能的减少噪声产生的误报。</li><li><strong>高定位性:</strong> 标识出的边缘要与图像中的实际边缘尽可能接近。</li><li><strong>最小响应:</strong> 图像中的边缘只能标识一次。</li></ul><p>那么问题来了，我们都已经介绍过Sobel、Laplace这种一阶或二阶的算子了，Canny算子又是什么？它又是凭什么获得最优这个称号的？</p><blockquote><p>什么是Canny边缘检测？</p></blockquote><p>Canny 边缘检测算法其实就是 John F. Canny 于 1986年开发出来的一个多级边缘检测算法，用Canny的名字命名，用来检测图像边缘的一种算法。</p><blockquote><p>它为什么这么厉害？</p></blockquote><p>Canny一定是调酒大师，简单的素材在他手里组合一下就焕发了新的活力。简单的回答是，Canny合理的运用了滤波、一阶、二阶边缘检测、边缘细化以及关键的提出了“双阈值边缘连接处理”，把这些基础简单的算法组合一下，达到了最优的效果。可以参考下面的顺序：</p><ol><li><strong>彩色图像转换为灰度图像</strong></li><li><strong>对图像进行高斯模糊</strong></li><li><strong>计算图像梯度，根据梯度计算图像边缘幅值与角度</strong></li><li><strong>非最大信号压制处理（边缘细化）</strong></li><li><strong>双阈值边缘连接处理</strong></li><li><strong>二值化图像输出结果</strong></li></ol><blockquote><p><strong>彩色图像转换为灰度图像</strong></p></blockquote><p>这个不用过多解释了把，cvtColor。因为Canny只能处理灰度图像，而且转换的最终结果是二值图。所以如果是彩色图，转换后才能灰度图还是很有必要的</p><blockquote><p><strong>对图像进行高斯模糊</strong></p></blockquote><p>在Canny内部，已经做了一个size=5的高斯滤波，可以参考如下内核算子。但是需要注意的是，在做Canny之前是否要再做一次高斯滤波是非常值得考究的事情。</p><p><a href="../img/cv/6.png" data-fancybox="group" data-caption="6" class="fancybox"><img alt="6" data-src="../img/cv/6.png" class="lazyload" title="6"></a></p><blockquote><p><strong>计算图像梯度，根据梯度计算图像边缘幅值与角度</strong></p><p><strong>最大信号压制处理（边缘细化）</strong></p><p><strong>双阈值边缘连接处理</strong></p><p><strong>二值化图像输出结果</strong></p></blockquote><p>参考https://blog.csdn.net/weixin_40647819/article/details/91411424</p><p><a href="https://zhuanlan.zhihu.com/p/79896426" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79896426</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>图像金字塔</title>
      <link href="/2020/02/12/%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/"/>
      <url>/2020/02/12/%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">title:  图像金字塔</span><br><span class="line">tags:</span><br><span class="line">-数字图像处理</span><br><span class="line">categories: cv</span><br><span class="line">cover: /img/ML.png</span><br><span class="line">katex: true</span><br></pre></td></tr></tbody></table></figure></div><h1 id="图像金字塔"><a class="markdownIt-Anchor" href="#图像金字塔"></a> 图像金字塔：</h1><p>一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。我们将一层一层的图像比喻成金字塔，层级越高，则图像越小，分辨率越低。就像这样：</p><p><a href="../img/cv/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" data-src="../img/cv/1.jpg" class="lazyload" title="1"></a></p><p>作用：</p><p>图像金字塔是图像中多尺度表达的一种，最初用于机器视觉和图像压缩，最主要用于图像的分割、融合。</p><p>分类：</p><p>高斯金字塔（Gussianpyramid）：用来下采样，主要的图像金字塔。</p><p>拉普拉斯金字塔（Laplacianpyramid）：用来从金字塔底层图像搭建上层未采样图像，上采样重建一个图像。在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。</p><p>图像金字塔中的向上和向下采样分别通过OpenCv函数pyrUp和pyrDown实现。</p><p>这里的向下与向上采样，是对图像的尺寸而言的（和金字塔的方向相反），即向下就是图像尺寸缩小，向上是图像尺寸变大。</p><h2 id="11高斯金字塔缩小图像"><a class="markdownIt-Anchor" href="#11高斯金字塔缩小图像"></a> 1.1高斯金字塔（缩小图像）</h2><p>高斯金字塔是由底部的最大分辨率图像逐次向下采样得到的一系列图像。最下面的图像分辨率最高，越往上图像分辨率越低。</p><p><a href="../img/cv/3.jpg" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/cv/3.jpg" class="lazyload" title="3"></a></p><p>高斯金字塔的向下采样过程是：</p><ol><li><p>对于给定的图像先做一次高斯平滑处理，也就是使用一个大小为的卷积核对图像进行卷积操作.OpenCv 中使用的高斯核:<a href="../img/cv/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" data-src="../img/cv/4.png" class="lazyload" title="4"></a></p></li><li><p>然后再对图像采样，去除图像中的偶数行和偶数列，然后就得到一张图片</p></li><li><p>对这张图片循环1) 和 2)操作就可以得到高斯金字塔。</p></li></ol><p>如模型可以看出，一次循环得到的图像即为G_(i+1)的图像，显而易见，结果图像只有原图的四分之一。通过对输入图像G_i(原始图像)不停迭代以上步骤就会得到整个金字塔。同时我们也可以看到，向下取样会逐渐丢失图像的信息。以上就是对图像的向下取样操作，即缩小图像。</p><h3 id="高斯金字塔的向上采样过程是"><a class="markdownIt-Anchor" href="#高斯金字塔的向上采样过程是"></a> <strong>高斯金字塔的向上采样过程是：</strong></h3><ol><li><p>将图像在每个方向扩大为原来的两倍，新增的行和列以0填充</p></li><li><p>使用先前同样的内核(乘以4)与放大后的图像卷积，获得 “新增像素”的近似值</p></li></ol><p>得到的图像即为放大后的图像，但是与原来的图像相比会发觉比较模糊，因为在缩放的过程中已经丢失了一些信息，如果想在缩小和放大整个过程中减少信息的丢失，这些数据形成了<strong>拉普拉斯金字塔</strong>。</p><p>注意：上采样和下采样是非线性处理，不可逆，有损的处理！</p><h2 id="12拉普拉斯金字塔放大图像"><a class="markdownIt-Anchor" href="#12拉普拉斯金字塔放大图像"></a> <strong>1.2拉普拉斯金字塔（放大图像）</strong></h2><p>用来从金字塔低层图像重建上层未采样图像，在数字图像处理中也即是预测残差，可以对图像进行最大程度的还原，配合高斯金字塔一起使用。</p><p><a href="../img/cv/5.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" data-src="../img/cv/5.jpg" class="lazyload" title="5"></a></p><p>​                                                       拉普拉斯金字塔的生成和高斯金字塔的关系</p><p>好在拉普拉斯金字塔有现成的公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mi>G</mi><mi>i</mi></msub><mo>−</mo><msub><mi>U</mi><mi>p</mi></msub><mo stretchy="false">(</mo><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>⊗</mo><mo stretchy="false">)</mo><msub><mi>κ</mi><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow></msub></mrow><annotation encoding="application/x-tex">L_{i} = G_{i} -U_{p} (G_{i+1}\otimes )\kappa_{5\times5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mord">⊗</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span><span class="mbin mtight">×</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">G_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示第i层的高斯图像;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">G_{i+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>表示第i+1层的高斯图像;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>U</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">U_{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>表示向上采样，将源图像中位置为(x,y)的像素映射到目标图像的(2x+1,2y+1)位置;</p><p>$\otimes $ 用来表示卷积;</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>κ</mi><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\kappa_{5\times5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span><span class="mbin mtight">×</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>表示5*5的内核（参考上面的高斯内核）</p><p>因此在OpenCv中的拉普拉斯公式等价于   <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mi>G</mi><mi>i</mi></msub><mo>−</mo><mi>P</mi><mi>y</mi><mi>r</mi><mi>U</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>G</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{i} = G_{i} -PyrUp(G_{i+1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>也就是说，拉普拉斯金字塔是通过源图像减去先缩小后再放大的图像的一系列图像构成的。保留的是残差！为图像还原做准备！</p><p><a href="../img/cv/2.jpg" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/cv/2.jpg" class="lazyload" title="2"></a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SVM算法总结</title>
      <link href="/2020/02/12/%E5%88%9D%E5%A7%8B/"/>
      <url>/2020/02/12/%E5%88%9D%E5%A7%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cnn</title>
      <link href="/2020/02/03/cnn/"/>
      <url>/2020/02/03/cnn/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p><a href="https://www.cnblogs.com/pinard/p/6489633.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6489633.html</a></p><p><a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6494810.html</a></p><p>特征图</p><ol><li>数据输入层：Input Layer</li><li>卷积计算层：CONV Layer<br>ReLU激励层：ReLU Incentive  Layer<br>池化层：Pooling Layer  下采样</li><li>全连接层：FC Layer    -分类，回归<br>备注：Batch Normalization Layer（必备）<br>结构：输入层–{[卷积层+批归一化+激活函数+dropout(可选)]*N-池化层}*M–拉平层–[FC+批归一化+激活]*K–输出层–激活函数(分类用:softmax或sigmoid)</li></ol><p>卷积神经网络-Input Layer：</p><p>分类：one-hot 哑编码</p><p>回归：z-score</p><p>和神经网络/机器学习一样，需要对输入的数据需要进行预处理操作，需要进行预处理的主要原因是：<br>输入数据单位不一样，可能会导致神经网络收敛速度慢，训练时间长<br>数据范围大（方差大）的输入在模式分类中的作用可能偏大，而数据范围小的作用就有可能偏小<br>由于神经网络中存在的激活函数是有值域限制的，因此需要将网络训练的目标数据映射到激活函数的值域<br>S形激活函数在(-4, 4)区间以外区域很平缓，区分度太小。例如S形函数f(X)，f(100)与f(5)只相差0.0067</p><p>常见3种数据预处理方式<br>去均值<br>将输入数据的各个维度中心化到0<br>归一化   (0,255) (0,1)<br>将输入数据的各个维度的幅度归一化到同样的范围<br>PCA/白化<br>用PCA降维（去掉特征与特征之间的相关性）<br>白化是在PCA的基础上，对转换后的数据每个特征轴上的幅度进行归一化<br><a href="http://ufldl.stanford.edu/wiki/index.php/%E7%99%BD%E5%8C%96" target="_blank" rel="noopener">http://ufldl.stanford.edu/wiki/index.php/白化</a></p><p>卷积计算层：CONV Layer<br>局部关联：每个神经元看做一个filter/kernel<br>窗口(receptive field–感受野)滑动，filter对局部数据进行计算<br>相关概念<br>输入特征图的深度：  depth == channel<br>卷积核大小(滤波器):   kernel  size  11 3/3<br>输出深度==卷积核个数<br>步幅：stride（取值：1   2   4 ） 影响输出图片的高和宽<br>填充值：zero-padding<br>填充方式：same  或者  valid<br>CONV过程参考：<a href="http://cs231n.github.io/assets/conv-demo/index.html" target="_blank" rel="noopener">http://cs231n.github.io/assets/conv-demo/index.html</a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">tf.nn.conv2d(input,    # 卷积的输入，必须是一个4-D tensor对象</span><br><span class="line">    filter,            # 滤波器</span><br><span class="line">    strides,           # 步幅</span><br><span class="line">    padding,           # 填充方式  string:  'SAME'   or  'VALID'</span><br><span class="line">    data_format="NHWC",   # 对输入数据格式的要求，[N, height, width, channels]； 也可以是另一种格式："NCHW"</span><br><span class="line">    dilations=[1, 1, 1, 1],   #扩大感受野</span><br><span class="line">    name=None)</span><br><span class="line">"""</span><br><span class="line">或者</span><br><span class="line">  conv_output1 = tf.layers.conv2d(</span><br><span class="line">            inputs=input_x, kernel_size=7, filters=20, strides=2, padding='valid',</span><br><span class="line">            use_bias=True</span><br><span class="line">        )</span><br></pre></td></tr></tbody></table></figure></div><p>池化层：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">max_pool(value,   # 也是4-D tensors [N, height, width, channels] </span><br><span class="line">    ksize,     # 池化核大小</span><br><span class="line">    strides,   # 池化步幅大小</span><br><span class="line">    padding,   # 填充方式</span><br><span class="line">    data_format="NHWC",   # 对输入数据格式的约定，也可以是另一种格式："NCHW"</span><br><span class="line">    name=None)</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>卷积神经网络-参数初始化:</p><p>在卷积神经网络中，可以看到神经元之间的连接是通过权重w以及偏置b实现的。在具体的神经网络之前，我们还有一个任务需要做，那就是初始化参数<br>权重的初始化（截尾正态分布 标准差为(经验分布)<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><msqrt><mi>n</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.383108em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6258665em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8059050000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-2.765905em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.234095em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>或者0.1）<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/2.png" class="lazyload" title="2"></a></p><p>​            一般方式：很小的随机数(对于多层深度神经网络，太小的值会导致回传的梯度非常小)，一般随机数是服从均值为0，方差未知(建议：2/n, n为权重数量，<a href="https://arxiv.org/pdf/1502.01852.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1502.01852.pdf</a>)的高斯分布随机数列。<br>错误方式：全部初始化为0，全部设置为0，在反向传播的时候是一样的梯度值，那么这个网络的权重是没有办法差异化的，也就没有办法学习到东西。<br>偏置项的初始化<br>​                  一 般直接设置为0，在存在ReLU激活函数的网络中，也可以考虑设置为一个很小的数字</p><p>卷积神经网络正则化和Dropout</p><p>神经网络的学习能力受神经元数目以及神经网络层次的影响，神经元数目越大，神经网络层次越高，那么神经网络的学习能力越强，那么就有可能出现过拟合的问题；(通俗来讲：神经网络的空间表达能力变得更紧丰富了)<br>Regularization：正则化，通过降低模型的复杂度，通过在cost函数上添加一个正则项的方式来降低overfitting，主要有L1和L2两种方式</p><p>或</p><p>Dropout：通过随机删除神经网络中的神经元来解决overfitting问题，在每次迭代的时候，只使用部分神经元训练模型获取W和d的值，参考：《Dropout: A Simple Way to Prevent Neural Networks from Overfitting》</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/4.png" data-fancybox="group" data-caption="4" class="fancybox"><img alt="4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/4.png" class="lazyload" title="4"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/3.png" class="lazyload" title="3"></a></p><p>模型保存与恢复持久化训练</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_file_path</span><span class="params">(dir_path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    创建文件夹函数</span></span><br><span class="line"><span class="string">    :param dir_path:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir_path):</span><br><span class="line">        os.makedirs(dir_path)</span><br><span class="line">        print(<span class="string">'创建文件夹:{}'</span>.format(dir_path))</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 6、构建持久化对象</span><br><span class="line">CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">create_file_path(CKECKPOINT_DIR)</span><br><span class="line">saver = tf.train.Saver(max_to_keep=1)</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#持久化模型</span><br><span class="line">checkpoints_file = 'model_{}'</span><br></pre></td></tr></tbody></table></figure></div><p>全部代码：Mnist数据集cnn分类</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(</span><br><span class="line">    '../datas/mnist', one_hot=True, reshape=False)</span><br><span class="line">print(mnist.train.num_examples)</span><br><span class="line"></span><br><span class="line"># 超参数设置</span><br><span class="line">lr = 1e-2</span><br><span class="line">epochs = 10</span><br><span class="line">batch_size = 256</span><br><span class="line">test_valid_size = 512  # 验证或者测试样本的数量</span><br><span class="line">num_classes = 10  # 类别数量</span><br><span class="line">keep_prob = 0.7   # dropout保留概率， 丢弃概率=1-0.7 = 0.3</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">网络结构图</span><br><span class="line">input [N, 28, 28, 1]</span><br><span class="line">Conv1 weights=[5, 5, 1, 32] S=1    ---> [N, 28, 28, 32]</span><br><span class="line">MaxPool1  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/2, 28/2, 32]</span><br><span class="line">Conv2 weights=[5, 5, 32, 64] S=1    ---> [N, 28/2, 28/2, 64]</span><br><span class="line">MaxPool2  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/4, 28/4, 64]</span><br><span class="line"></span><br><span class="line">Flatten [N, 28/4, 28/4, 64] 4-D  ---> [N, 7*7*64]  2-D</span><br><span class="line">FC1 Weights=[7*7*64, 1024] ---> [N, 1024]</span><br><span class="line">FC2 Weights=[1024, 10] ---> [N, 10]</span><br><span class="line">"""</span><br><span class="line"># 构建模型图 1、创建变量</span><br><span class="line">graph = tf.Graph()</span><br><span class="line">with graph.as_default():</span><br><span class="line">    weights = {</span><br><span class="line">        'conv1': tf.get_variable('w1', shape=[5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'conv2': tf.get_variable('w2', shape=[5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'fc1': tf.get_variable('w3', shape=[7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.1)),</span><br><span class="line">        'fc2': tf.get_variable('w4', shape=[1024, num_classes], initializer=tf.truncated_normal_initializer(stddev=0.1))</span><br><span class="line">    }</span><br><span class="line">    biases = {</span><br><span class="line">        'conv1': tf.get_variable('b1', shape=[32], initializer=tf.zeros_initializer()),</span><br><span class="line">        'conv2': tf.get_variable('b2', shape=[64], initializer=tf.zeros_initializer()),</span><br><span class="line">        'fc1': tf.get_variable('b3', shape=[1024], initializer=tf.zeros_initializer()),</span><br><span class="line">        'fc2': tf.get_variable('b4', shape=[num_classes], initializer=tf.zeros_initializer())</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def conv2d(input_tensor, filter_w, filter_b, strides=[1, 1, 1, 1]):</span><br><span class="line">    """</span><br><span class="line">    实现 卷积 + 偏置项相加 + 激活函数</span><br><span class="line">    :param input_tensor: 输入</span><br><span class="line">    :param filter_w:   卷积核变量</span><br><span class="line">    :param filter_b:    偏置项</span><br><span class="line">    :param strides:     步幅</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、卷积</span><br><span class="line">    conv = tf.nn.conv2d(</span><br><span class="line">        input=input_tensor, filter=filter_w, strides=strides, padding='SAME'</span><br><span class="line">    )</span><br><span class="line">    # 2、偏置项相加</span><br><span class="line">    conv = tf.nn.bias_add(conv, filter_b)</span><br><span class="line">    # 3、激活</span><br><span class="line">    conv = tf.nn.relu(conv)</span><br><span class="line">    return conv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def maxpool2d(input_tensor, k=2):</span><br><span class="line">    kernel_size = [1, k, k, 1]</span><br><span class="line">    strides = [1, k, k, 1]</span><br><span class="line">    maxpool_out = tf.nn.max_pool(</span><br><span class="line">        value=input_tensor, ksize=kernel_size, strides=strides, padding='SAME'</span><br><span class="line">    )</span><br><span class="line">    return maxpool_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def fully_connect(input_tensor, weights, biases, activation=tf.nn.relu):</span><br><span class="line">    """</span><br><span class="line">    实现全连接 + 偏置项相加 + 激活</span><br><span class="line">    :param input_tensor:</span><br><span class="line">    :param weights:</span><br><span class="line">    :param biases:</span><br><span class="line">    :param activation:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    fc = tf.matmul(input_tensor, weights) + biases</span><br><span class="line">    if activation:</span><br><span class="line">        fc = activation(fc)</span><br><span class="line">        return fc</span><br><span class="line">    else:</span><br><span class="line">        # 这里是为了返回最终输出的logits。</span><br><span class="line">        return fc</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">网络结构图</span><br><span class="line">input [N, 28, 28, 1]</span><br><span class="line">Conv1 weights=[5, 5, 1, 32] S=1    ---> [N, 28, 28, 32]</span><br><span class="line">MaxPool1  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/2, 28/2, 32]</span><br><span class="line">Conv2 weights=[5, 5, 32, 64] S=1    ---> [N, 28/2, 28/2, 64]</span><br><span class="line">MaxPool2  kernel_size=[1, 2, 2, 1] S=2    ---> [N, 28/4, 28/4, 64]</span><br><span class="line">Flatten [N, 28/4, 28/4, 64] 4-D  ---> [N, 7*7*64]  2-D</span><br><span class="line">FC1 Weights=[7*7*64, 1024] ---> [N, 1024]</span><br><span class="line">FC2 Weights=[1024, 10] ---> [N, 10]</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def model(input_x, weights, biases, keep_prob):</span><br><span class="line">    """</span><br><span class="line">    搭建CNN网络，返回logits</span><br><span class="line">    :param input_x:   模型输入，是占位符</span><br><span class="line">    :param weights:</span><br><span class="line">    :param biases:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.variable_scope('Network'):</span><br><span class="line">        # 卷积1  [N, 28, 28, 1]  --> [N, 28, 28, 32]</span><br><span class="line">        conv1 = conv2d(</span><br><span class="line">            input_tensor=input_x, filter_w=weights['conv1'], filter_b=biases['conv1'])</span><br><span class="line">        # 池化1 [N, 28, 28, 32]  -->[N, 28/2, 28/2, 32]</span><br><span class="line">        pool1 = maxpool2d(conv1)</span><br><span class="line">        # 卷积2  [N, 28/2, 28/2, 32]  --> [N, 28/2, 28/2, 64]</span><br><span class="line">        conv2 = conv2d(</span><br><span class="line">            input_tensor=pool1, filter_w=weights['conv2'], filter_b=biases['conv2'])</span><br><span class="line">        # 池化2 [N, 28/2, 28/2, 64]  -->[N, 28/4, 28/4, 64]</span><br><span class="line">        pool2 = maxpool2d(conv2)</span><br><span class="line"></span><br><span class="line">        # 拉平层 [N, 28/4, 28/4, 64] ---> [N, 7*7*64]</span><br><span class="line">        shape = pool2.get_shape()  # [N, 7, 7, 64]</span><br><span class="line">        flatten_shape = shape[1] * shape[2] * shape[3]</span><br><span class="line">        flatted = tf.reshape(pool2, shape=[-1, flatten_shape])</span><br><span class="line"></span><br><span class="line">        # 全连接层1  [N, 7*7*64] ---> [N, 1024]</span><br><span class="line">        fc1 = fully_connect(</span><br><span class="line">            input_tensor=flatted, weights=weights['fc1'], biases=biases['fc1'])</span><br><span class="line">        fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line">        # 全连接层2（输出层）   [N, 1024] --->  [N, 10]</span><br><span class="line">        logits = fully_connect(</span><br><span class="line">            input_tensor=fc1, weights=weights['fc2'], biases=biases['fc2'], activation=None</span><br><span class="line">        )</span><br><span class="line">        return logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_file_path(dir_path):</span><br><span class="line">    """</span><br><span class="line">    创建文件夹函数</span><br><span class="line">    :param dir_path:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    if not os.path.exists(dir_path):</span><br><span class="line">        os.makedirs(dir_path)</span><br><span class="line">        print('创建文件夹:{}'.format(dir_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train():</span><br><span class="line">    """</span><br><span class="line">    构建模型</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with graph.as_default():</span><br><span class="line">        # 1、创建占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='input_x')</span><br><span class="line">        input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')</span><br><span class="line">        learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')</span><br><span class="line">        keep_probab = tf.placeholder(tf.float32, shape=None, name='keep_probab')</span><br><span class="line"></span><br><span class="line">        # 2、构建模型</span><br><span class="line">        logits = model(input_x, weights, biases, keep_prob=keep_probab)</span><br><span class="line"></span><br><span class="line">        # 3、构建模型损失</span><br><span class="line">        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">            logits=logits, labels=input_y</span><br><span class="line">        ))</span><br><span class="line">        # 可视化代码</span><br><span class="line">        tf.summary.scalar('train_loss', loss, collections=['train'])</span><br><span class="line">        tf.summary.scalar('valid_loss', loss, collections=['valid'])</span><br><span class="line"></span><br><span class="line">        # 4、构建模型优化器</span><br><span class="line">        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">        train_opt = optimizer.minimize(loss=loss)</span><br><span class="line"></span><br><span class="line">        # 5、求模型准确率</span><br><span class="line">        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(input_y, 1))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line">        # 可视化代码</span><br><span class="line">        tf.summary.scalar('train_accuracy', accuracy, collections=['train'])</span><br><span class="line">        tf.summary.scalar('valid_accuracy', accuracy, collections=['valid'])</span><br><span class="line"></span><br><span class="line">        # 6、构建持久化对象</span><br><span class="line">        CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">        create_file_path(CKECKPOINT_DIR)</span><br><span class="line">        saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session(graph=graph) as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        # todo 模型可视化。</span><br><span class="line">        train_sum = tf.summary.merge_all('train')</span><br><span class="line">        valid_sum = tf.summary.merge_all('valid')</span><br><span class="line"></span><br><span class="line">        LOG_DIR = './model/graph'</span><br><span class="line">        train_writer = tf.summary.FileWriter(LOG_DIR+ '/train_graph', graph=sess.graph)</span><br><span class="line">        valid_writer = tf.summary.FileWriter(LOG_DIR+ '/valid_graph')</span><br><span class="line"></span><br><span class="line">        step = 1</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            # 构建批量数据的循环操作</span><br><span class="line">            for batch in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                # 获取当前批量的数据(该数据已经归一化，且随机打乱的)</span><br><span class="line">                batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                feed = {input_x: batch_x, input_y:batch_y,</span><br><span class="line">                        learning_rate:lr, keep_probab:keep_prob}</span><br><span class="line">                sess.run(train_opt, feed_dict=feed)  # 执行模型训练</span><br><span class="line">                if step % 2 == 0:</span><br><span class="line">                    feed = {input_x: batch_x, input_y: batch_y,</span><br><span class="line">                            learning_rate: lr, keep_probab: 1.0}</span><br><span class="line">                    train_loss, train_acc, train_sum_ = sess.run(</span><br><span class="line">                        [loss, accuracy, train_sum], feed)</span><br><span class="line">                    train_writer.add_summary(train_sum_, global_step=step)</span><br><span class="line"></span><br><span class="line">                    val_feed = {input_x: mnist.validation.images[:test_valid_size],</span><br><span class="line">                                input_y: mnist.validation.labels[:test_valid_size],</span><br><span class="line">                                keep_probab: 1.0}</span><br><span class="line">                    val_loss, val_acc, valid_sum_ = sess.run(</span><br><span class="line">                        [loss, accuracy, valid_sum], val_feed)</span><br><span class="line">                    valid_writer.add_summary(valid_sum_, global_step=step)</span><br><span class="line">                    print('Epochs:{} - Step:{} - Train Loss:{:.5f} - Valid Loss:{:.5f} - Valid Acc:{:.5f}'.format(</span><br><span class="line">                        e, step, train_loss, val_loss, val_acc</span><br><span class="line">                    ))</span><br><span class="line">                step += 1</span><br><span class="line">                # todo 模型持久化</span><br><span class="line">                if step % 50 == 0:</span><br><span class="line">                    files = 'model.ckpt'</span><br><span class="line">                    save_files = os.path.join(CKECKPOINT_DIR, files)</span><br><span class="line">                    saver.save(sess, save_path=save_files, global_step=step)</span><br><span class="line">                    print('模型成功持久化到文件夹:{}'.format(save_files))</span><br><span class="line">        # todo 测试数据集效果</span><br><span class="line">        test_feed = {input_x: mnist.test.images[:test_valid_size],</span><br><span class="line">                     input_y: mnist.test.labels[:test_valid_size],</span><br><span class="line">                     keep_probab: 1.0}</span><br><span class="line">        test_acc = sess.run(accuracy, test_feed)</span><br><span class="line">        print('Test Acc:{:.5f}'.format(test_acc))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def restore_train():</span><br><span class="line">    """</span><br><span class="line">    恢复模型继续训练</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with graph.as_default():</span><br><span class="line">        # 1、创建占位符</span><br><span class="line">        input_x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='input_x')</span><br><span class="line">        input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')</span><br><span class="line">        learning_rate = tf.placeholder(tf.float32, shape=None, name='learning_rate')</span><br><span class="line">        keep_probab = tf.placeholder(tf.float32, shape=None, name='keep_probab')</span><br><span class="line"></span><br><span class="line">        # 2、构建模型</span><br><span class="line">        logits = model(input_x, weights, biases, keep_prob=keep_probab)</span><br><span class="line"></span><br><span class="line">        # 3、构建模型损失</span><br><span class="line">        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">            logits=logits, labels=input_y</span><br><span class="line">        ))</span><br><span class="line"></span><br><span class="line">        # 4、构建模型优化器</span><br><span class="line">        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">        train_opt = optimizer.minimize(loss=loss)</span><br><span class="line"></span><br><span class="line">        # 5、求模型准确率</span><br><span class="line">        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(input_y, 1))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line">        # 6、构建持久化对象</span><br><span class="line">        CKECKPOINT_DIR = './model/ai13'</span><br><span class="line">        saver = tf.train.Saver(max_to_keep=1)</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session(graph=graph) as sess:</span><br><span class="line">        # fixme 恢复模型继续训练.</span><br><span class="line">        # 获取持久化对象的信息。</span><br><span class="line">        ckpt = tf.train.get_checkpoint_state(CKECKPOINT_DIR)</span><br><span class="line">        if ckpt is not None:</span><br><span class="line">            saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">            print('成功恢复模型继续训练!')</span><br><span class="line">        else:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            print('没有持久化的模型，从头随机初始化开始训练!')</span><br><span class="line"></span><br><span class="line">        step = 1</span><br><span class="line">        for e in range(epochs):</span><br><span class="line">            # 构建批量数据的循环操作</span><br><span class="line">            for batch in range(mnist.train.num_examples // batch_size):</span><br><span class="line">                # 获取当前批量的数据(该数据已经归一化，且随机打乱的)</span><br><span class="line">                batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line"></span><br><span class="line">                feed = {input_x: batch_x, input_y:batch_y,</span><br><span class="line">                        learning_rate:lr, keep_probab:keep_prob}</span><br><span class="line">                sess.run(train_opt, feed_dict=feed)  # 执行模型训练</span><br><span class="line">                if step % 2 == 0:</span><br><span class="line">                    feed = {input_x: batch_x, input_y: batch_y,</span><br><span class="line">                            learning_rate: lr, keep_probab: 1.0}</span><br><span class="line">                    train_loss, train_acc = sess.run(</span><br><span class="line">                        [loss, accuracy], feed)</span><br><span class="line"></span><br><span class="line">                    val_feed = {input_x: mnist.validation.images[:test_valid_size],</span><br><span class="line">                                input_y: mnist.validation.labels[:test_valid_size],</span><br><span class="line">                                keep_probab: 1.0}</span><br><span class="line">                    val_loss, val_acc = sess.run(</span><br><span class="line">                        [loss, accuracy], val_feed)</span><br><span class="line">                    print('Epochs:{} - Step:{} - Train Loss:{:.5f} - Valid Loss:{:.5f} - Valid Acc:{:.5f}'.format(</span><br><span class="line">                        e, step, train_loss, val_loss, val_acc</span><br><span class="line">                    ))</span><br><span class="line">                step += 1</span><br><span class="line">                # todo 模型持久化</span><br><span class="line">                if step % 50 == 0:</span><br><span class="line">                    files = 'model.ckpt'</span><br><span class="line">                    save_files = os.path.join(CKECKPOINT_DIR, files)</span><br><span class="line">                    saver.save(sess, save_path=save_files, global_step=step)</span><br><span class="line">                    print('模型成功持久化到文件夹:{}'.format(save_files))</span><br><span class="line">        # todo 测试数据集效果</span><br><span class="line">        test_feed = {input_x: mnist.test.images[:test_valid_size],</span><br><span class="line">                     input_y: mnist.test.labels[:test_valid_size],</span><br><span class="line">                     keep_probab: 1.0}</span><br><span class="line">        test_acc = sess.run(accuracy, test_feed)</span><br><span class="line">        print('Test Acc:{:.5f}'.format(test_acc))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # train()</span><br><span class="line">    restore_train()</span><br></pre></td></tr></tbody></table></figure></div><p>批归一化：</p><p>批归一化BN原理—平滑了损失函数超平面<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.6.png" data-fancybox="group" data-caption="6.6" class="fancybox"><img alt="6.6" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.6.png" class="lazyload" title="6.6"></a></p><p><a href="https://www.cnblogs.com/skyfsm/p/8453498.html" target="_blank" rel="noopener">https://www.cnblogs.com/skyfsm/p/8453498.html</a></p><p>训练集</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.7.png" data-fancybox="group" data-caption="6.7" class="fancybox"><img alt="6.7" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.7.png" class="lazyload" title="6.7"></a></p><p>对测试集<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.8.png" data-fancybox="group" data-caption="6.8" class="fancybox"><img alt="6.8" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.8.png" class="lazyload" title="6.8"></a></p><p>批归一化在激活函数前 dropout在激活函数后</p><h1 id="cnn-adam优化器"><a class="markdownIt-Anchor" href="#cnn-adam优化器"></a> cnn-Adam优化器</h1><h2 id="自适应学习率本质是调整梯度值"><a class="markdownIt-Anchor" href="#自适应学习率本质是调整梯度值"></a> 自适应学习率（本质是调整梯度值）</h2><h3 id="指数移动平均数"><a class="markdownIt-Anchor" href="#指数移动平均数"></a> 指数移动平均数</h3><p>Mean t = beta* Mean t-1 + (1-beta) * 当前均值<br>beta = 0.9  0.99</p><p><a href="https://zhuanlan.zhihu.com/p/32335746" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32335746</a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.9.png" data-fancybox="group" data-caption="6.9" class="fancybox"><img alt="6.9" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.9.png" class="lazyload" title="6.9"></a></p><p>只需保存v这个变量</p><h3 id="动量momentum"><a class="markdownIt-Anchor" href="#动量momentum"></a> 动量Momentum</h3><p>tf.train.MomentumOptimizer()</p><p>减小震荡，向最优值前进。</p><p>能够跳出局部最优(当W_2为0，还有V_2）<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.13.png" data-fancybox="group" data-caption="6.13" class="fancybox"><img alt="6.13" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.13.png" class="lazyload" title="6.13"></a></p><p>2、均方根RMSProp</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.14.png" data-fancybox="group" data-caption="6.14" class="fancybox"><img alt="6.14" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.14.png" class="lazyload" title="6.14"></a></p><p>tf.train.RMSPropOptimizer()</p><p>3、Adam</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.15.png" data-fancybox="group" data-caption="6.15" class="fancybox"><img alt="6.15" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.15.png" class="lazyload" title="6.15"></a></p><p>tf.train.AdamOptimizer()</p><h2 id="批归一化作用"><a class="markdownIt-Anchor" href="#批归一化作用"></a> 批归一化作用</h2><ol><li><p><strong>网络训练更快</strong> – 神经网络每一次迭代都会做大量的计算（正向和反向，以及调整超参数），导致很慢。如果能够更快的收敛，那么整体训练速度自然要快很多。</p></li><li><p><strong>允许更大的学习率</strong> – 梯度下降算法要求使用非常小的学习率，网络才能收敛。网络越深，反向传播的梯度也会越小，就需要更多的迭代来学习。批归一化允许我们使用相对来说大一些的学习率，可以加速网络训练。</p></li><li><p><strong>权重初始化更容易</strong> – 权重初始化是很难的，特别是当网络越来越来深。批归一化允许我们不用过分关心权重初始化的值。</p></li><li><p><strong>使激活函数有更多选择</strong> – 部分激活函数有使用条件限定。Sigmoid不能用于深度网络中，因其丢失梯度过高。 ReLUs经常会梯度消失而导致网络完全停止学习，所以非常小心值域范围（读入激活函数的）。但批归一化对任何进入激活函数的值都做了规范，所以之前在深度网络中表现不好的非线性函数也可以作为备选项了。</p></li><li><p><strong>创建深度网络更简单</strong> – 基于1-4原因，使用批归一化创建并训练深度网络更简单。当然网络越深，一般而言，效果越好。</p></li><li><p><strong>提供了一些正则化作用</strong> – 批归一化是在网络中增加了一些噪音。实际起了一定的dropout功能，所以在使用了批归一化网络中，可以考虑减少dropout的使用。</p></li><li><p><strong>总之，让网络效果更佳</strong> – 有一些测试表明批归一化能够改进网络效果。BN是优化网络速度的手段，而不是提升网络精度的方法。显然，若你可以训练的更快，意味着你可以尝试更多网络设计方案，迭代更多次，也可以构建更深的网络（效果更佳）。最终你通过批归一化达到提升网络效果。</p></li></ol><p>批归一化在批量batch_size很小的情况下会失效</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.11.jpg" data-fancybox="group" data-caption="6.11" class="fancybox"><img alt="6.11" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.11.jpg" class="lazyload" title="6.11"></a><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.10.png" data-fancybox="group" data-caption="6.10" class="fancybox"><img alt="6.10" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.10.png" class="lazyload" title="6.10"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.12.png" data-fancybox="group" data-caption="6.12" class="fancybox"><img alt="6.12" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/6.12.png" class="lazyload" title="6.12"></a></p><p>做位移和缩放时按通道数（4）去做</p><h1 id="数据增强"><a class="markdownIt-Anchor" href="#数据增强"></a> 数据增强</h1><p>增加训练数据，则能够提升算法的准确率，因为这样可以避免过拟合，而避免了过拟合你就可以增大你的网络结构了。当训练数据有限的时候，可以通过一些变换来从已有的训练数据集中生成一些新的数据，来扩大训练数据。数据增强的方法有：</p><p>1）水平翻转（旋转） CNN不具有旋转不变性</p><p>2）随机裁剪(crop采样)<br>如原始图像大小为256<em>256，随机裁剪出一些图像224</em>224的图像。如下图，红色方框内为随机裁剪出的224*224的图片。 AlexNet 训练时，对左上、右上、左下、右下、中间做了5次裁剪，然后翻转，得到一些剪切图片。防止大网络过拟合(under ubstantial overfitting)。</p><p>3）样本不均衡（解决方案：增加小众类别的图像数据）<br>样本不均衡即有些类别图像特别多，有些特别少。类别不平衡数据的处理：Label shuffle。</p><p>4）其他<br>平移变换；<br>旋转/仿射变换（线性变换+平移）；<br>高斯噪声、模糊处理<br>对颜色的数据增强：图像亮度、饱和度、对比度变化。</p><p>5）训练和测试要协调<br>在训练的时候，我们通常都需要做数据增强，在测试的时候，我们通常很少去做数据增强。这其中似乎有些不协调，因为你训练和测试之间有些不一致。实验发现，训练的最后几个迭代，移除数据增强，和传统一样测试，可以提升一点性能。<br>如果训练的时候一直使用尺度和长宽比增强数据增强，在测试的时候也同样做这个变化，随机取32个裁剪图片来测试，也可以在最后的模型上提升一点性能。<br>就是多尺度的训练，多尺度的测试。</p><h1 id="经典网络71"><a class="markdownIt-Anchor" href="#经典网络71"></a> 经典网络<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.1.png" data-fancybox="group" data-caption="7.1" class="fancybox"><img alt="7.1" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.1.png" class="lazyload" title="7.1"></a></h1><p>GoogleNet</p><p>1*1卷积核融合的是通道之间的信息</p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.3.jpg" data-fancybox="group" data-caption="7.3" class="fancybox"><img alt="7.3" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.3.jpg" class="lazyload" title="7.3"></a><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.4.png" data-fancybox="group" data-caption="7.4" class="fancybox"><img alt="7.4" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.4.png" class="lazyload" title="7.4"></a></p><p><a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7-6.png" data-fancybox="group" data-caption="7-6" class="fancybox"><img alt="7-6" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/7-6.png" class="lazyload" title="7-6"></a></p><p>融合了不同尺度的特征信息<a href="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.2.png" data-fancybox="group" data-caption="7.2" class="fancybox"><img alt="7.2" data-src="../img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/cnn/7.2.png" class="lazyload" title="7.2"></a></p><h1 id="骨干网络趋势"><a class="markdownIt-Anchor" href="#骨干网络趋势"></a> 骨干网络趋势</h1><p>1.深。ResNet DenseNet</p><p>2.宽。Inception  Inception-ResNet（宽+深） ResNet（宽+深）</p><p>3.卷积的注意力机制。SeNet CBAM Non-local-Net   Global Context net</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tensflow</title>
      <link href="/2020/01/17/tensflow/"/>
      <url>/2020/01/17/tensflow/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>TensorFlow变量作用域 TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。 其命名来源于本身的原理，Tensor（张量）意味着N维数组，Flow（流）意味着基于数据流图的计算.Tensorflow运行过程就是张量从图的一端流动到另一端的计算过程。张量从图中流过的直观图像是其取名为“TensorFlow”的原因。</p><p>TensorFlow的关键点是：“Data Flow Graphs”，表示TensorFlow是一种基于图的计算框架，其中节点（Nodes）在图中表示数学操作，线（Edges）则表示在节点间相互联系的多维数据数组，即张量（Tensor），这种基于流的架构让TensorFlow具有非常高的灵活性，该灵活性也让TensorFlow框架可以在多个平台上进行计算，例如：台式计算机、服务器、移动设备等。<br>备注：TensorFlow的开发过程中，重点在于构建执行流图。</p><p>What is Data Flow Graphs?</p><p>数据流图使用节点（Node）和线（Edges）的有向图描述数学计算；节点一般用来表示施加的数学操作，也可以表示数据输入(feed in)的起点和输出(push out)的终点，或者是读取/写入持久变量(persistent variable)的终点。线表示的是节点之间的输入/输出关系，这些线可以输运“size可动态调整”的多维数组，即张量(Tensor)。</p><p>一旦输入端的所有张量准备好，节点将被分配到各种计算设备完成异步并行地执行运算。<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/1_ys.png" class="lazyload" title="1_ys"></a></p><p>TensorFlow基本概念:</p><p>图（Graph）：图描述了计算的过程，TensorFlow使用图来表示计算任务。</p><p>张量（Tensor）：TensorFlow使用tensor表示数据。每个Tensor是一个类型化的多维数组。</p><p>操作（op）：图中的节点被称为op（opearation的缩写），一个op获得/输入0个或多个Tensor，执行计算，产生0个或多个Tensor。</p><p>变量（Variable）：运行过程中可以被改变，用于维护状态。</p><p>会话（Session）：图必须在称之为“会话”的上下文中执行。会话将图的op分发到诸如CPU或GPU之类的设备上执行。</p><p>TensorFlow的边即有两种连接关系：<br>数据依赖<br>控制依赖<br>实线边表示数据依赖，代表数据，即张量。任意维度的数据统称为张量。在机器学习算法中，张量在数据流图中从前往后流动一遍就完成一次前向传播，而残差从后向前流动一遍就完成一次反向传播。<br>虚线边表示控制依赖，可以用于控制操作的运行，这被用来确保happens-before关系，这类边上没有数据流过，但源节点必须在目的节点开始执行前完成。</p><p>数据属性：</p><table><thead><tr><th><strong>数据类型</strong></th><th><strong>Python****类型</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>DT_FLOAT</td><td>tf.float32</td><td>32位浮点型</td></tr><tr><td>DT_DOUBLE</td><td>tf.float64</td><td>64位浮点型</td></tr><tr><td>DT_INT64</td><td>tf.int64</td><td>64位有符号整型</td></tr><tr><td>DT_INT32</td><td>tf.int32</td><td>32位有符号整型</td></tr><tr><td>DT_INT16</td><td>tf.int16</td><td>16位有符号整型</td></tr><tr><td>DT_INT8</td><td>tf.int8</td><td>8位有符号整型</td></tr><tr><td>DT_UINT8</td><td>tf.uint8</td><td>8位无符号整型</td></tr><tr><td>DT_STRING</td><td>tf.string</td><td>可变长度的字节数组，每一个张量元素都是一个字节数组</td></tr><tr><td>DT_BOOL</td><td>tf.bool</td><td>布尔型</td></tr><tr><td>DT_COMPLEX64</td><td>tf.complex64</td><td>由两个32位浮点数组成的复数：实数和虚数</td></tr></tbody></table><p>节点：</p><p>节点又称为算子，它代表一个操作，一般用来表示施加的数字运算，也可以表示数据输入的起点以及输出的重点，或者是读取/写出持久化变量的终点。</p><table><thead><tr><th><strong>类别</strong></th><th><strong>示例</strong></th></tr></thead><tbody><tr><td>数学运算操作</td><td>Add、Subtract、Multiply、Div、Exp、Log、Greater、Less、Equal……</td></tr><tr><td>数组运算操作</td><td>Concat, Slice, Split, Constant, Rank, Shape, Shuffle……</td></tr><tr><td>矩阵运算操作</td><td>MatMul, MatrixInverse, MatrixDeterminant……</td></tr><tr><td>有状态的操作</td><td>Variable、Assign、AssignAdd……</td></tr><tr><td>神经网络构建操作</td><td>SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool……</td></tr><tr><td>检查点操作</td><td>Save, Restore……</td></tr><tr><td>队列和同步操作</td><td>Enqueue, Dequeue, MutexAcquire, MutexRelease……</td></tr><tr><td>控制张量流动的操作</td><td>Merge, Switch, Enter, Leave, NextIteration……</td></tr></tbody></table><p>使用TensorFlow必须理解下列概念：<br>使用图(graph)来表示计算任务；<br>在会话(session)的上下文中执行图；<br>使用tensor表示数据；<br>通过变量(Variable)来维护状态 ；<br>使用feed和fetch可以为任意的操作(Operation/op)赋值或者从其中获取数据。</p><p>TensorFlow程序结构:</p><p>TensorFlow的程序一般分为两个阶段：构建阶段和执行阶段；<br>构建阶段：op的执行步骤被描述称为一个图，然后使用TensorFlow提供的API构建这个图。<br>执行阶段：将构建好的执行图(Operation Graph)在给定的会话中执行，并得到执行结果。</p><p>TensorFlow图：</p><p>不使用默认图(Graph)，使用多个图来进行编程；但是注意：操作必须属于同一个图，不同图中的节点不能相连。</p><p>TensorFlow会话:</p><p>当执行图构建完成后，才能给启动图，进入到执行阶段；启动图的第一步就是创建一个Session对象，如果无任何参数的情况下，会话构造器将启动默认图。</p><p>tf.Session在构建会话的时候，如果不给定任何参数，那么构建出来Session对应的内部的Graph其实就是默认Graph，不过我们可以通过参数给定具体对应的是那一个Graph以及当前Session对应的配合参数。Session的构造主  要有三个参数，作用如下：<br>target：给定连接的url，只有当分布式运行的时候需要给定(后面分布式运行讲)；<br>graph：给定当前Session对应的图，默认为TensorFlow中的默认图；<br>config：给定当前Session的相关参数，参数详见：<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto%E4%B8%AD%E7%9A%84%5BConfigProto%5D" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto中的[ConfigProto]</a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">tf.Session(target='', graph=None, config=None)</span><br><span class="line">    target: 给定连接的url，只有当分布式运行的时候需要给定。</span><br><span class="line">    graph:  调用哪张图，如果不给定，则调用默认图。</span><br><span class="line">    config: 会话的配置文件。</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>通过Session的config参数可以对TensorFlow的应用的执行进行一些优化调整，主要涉及到的参数如下：</p><table><thead><tr><th><strong>属性</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>gpu_options</td><td>GPU相关参数，主要参数：per_process_gpu_memory_fraction和allow_growth</td></tr><tr><td>allow_soft_placement</td><td>是否允许动态使用CPU和GPU，默认为False；当我们的安装方式为GPU的时候，建议该参数设置为True，因为TensorFlow中的部分op只能在CPU上运行。</td></tr><tr><td>log_device_placement</td><td>是否打印日志，默认为False，不打印日志</td></tr><tr><td>graph_options</td><td>Graph优化相关参数，一般不需要给定，默认即可，主要参数：optimizer_options(do_common_subexpression_elimination、do_constant_folding和opt_level)</td></tr></tbody></table><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">"""</span><br><span class="line">gpu_options 参数</span><br><span class="line">    per_process_gpu_memory_fraction 浮点数[0, 1.0]， 表示限制该gpu设备显存使用的百分比</span><br><span class="line">    allow_growth  bool值，不预先分配使用整个gpu显存计算，而是从小到大按需增长。</span><br><span class="line">"""</span><br></pre></td></tr></tbody></table></figure></div><p>在TensorFlow中，除了可以使用Session表示这个会话外，还可以通过InteractiveSession来表示会话，InteractiveSession的意思是：交互式会话，使用交互式会话可以降低代码的复杂度，使用Tensor.eval()或者Operation.run()来代替Session.run()方法，这样可以避免一个变量来维持会话；备注：Session也可以使用Tensor.eval()和Operation.run()获取数据/执行操作(只要明确当前会话)。</p><p>Tensor张量：</p><p>TensorFlow使用Tensor数据结构来代表所有数据，计算图中，操作间传递的数据都是Tensor。Tensor可以看作是一个n维的数组或者列表，一个Tensor主要由一个静态数据类型和动态类型的维数(Rank、Shape)组成。Tensor可以在图中的节点之间流通。</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/2.png" class="lazyload" title="2"></a></p><p>TensorFlow变量：</p><p>变量(Variables)是维护图执行过程中的状态信息。在训练模型过程中，可以通过变量来存储和更新参数。变量包含张量(Tensor)存放于内存的缓存区。建模的时候变量必须被明确的初始化，模型训练后变量必须被存储到磁盘。这些变量的值可以在之后的模型训练和分析中被加载。</p><p>在构建变量的时候，必须将一个张量或者可以转化为张量的Python对象作为初始值传入构造函数Variable中。</p><p>占位符：</p><p>可以使用 shape=[None, 3]， None使用类似于numpy。</p><p>input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name=‘input_x’)</p><p>y_hat_, y_hat1_ = sess.run(<br>fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</p><p>以字典方式通过feed_dict传入</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">使用tensorflow 实现简单的 线性回归  y = np.dot(x, W) + b</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def f1():</span><br><span class="line">    """</span><br><span class="line">    先使用常量进行构建，展示大致的业务逻辑</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入</span><br><span class="line">        input_x = tf.constant(</span><br><span class="line">            value=[[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]], dtype=tf.float32, shape=[4, 3], name='input_x'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.constant(</span><br><span class="line">            value=[[-5],</span><br><span class="line">                   [3],</span><br><span class="line">                   [2]], dtype=tf.float32, shape=[3, 1], name='weights'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_ = sess.run(y_hat)</span><br><span class="line">            print(y_hat_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f2():</span><br><span class="line">    """</span><br><span class="line">    变量使用 tf.Variable()来构建</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入</span><br><span class="line">        input_x = tf.constant(</span><br><span class="line">            value=[[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]], dtype=tf.float32, shape=[4, 3], name='input_x'</span><br><span class="line">        )</span><br><span class="line">        """</span><br><span class="line">        tf.Variable(self,</span><br><span class="line">               initial_value=None,    # 给定初始化的值，可以是python的基本数据类型，也可以是tf的tensor对象</span><br><span class="line">               trainable=True,        # bool 该变量是否参与模型训练。也就是该变量是否会执行梯度下降</span><br><span class="line">               collections=None,</span><br><span class="line">               validate_shape=True,</span><br><span class="line">               caching_device=None,</span><br><span class="line">               name=None,            # tensorflow底层的名字。</span><br><span class="line">               variable_def=None,</span><br><span class="line">               dtype=None,           # 数据类型</span><br><span class="line">               expected_shape=None,</span><br><span class="line">               import_scope=None,</span><br><span class="line">               constraint=None):</span><br><span class="line">        """</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_ = sess.run(y_hat)</span><br><span class="line">            print(y_hat_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f3():</span><br><span class="line">    """</span><br><span class="line">    占位符的使用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入(占位符)</span><br><span class="line">        # todo 可以使用 shape=[None, 3]， None使用类似于numpy。</span><br><span class="line">        input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='input_x')</span><br><span class="line">        input_c = tf.placeholder_with_default(</span><br><span class="line">            input=1.0, shape=[], name='input_c'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        y_hat1 = y_hat + input_c</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # 加载训练数据</span><br><span class="line">            data1 = [[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]]</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data1})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">            data2 = [[1, 2, 3],</span><br><span class="line">                     [2, 3, 4],</span><br><span class="line">                     [2, 3, 9]]</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f4():</span><br><span class="line">    """</span><br><span class="line">    tensorboard的调用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 一、建图</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、创建模型输入(占位符)</span><br><span class="line">        # todo 可以使用 shape=[None, 3]， None使用类似于numpy。</span><br><span class="line">        input_x = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='input_x')</span><br><span class="line">        input_c = tf.placeholder_with_default(</span><br><span class="line">            input=1.0, shape=[], name='input_c'</span><br><span class="line">        )</span><br><span class="line">        # 2、创建变量</span><br><span class="line">        weights = tf.Variable(</span><br><span class="line">            initial_value=[[-5],</span><br><span class="line">                           [3],</span><br><span class="line">                           [2]], dtype=tf.float32, name='weights'</span><br><span class="line">        )</span><br><span class="line">        print(weights)</span><br><span class="line">        bias_value = tf.constant(</span><br><span class="line">            value=[2], dtype=tf.float32, shape=[1], name='bias'</span><br><span class="line">        )</span><br><span class="line">        bias = tf.Variable(initial_value=bias_value, dtype=tf.float32, name='bias')</span><br><span class="line"></span><br><span class="line">        # 3、构建正向传播过程</span><br><span class="line">        y_hat = tf.matmul(input_x, weights) + bias</span><br><span class="line">        y_hat1 = y_hat + input_c</span><br><span class="line">        print(y_hat)</span><br><span class="line"></span><br><span class="line">        # 二、构建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 执行变量初始化赋值</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            # fixme 加入一段可视化代码</span><br><span class="line">            """</span><br><span class="line">            tf.summary.FileWriter(self,</span><br><span class="line">               logdir,                # 记录日志或者事件的路径。</span><br><span class="line">               graph=None,            # 可视化的图对象</span><br><span class="line">               max_queue=10,</span><br><span class="line">               flush_secs=120,</span><br><span class="line">               graph_def=None,</span><br><span class="line">               filename_suffix=None,</span><br><span class="line">               session=None):</span><br><span class="line">            """</span><br><span class="line">            writer = tf.summary.FileWriter(</span><br><span class="line">                logdir='./model/ai13', graph=sess.graph</span><br><span class="line">            )</span><br><span class="line">            # 加载训练数据</span><br><span class="line">            data1 = [[1,2,3],</span><br><span class="line">                   [2,3,4],</span><br><span class="line">                   [12,34,23],</span><br><span class="line">                   [2,3,9]]</span><br><span class="line">            # 执行模型图</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data1})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">            data2 = [[1, 2, 3],</span><br><span class="line">                     [2, 3, 4],</span><br><span class="line">                     [2, 3, 9]]</span><br><span class="line">            y_hat_, y_hat1_ = sess.run(</span><br><span class="line">                fetches=[y_hat, y_hat1], feed_dict={input_x: data2, input_c: 10.0})</span><br><span class="line">            print(y_hat_, y_hat1_)</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    f4()</span><br></pre></td></tr></tbody></table></figure></div><p>tensorboard 可视化：</p><p>打开日志文件 tensorboard —logdir 绝对路径（到文件夹 ）</p><p>“”"<br>tf.summary.FileWriter(self,<br>logdir,                # 记录日志或者事件的路径。<br>graph=None,            # 可视化的图对象<br>max_queue=10,<br>flush_secs=120,<br>graph_def=None,<br>filename_suffix=None,<br>session=None):<br>“”"<br>writer = tf.summary.FileWriter(<br>logdir=’./model/ai13’, graph=sess.graph<br>)</p><p>TensorFlow控制依赖：</p><p>with g.control_dependencies[a,b,c]:</p><h1 id="d-and-e-will-only-run-after-a-b-c-have-executed"><a class="markdownIt-Anchor" href="#d-and-e-will-only-run-after-a-b-c-have-executed"></a> “d” and “e” will only run after ‘’’a‘’ ‘’b’’ ‘’c’‘ have executed</h1><p>我们可以通过Variable和assign完成变量的定义和更新，但是如果在更新变量之前需要更新其它变量，那么会导致一个比较严重的问题：也就是需要多次调用sess.run方法来进行变量的更新。通过这种方式，代码复杂程度上升，同时也没有执行效率。<br>解决该问题的方案就是：控制依赖。通过TensorFlow中提供的一组函数来处理不完全依赖的情况下的操作排序问题(即给定哪个操作先执行的问题)， 通过tf.control_dependencies API完成。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def change_var_shape():</span><br><span class="line">    """</span><br><span class="line">    实现动态的更新变量的维度数目。需要设置tf.assign中的validate_shape=False</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个变量</span><br><span class="line">        x = tf.Variable(</span><br><span class="line">            initial_value=[[0, 2, 3, 4, 0]],</span><br><span class="line">            dtype=tf.float32,</span><br><span class="line">            validate_shape=True   # 设置为False时候，表示不进行初始值shape的验证</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 2、做一个矩阵合并的操作---沿着行进行合并。</span><br><span class="line">        temp = [0.0, 2.0, 3.0, 4.0, 0.0]</span><br><span class="line">        concat = tf.concat(values=[x, tf.expand_dims(temp, axis=0)], axis=0) # 必须沿着已经存在的轴进行拼接。tf.expand_dims扩展轴</span><br><span class="line">        # tf.squeeze()  缩减tensor中维度为1的轴（需要指定）。</span><br><span class="line">        # 3、做一个赋值更新的操作</span><br><span class="line">        assign_opt = tf.assign(ref=x, value=concat, validate_shape=False)</span><br><span class="line"></span><br><span class="line">        # 二、执行会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            for _ in range(5):</span><br><span class="line">                _, x_ = sess.run([assign_opt, x])</span><br><span class="line">                print(x_)</span><br></pre></td></tr></tbody></table></figure></div><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tens/3.png" class="lazyload" title="3"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def factorial():</span><br><span class="line">    """</span><br><span class="line">    实现一个求解n阶乘的值，再乘以3的这样一个需求。</span><br><span class="line">    tf.control_dependencies()</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示一个数字</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行乘法的操作</span><br><span class="line">        temp = sum_x * input_x</span><br><span class="line">        # 将temp 赋值给 sum_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">            y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line">        该段代码的含义是：确保执行顺序为  assign_opt --> assign_opt1 --> y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt1]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow设备:</p><p>设备是指一块可以用来运算并且拥有自己的地址空间的硬件，如CPU和GPU。Tensorflow为了在执行操作的时候，充分利用计算资源，可以明确指定操作在哪个设备上执行。</p><p>一般情况下，不需要显示指定使用CPU还是GPU，TensorFlow会自动检测。如果检测到GPU，TensorFlow会尽可能地利用第一个GPU来执行操作。注意：如果机器上有超过一个可用的GPU，那么除了第一个外其它GPU默认是不参与计算的。所以，在实际TensorFlow编程中，经常需要明确给定使用的CPU和GPU。</p><p>“/cpu:0”：表示使用机器CPU运算<br>“/gpu:0”：表示使用第一个GPU运算，如果有的话<br>“/gpu:1”：表示使用第二个GPU运算，以此类推</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def factorial():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        """</span><br><span class="line">        注意事项：</span><br><span class="line">        如果不使用tf.device指定具体运行的设备的话，tensorflow会根据你安装的版本选择默认的设备运行。</span><br><span class="line">            1、如果安装的是cpu版本的tf，那么运行在cpu上面。</span><br><span class="line">            2、如果安装的是gpu版本的tf，那么运算操作一定运行在第一个gpu，但是会在所有gpu上分配内存。</span><br><span class="line">            如何通过tf.device指定了具体的运行设备，那么该运算一定会放到你指定的设备上运行，如果没有，就会报错。</span><br><span class="line">            建议将：allow_soft_placement=True</span><br><span class="line">        """</span><br><span class="line">        with tf.device('/CPU:0'):</span><br><span class="line">            # 1、定义一个占位符，表示一个数字</span><br><span class="line">            input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        with tf.device('/CPU:1'):</span><br><span class="line">            # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">            sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        with tf.device('/GPU:0'):</span><br><span class="line">            # 3、执行乘法的操作</span><br><span class="line">            temp = sum_x * input_x</span><br><span class="line">            # 将temp 赋值给 sum_x</span><br><span class="line">            assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">            # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        config = tf.ConfigProto(</span><br><span class="line">            log_device_placement=True, allow_soft_placement=True</span><br><span class="line">        )</span><br><span class="line">        with tf.Session(config=config) as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">假设现在有两个GPU，我们代码运行的时候希望仅在第二个GPU上运行，并且仅在第二个GPU上分配内存 </span><br><span class="line">               --> 通过给定环境变量解决</span><br><span class="line">"""</span><br><span class="line"># os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "0,1"  # 允许当前代码使用第一块、第二块GPU</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "1"  # 允许当前代码使用第二块GPU</span><br><span class="line"># os.environ['CUDA_VISIBLE_DEVICES'] = "-1"  # 允许当前代码不允许使用GPU</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    factorial()</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow变量作用域:</p><p>通过tf.Variable我们可以创建变量，但是当模型复杂的时候，需要构建大量的变量集，这样会导致我们对于变量管理的复杂性，而且没法共享变量(存在多个相似的变量)。针对这个问题，可以通过TensorFlow提供的变量作用域机制来解决，在构建一个图的时候，就可以非常容易的使用共享命名过的变量。</p><p>Tensorflow中有两个作用域，一个是name_scope，另一个是variable_scope。<br>变量作用域机制在TensorFlow中主要通过两部分组成：<br>tf.get_variable：通过所给定的名字创建或者返回一个对应的变量<br>tf.variable_scope：为通过创建的变量或者操作Operation指定命名空间</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># sum_x = 0</span><br><span class="line"># for i in range(1, 5):</span><br><span class="line">#     sum_x += i</span><br><span class="line">#     print(sum_x)</span><br><span class="line">with g.c</span><br><span class="line">def sum1():</span><br><span class="line">    """</span><br><span class="line">    使用tf.assign实现一个累加器。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示被累加的值</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存累加的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=0.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行累加的操作</span><br><span class="line">        sum_x = sum_x + input_x</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                sum_x_ = sess.run(sum_x, feed_dict={input_x: i})</span><br><span class="line">                print(sum_x_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def sum2():</span><br><span class="line">    """</span><br><span class="line">    使用tf.assign_add()  或者 tf.assign() 实现一个累加器。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示被累加的值</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存累加的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=0.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行累加的操作</span><br><span class="line">        # assign_add = tf.assign_add(ref=sum_x, value=input_x)</span><br><span class="line">        """</span><br><span class="line">        tf.assign(ref, value)</span><br><span class="line">            ref: 你要更新的值。</span><br><span class="line">            value: 累加的值。</span><br><span class="line">        """</span><br><span class="line">        temp = sum_x + input_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                sum_x_, _ = sess.run([sum_x, assign_opt], feed_dict={input_x: i})</span><br><span class="line">                print(sum_x_)</span><br><span class="line"></span><br><span class="line">def change_var_shape():</span><br><span class="line">    """</span><br><span class="line">    实现动态的更新变量的维度数目。需要设置tf.assign中的validate_shape=False</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个变量</span><br><span class="line">        x = tf.Variable(</span><br><span class="line">            initial_value=[[0, 2, 3, 4, 0]],</span><br><span class="line">            dtype=tf.float32,</span><br><span class="line">            validate_shape=True   # 设置为False时候，表示不进行初始值shape的验证</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 2、做一个矩阵合并的操作---沿着行进行合并。</span><br><span class="line">        temp = [0.0, 2.0, 3.0, 4.0, 0.0]</span><br><span class="line">        concat = tf.concat(values=[x, tf.expand_dims(temp, axis=0)], axis=0) # 必须沿着已经存在的轴进行拼接。</span><br><span class="line">        # tf.squeeze()  缩减tensor中维度为1的轴（需要指定）。</span><br><span class="line">        # 3、做一个赋值更新的操作</span><br><span class="line">        assign_opt = tf.assign(ref=x, value=concat, validate_shape=False)</span><br><span class="line"></span><br><span class="line">        # 二、执行会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            for _ in range(5):</span><br><span class="line">                _, x_ = sess.run([assign_opt, x])</span><br><span class="line">                print(x_)</span><br><span class="line">with control</span><br><span class="line"></span><br><span class="line">def factorial():</span><br><span class="line">    """</span><br><span class="line">    实现一个求解n阶乘的值，再乘以3的这样一个需求。</span><br><span class="line">    tf.control_dependencies()</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 1、定义一个占位符，表示一个数字</span><br><span class="line">        input_x = tf.placeholder(tf.float32, shape=None, name='inputx')</span><br><span class="line"></span><br><span class="line">        # 2、定一个变量，作为储存阶乘的值</span><br><span class="line">        sum_x = tf.Variable(initial_value=1.0, dtype=tf.float32, name='sum_x')</span><br><span class="line"></span><br><span class="line">        # 3、执行乘法的操作</span><br><span class="line">        temp = sum_x * input_x</span><br><span class="line">        # 将temp 赋值给 sum_x</span><br><span class="line">        assign_opt = tf.assign(ref=sum_x, value=temp)</span><br><span class="line"></span><br><span class="line">        # 4、将阶乘以后的sum_x 乘以3，得到最终的预测值y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">            y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line">        该段代码的含义是：确保执行顺序为  assign_opt --> assign_opt1 --> y_hat</span><br><span class="line">        with tf.control_dependencies(control_inputs=[assign_opt]):</span><br><span class="line">            with tf.control_dependencies(control_inputs=[assign_opt1]):</span><br><span class="line">                # fixme 在执行y_hat之前，一定先执行assign_opt赋值的操作</span><br><span class="line">                y_hat = sum_x * 3</span><br><span class="line">        """</span><br><span class="line"></span><br><span class="line">        # 二、创建会话</span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            # 构建迭代累加的值</span><br><span class="line">            data = [1, 3, 5, 7, 9]</span><br><span class="line">            for i in data:</span><br><span class="line">                y_hat_ = sess.run(y_hat, feed_dict={input_x: i})</span><br><span class="line">                print(y_hat_)</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # sum2()</span><br><span class="line">    # change_var_shape()</span><br><span class="line">    factorial()</span><br></pre></td></tr></tbody></table></figure></div><p>TensorFlow变量作用域：</p><p>通过tf.Variable我们可以创建变量，但是当模型复杂的时候，需要构建大量的变量集，这样会导致我们对于变量管理的复杂性，而且没法共享变量(存在多个相似的变量)。针对这个问题，可以通过TensorFlow提供的变量作用域机制来解决，在构建一个图的时候，就可以非常容易的使用共享命名过的变量。<br>Tensorflow中有两个作用域，一个是name_scope，另一个是variable_scope。<br>变量作用域机制在TensorFlow中主要通过两部分组成：<br>tf.get_variable：通过所给定的名字创建或者返回一个对应的变量<br>tf.variable_scope：为通过创建的变量或者操作Operation指定命名空间</p><p>tf.get_variable方法在调用的时候，主要需要给定参数名称name，形状shape，数据类型dtype以及初始化方式initializer四个参数。该API底层执行的时候，根据variable score的属性reuse的值决定采用何种方式来获取变量。当reuse值为False的时候(不允许设置)，作用域就是创建新变量设置的，此时要求对应的变量不存在，否则报错；当reuse值为True的时候，作用域就是为重用变量所设置的，此时要求对应的变量必须存在，否则报错。当reuse的值为tf.AUTO_REUSE的时候，表示如果变量存在就重用变量，如果变量不存在，就创建新变量返回。(备注：reuse一般设置在variable score对象上)</p><p>tf.get_variable常用的initializer初始化器：</p><table><thead><tr><th><strong>初始化器</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>tf.constant_initializer(value)</td><td>初始化为给定的常数值value</td></tr><tr><td>tf.random_uniform_initializer(a, b)</td><td>初始化为从a到b的均匀分布的随机值</td></tr><tr><td>tf.random_normal_initializer(mean, stddev)</td><td>初始化为均值为mean、方差为stddev的服从高斯分布的随机值</td></tr><tr><td>tf.orthogonal_initializer(gini=1.0)</td><td>初始化一个正交矩阵，gini参数作用是最终返回的矩阵是随机矩阵乘以gini的结果</td></tr><tr><td>tf.identity_initializer(gini=1.0)</td><td>初始化一个单位矩阵，gini参数作用是最终返回的矩阵是随机矩阵乘以gini的结果</td></tr></tbody></table><p>tf.variable_score方法的作用就是定义一个作用域，定义在variable_score作用域中的变量和操作，会将variable score的名称作为前缀添加到变量/操作名称前，支持嵌套的作用域，添加前缀规则和文件目录路径的规则类似。<br>tf.variable_score参数如果给定的是一个已经存在的作用域对象的时候，那么构建变量的时候表示直接跳过当前作用域前缀，直接成为一个完全不同与现在的作用域(直接创建给定作用域下的变量)。但是构建操作的时候，还是和嵌套的方式一样，直接添加子作用域。<br>tf.variable_score参数中，可以给定当前作用域中默认的初始化器initializer，并且子作用域会直接继承父作用域的相关参数(是否重用、默认初始化器等)</p><p>TensorFlow中的name_score和variable_score是两个不同的东西，name_score的主要作用是为op_name前加前缀，variable_score是为get_variable创建的变量的名字加前缀。简单来讲：使用tf.Variable创建的变量受name_score和variable_score的的效果，会给变量添加前缀，但是使用tf.get_variable创建变量只受variable_score的效果。<br>name_score的主要作用就是：Tensorflow中常常会有数以千计的节点，在可视化的过程中很难一下子展示出来，因此用name_scope为变量划分范围，在可视化中，这表示在计算图中的一个层级。name_scope会影响op_name，不会影响用get_variable()创建的变量，而会影响通过Variable()创建的变量。<br>注意：variable_score内部会创建一个同名的name_score</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">def f1():</span><br><span class="line">    """</span><br><span class="line">    基于tf.Variable()创建一个变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 创建一个新的变量，哪怕名字相同。</span><br><span class="line">    w = tf.Variable(</span><br><span class="line">        initial_value=tf.random_normal(shape=[2], mean=0.0, stddev=1.0),</span><br><span class="line">        dtype=tf.float32, name='w'</span><br><span class="line">    )</span><br><span class="line">    return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def f2(initializer=tf.random_normal_initializer(mean=0.0, stddev=1.0)):</span><br><span class="line">    """</span><br><span class="line">    基于tf.get_variable()获取或者创建变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    """</span><br><span class="line">    tf.get_variable(name,        # 变量名字，必须给定</span><br><span class="line">                 shape=None,     # 变量的形状</span><br><span class="line">                 dtype=None,     # 数据类型</span><br><span class="line">                 initializer=None,  # 该变量的初始值生成方式，也就是初始化器。</span><br><span class="line">                 regularizer=None,  # 正则化项</span><br><span class="line">                 trainable=True,    # 变量是否参与模型训练。</span><br><span class="line">                 collections=None,</span><br><span class="line">                 caching_device=None,</span><br><span class="line">                 partitioner=None,</span><br><span class="line">                 validate_shape=True,</span><br><span class="line">                 use_resource=None,</span><br><span class="line">                 custom_getter=None,</span><br><span class="line">                 constraint=None):</span><br><span class="line">        功能：基于给定的name从tensorflow内部获取相应的变量，如果name对应的变量已经存在，那么直接获取该变量，</span><br><span class="line">            如果不存在，直接创建一个新的变量。</span><br><span class="line">        注意：根据name获取变量重用，只支持tf.get_variable创建的变量。</span><br><span class="line">    """</span><br><span class="line">    w = tf.get_variable(</span><br><span class="line">        name='w', shape=[2], dtype=tf.float32, initializer=initializer</span><br><span class="line">    )</span><br><span class="line">    return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h1():</span><br><span class="line">    """</span><br><span class="line">    学习tf.get_variable()变量重用用法。</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、用tf.Variable()创建2个变量</span><br><span class="line">    w11 = f1()</span><br><span class="line">    w12 = f1()</span><br><span class="line"></span><br><span class="line">    # 2、用tf.get_variable()创建变量</span><br><span class="line">    w21 = f2()</span><br><span class="line">    # fixme 需要设置一下，告诉tf名字相同可以重用。</span><br><span class="line">    tf.get_variable_scope().reuse_variables()</span><br><span class="line">    w22 = f2()</span><br><span class="line"></span><br><span class="line">    print(w11.name, w12.name, w21.name, w22.name)</span><br><span class="line">    print('w21 和 w22是同一个变量吗?:{}'.format(w21 == w22))</span><br><span class="line"></span><br><span class="line">    # 二、执行会话</span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22]))</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">1、学习 变量命名域 tf.varible_scope()用法</span><br><span class="line">2、学习 命名域 tf.name_scope() 用法</span><br><span class="line">3、学习 tf.trainable_variables() 的使用</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">tf.variable_scope(self,</span><br><span class="line">               name_or_scope,       # string类型 该变量命名域名字。 </span><br><span class="line">               default_name=None,   # 默认名字。如果参数name_or_scope 为空，那么使用该参数定义的名字。反之，则启用name_or_scope定义的名字</span><br><span class="line">               values=None,         # 传入的值</span><br><span class="line">               initializer=None,    # 变量命名域的初始化器</span><br><span class="line">               regularizer=None,    # 变量命名域的正则化项</span><br><span class="line">               caching_device=None,</span><br><span class="line">               partitioner=None,</span><br><span class="line">               custom_getter=None,</span><br><span class="line">               reuse=None,          # 决定该变量命名域的变量是否重用。</span><br><span class="line">               dtype=None,</span><br><span class="line">               use_resource=None,</span><br><span class="line">               constraint=None,</span><br><span class="line">               auxiliary_name_scope=True):</span><br><span class="line">               </span><br><span class="line">tf.name_scope(</span><br><span class="line">    name,      # 命名域的名字</span><br><span class="line">    default_name=None,  # 命名域默认的名字</span><br><span class="line">    values=None):     # 传入的tensor值。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def h2():</span><br><span class="line">    with tf.name_scope('ai13'):</span><br><span class="line">        with tf.variable_scope('t1'):</span><br><span class="line">            # 再次创建2个变量</span><br><span class="line">            w11 = f1()</span><br><span class="line">            w12 = f1()</span><br><span class="line"></span><br><span class="line">    # 父域定义的参数 同样也会影响子域。</span><br><span class="line">    with tf.variable_scope('t10', initializer=tf.constant_initializer(28.0)):</span><br><span class="line">        with tf.name_scope('ai14'):  # fixme tf.name_scope对tf.get_variable生成的变量无效</span><br><span class="line">            with tf.variable_scope('t2', reuse=tf.AUTO_REUSE):</span><br><span class="line">                w21 = f2(initializer=None)</span><br><span class="line">                w22 = f2()</span><br><span class="line">    # 做一个加法操作</span><br><span class="line">    with tf.name_scope('ai15'):</span><br><span class="line">        with tf.variable_scope('t5'):</span><br><span class="line">            rezult = tf.add(w11+w12+w21, w22, name='add_rezult')</span><br><span class="line"></span><br><span class="line">    print(w11.name, w12.name)</span><br><span class="line">    print('**'*50)</span><br><span class="line">    print(w21.name, w22.name)</span><br><span class="line">    print('**'*50)</span><br><span class="line">    print(rezult.name)</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22, rezult]))</span><br><span class="line"></span><br><span class="line">        # 基于tensor的名字直接从图中获取对应的tensor的值。</span><br><span class="line">        temp = tf.get_default_graph().get_tensor_by_name('t10/t2/w:0')</span><br><span class="line">        print(sess.run(temp))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h3():</span><br><span class="line">    """</span><br><span class="line">    学习tf.trainable_variables()使用</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.name_scope('ai13'):</span><br><span class="line">        with tf.variable_scope('t1'):</span><br><span class="line">            # 再次创建2个变量</span><br><span class="line">            w11 = f1()</span><br><span class="line">            w12 = f1()</span><br><span class="line"></span><br><span class="line">    with tf.name_scope('ai14'):  # fixme tf.name_scope对tf.get_variable生成的变量无效</span><br><span class="line">        with tf.variable_scope('t2', reuse=tf.AUTO_REUSE):</span><br><span class="line">            w21 = f2(initializer=None)</span><br><span class="line">            w22 = f2()</span><br><span class="line">    # 做一个加法操作</span><br><span class="line">    with tf.name_scope('ai15'):</span><br><span class="line">        with tf.variable_scope('t5'):</span><br><span class="line">            rezult = tf.add(w11+w12+w21, w22, name='add_rezult')</span><br><span class="line"></span><br><span class="line">    # print(w11.name, w12.name)</span><br><span class="line">    # print('**'*50)</span><br><span class="line">    # print(w21.name, w22.name)</span><br><span class="line">    # print('**'*50)</span><br><span class="line">    # print(rezult.name)</span><br><span class="line">    # fixme 增加一段代码，展示如何获取指定的变量。</span><br><span class="line">    t_vars = tf.trainable_variables()</span><br><span class="line">    print(t_vars)</span><br><span class="line">    ai13_vars = [var for var in t_vars if var.name.startswith('ai13')]</span><br><span class="line">    print(ai13_vars)</span><br><span class="line"></span><br><span class="line">    with tf.Session() as sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        print(sess.run([w11, w12, w21, w22, rezult]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def h4():</span><br><span class="line">    """</span><br><span class="line">    展示tf.variable_scope() 中values参数的用法</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    default_graph = tf.Graph()</span><br><span class="line">    with default_graph.as_default():</span><br><span class="line">        w12 = f1()</span><br><span class="line"></span><br><span class="line">    graph1 = tf.Graph()</span><br><span class="line">    with graph1.as_default():</span><br><span class="line">        with tf.variable_scope('foo'):</span><br><span class="line">            w21 = f1()</span><br><span class="line"></span><br><span class="line">    graph2 = tf.Graph()</span><br><span class="line">    with graph2.as_default():</span><br><span class="line">        with tf.variable_scope('foo', values=[w12]):</span><br><span class="line">            w22 = f1()</span><br><span class="line"></span><br><span class="line">    print(w21.graph == default_graph)</span><br><span class="line">    print(w22.graph == default_graph)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    h4()</span><br></pre></td></tr></tbody></table></figure></div><p>模型持久化</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">模型持久化：就是将训练好的模型（权重 和 网络结构）保存到磁盘中。</span><br><span class="line">    1、可以用于部署。（服务器上训练---拷贝到 移动端进行预测）</span><br><span class="line">    2、进行断点继续训练。（大型模型训练 3--4天）</span><br><span class="line">    3、迁移学习。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line"># 变量的持久化</span><br><span class="line">def train():</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 构建2个变量</span><br><span class="line">        v1 = tf.get_variable(</span><br><span class="line">            name='v1', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.constant_initializer(value=5.0)</span><br><span class="line">        )</span><br><span class="line">        v2 = tf.get_variable(</span><br><span class="line">            name='v2', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.random_normal_initializer(mean=0.0, stddev=5.0)</span><br><span class="line">        )</span><br><span class="line">        rezult = v1 + v2</span><br><span class="line">        print(rezult)</span><br><span class="line"></span><br><span class="line">        # fixme 1、构建一个持久化的对象</span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">        # 创建持久化文件路径</span><br><span class="line">        checkpoint_dir = './model/ai13'</span><br><span class="line">        # 创建该路径(不存在该路径的情况下，执行)</span><br><span class="line">        if not os.path.exists(checkpoint_dir):</span><br><span class="line">            # 创建路径</span><br><span class="line">            os.makedirs(checkpoint_dir)</span><br><span class="line">            print('成功创建路径:{}'.format(checkpoint_dir))</span><br><span class="line"></span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line">            print(sess.run([v1, v2, rezult]))</span><br><span class="line">            # [5.0, -4.2127123, 0.7872877]</span><br><span class="line"></span><br><span class="line">            # fixme 触发持久化的操作</span><br><span class="line">            files_name = 'model.ckpt'</span><br><span class="line">            save_files = os.path.join(checkpoint_dir, files_name)</span><br><span class="line">            saver.save(sess=sess, save_path=save_files)  # 执行持久化的</span><br><span class="line">            print('成功将变量持久化到文件：{}'.format(save_files))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def restore_variables():</span><br><span class="line">    """</span><br><span class="line">    从磁盘中恢复变量</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    with tf.Graph().as_default():</span><br><span class="line">        # 构建2个变量</span><br><span class="line">        v1 = tf.get_variable(</span><br><span class="line">            name='v1', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.constant_initializer(value=5.0)</span><br><span class="line">        )</span><br><span class="line">        v2 = tf.get_variable(</span><br><span class="line">            name='v2', shape=[], dtype=tf.float32,</span><br><span class="line">            initializer=tf.random_normal_initializer(mean=0.0, stddev=5.0)</span><br><span class="line">        )</span><br><span class="line">        rezult = v1 + v2</span><br><span class="line">        print(rezult)</span><br><span class="line"></span><br><span class="line">        # fixme 1、构建一个持久化的对象</span><br><span class="line">        saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">        # 创建持久化文件路径</span><br><span class="line">        checkpoint_dir = './model/ai13'</span><br><span class="line"></span><br><span class="line">        with tf.Session() as sess:</span><br><span class="line">            # fixme 不需要变量初始化操作了</span><br><span class="line"></span><br><span class="line">            # 做一个恢复模型的操作。</span><br><span class="line">            files_name = 'model.ckpt'</span><br><span class="line">            save_files = os.path.join(checkpoint_dir, files_name)</span><br><span class="line"></span><br><span class="line">            # fixme 直接恢复变量。</span><br><span class="line">            saver.restore(sess=sess, save_path=save_files)</span><br><span class="line">            print(sess.run([v1, v2, rezult]))</span><br><span class="line">            # [5.0, -4.2127123, 0.7872877]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # train()</span><br><span class="line">    restore_variables()</span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>感知器模型</title>
      <link href="/2020/01/13/%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/01/13/%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="感知器模型"><a class="markdownIt-Anchor" href="#感知器模型"></a> 感知器模型</h1><p>感知器是一种模拟人的神经元的一种算法模型，是一种研究单个训练样本的二元分类器，是SVM和人工神经网络(ANN, Artificial Neural Networks)的基础。<br>一个感知器接受几个二进制的输入，并产生一个二进制的输出（阶跃函数），通常的表达方式如下：<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/1_ys.png" class="lazyload" title="1_ys"></a></p><p>感知器可以看作是根据权重来做出决定的一个设备/单元，只要我们可以给定一个比较适合的权重以及阈值，那么感知器应该是能够对数据进行判断的/分类预测的.</p><h2 id="感知器神经元逻辑与and"><a class="markdownIt-Anchor" href="#感知器神经元逻辑与and"></a> 感知器神经元–逻辑与(and)</h2><p>单个神经元完成逻辑与功能:<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2_ys.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2_ys.png" class="lazyload" title="2"></a></p><h2 id="感知器神经元直观理解之逻辑或or"><a class="markdownIt-Anchor" href="#感知器神经元直观理解之逻辑或or"></a> 感知器神经元直观理解之逻辑或or</h2><p>单个神经元完成逻辑或功能：<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/3_ys.png" class="lazyload" title="3_ys"></a></p><h2 id="感知器神经元直观理解之非线性可分"><a class="markdownIt-Anchor" href="#感知器神经元直观理解之非线性可分"></a> 感知器神经元直观理解之非线性可分</h2><p>通过将P1与P2结合完成非运算</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/4_ys.png" class="lazyload" title="4_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/5_ys.png" class="lazyload" title="5_ys"></a></p><h1 id="神经网络-基本架构"><a class="markdownIt-Anchor" href="#神经网络-基本架构"></a> 神经网络-基本架构</h1><p>针对感知器网络的这种很难学习的问题（非线性），引入S型神经元来代替感知器，从而解决这个问题。</p><p>从感知器模型中，我们可以将单个神经元的计算过程看成下列两个步骤：<br>先计算权重w和输入值x以及偏置项b之间的线性结果值z：z=wx+b<br>然后对结果值z进行一个数据的sign函数(变种)转换，得到一个离散的0/1值: y=int((sign(z)+1)/2)</p><p>在S型神经元中，和感知器神经元的区别在于：<br>对于结果值z的转换，采用的不是sign函数进行转换，是采用平滑类型的函数进行转换，让输出的结果值y最终  是一个连续的，S型神经元转指使用的是sigmoid函数。</p><h2 id="神经网络来源之神经元"><a class="markdownIt-Anchor" href="#神经网络来源之神经元"></a> 神经网络来源之“神经元”</h2><p>输入：x1、x2、x3和截距+1；输出：函数hw,b(x)，其中w权重和b偏置项是参数<a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/6_ys.png" class="lazyload" title="6_ys"></a></p><p>函数f被称为“激活函数”；常用/最好出现激活函数有sigmoid(逻辑回归函数)和tanh(双曲正切函数)</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/7_ys.png" class="lazyload" title="7_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/8.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/8.png" class="lazyload" title="7_ys"></a></p><h2 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h2><p>激活函数的主要作用是提供网络的非线性建模能力。如果没有激活函数，那么该网络仅能够表达线性映射，此时即便有再多的隐藏层，其整个网络跟单层神经网络也是等价的。因此也可以认为，只有加入了激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。 激活函数的主要特性是：可微性、单调性、输出值的范围；</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16_ys.png" data-fancybox="group" data-caption="16_ys" class="fancybox"><img alt="16_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/16_ys.png" class="lazyload" title="16_ys"></a></p><p>常见的激活函数：Sign函数、Sigmoid函数、Tanh函数、ReLU函数、Leaky-ReLU函数、ELU函数等</p><h1 id="神经网络"><a class="markdownIt-Anchor" href="#神经网络"></a> 神经网络</h1><p>神经网络主要由三个组成部分，第一个是架构（architecture）或称为拓扑结构（topology），描述神经元的层次与连接神经元的结构。第二个组成部分是神经网络使用的激励/激活函数。第三个组成部分是找出最优权重值的学习算法（SGD,BGD,MBGD）。</p><p>神经网络主要分为两种类型：前馈神经网络(Feedforward Neural Networks)是最常用的神经网络类型（如FC  CNN），一般定义为有向无环图，信号只能沿着最终输出的那个方向传播。另外一个是反馈神经网络(Feedback Neural Networks)，也称为递归神经网络(Recurent Neural Networks)，也就是网络中环。</p><h2 id="神经网络之浅层神经网络"><a class="markdownIt-Anchor" href="#神经网络之浅层神经网络"></a> 神经网络之浅层神经网络</h2><p>添加少量隐层的神经网络就叫做浅层神经网络；也叫作传统神经网络，一般为2隐层的神经网络(超过两隐层的话，效果会差很多).</p><p>深层网络面临问题：硬件，梯度消散（链式求导导致）</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/10_ys.png" class="lazyload" title="7_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/9.png" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/9.png" class="lazyload" title="9"></a></p><p>链式求导：(反向)$ \frac{\partial Loss}{\partial w^0}=\frac{\partial Loss}{\partial \tilde{y}}*w^3 \frac{\partial \tilde{y}}{\partial h_3}*w^2\frac{\partial h_3}{\partial h^2}…$</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11_ys.png" data-fancybox="group" data-caption="11_ys" class="fancybox"><img alt="11_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/11_ys.png" class="lazyload" title="11_ys"></a></p><h2 id="神经网络之非线性可分"><a class="markdownIt-Anchor" href="#神经网络之非线性可分"></a> 神经网络之非线性可分</h2><p>对线性分类器的与和或的组合可以完成非线性可分的问题；即通过多层的神经网络中加入激活函数的方式可以解决非线性可分的问题。</p><h2 id="神经网络之过拟合"><a class="markdownIt-Anchor" href="#神经网络之过拟合"></a> 神经网络之过拟合</h2><ol><li><p>理论上来讲，单隐层的神经网络可以逼近任何连续函数（只要隐层的神经元个数足够的多<一个神经元将数据集分为两类>）</p></li><li><p>虽然从数学表达上来讲，效果一样，但是在网络工程效果中，多隐层的神经网络效果要比单隐层的神经网络效果好</p></li><li><p>对于一些分类的问题来讲，三层的神经网络效果优于两层的神经网络，但是如果把层次不断增加(4,5,6,7…)，对于最终的效果不会产生太大的变化<br>提升隐层层数或者神经元个数，神经网络的“容量”会变大，那么空间表达能力会变强（模型的拟合能力变强），从而有可能导致过拟合的问题（解决：1.droppwt2.正则化3.减小模型复杂度）</p></li><li><p>对于视频/图片识别/文本/语音 等问题，传统的神经网络(全连接神经网络)不太适合</p></li></ol><h1 id="反向传播神经网络-bpnn"><a class="markdownIt-Anchor" href="#反向传播神经网络-bpnn"></a> 反向传播神经网络-BPNN</h1><pre><code>BP（梯度下降）</code></pre><p>梯度下降的数学推导</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13_ys.png" data-fancybox="group" data-caption="13_ys" class="fancybox"><img alt="13_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/13_ys.png" class="lazyload" title="13_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14_ys.png" data-fancybox="group" data-caption="14_ys" class="fancybox"><img alt="14_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/14_ys.png" class="lazyload" title="14_ys"></a></p><h2 id="反向传播-练习"><a class="markdownIt-Anchor" href="#反向传播-练习"></a> 反向传播-练习</h2><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12_ys.png" data-fancybox="group" data-caption="12_ys" class="fancybox"><img alt="12_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/12_ys.png" class="lazyload" title="12_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15_ys.jpg" data-fancybox="group" data-caption="15_ys" class="fancybox"><img alt="15_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/15_ys.jpg" class="lazyload" title="15_ys"></a></p><p>![17 (4)_ys](/img/深度学习/17 (4)_ys.png)</p><p>![17 (1)_ys](/img/深度学习/17 (1)_ys.png)</p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/20_ys.png" data-fancybox="group" data-caption="20_ys" class="fancybox"><img alt="20_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/20_ys.png" class="lazyload" title="20_ys"></a></p><p><a href="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/19_ys.png" data-fancybox="group" data-caption="19_ys" class="fancybox"><img alt="19_ys" data-src="/img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/19_ys.png" class="lazyload" title="19_ys"></a></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">SGD：实际应用中用全部样本随机打乱取均值，如果每次在样本中随机去选择 成本很高。</span><br><span class="line">实际工作中大部分用到的是小批量梯度算法</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">案例：研究生学院录取数据，用梯度下降训练一个网络。</span></span><br><span class="line"><span class="string">数据有三个输入特征：GRE 分数、GPA 分数和本科院校排名（从 1 到 4）。排名 1 代表最好，排名 4 代表最差。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">pd.set_option(<span class="string">'display.max_columns'</span>, <span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">'display.width'</span>, <span class="number">1000</span>)</span><br><span class="line">pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">admissions = pd.read_csv(<span class="string">'../datas/11.csv'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_explore</span><span class="params">(admissions)</span>:</span></span><br><span class="line">    print(admissions.head(n=<span class="number">10</span>))</span><br><span class="line">    print(admissions.info())         <span class="comment"># 查看是否有空值，以及数据类型</span></span><br><span class="line">    print(admissions.describe())     <span class="comment"># 再次可以看到是否有空值，以及值范围，需要考虑做数据变换。</span></span><br><span class="line">    print(<span class="string">'各个样本相应的数量为:{}'</span>.format(admissions[<span class="string">'admit'</span>].value_counts()))   <span class="comment"># 查看样本是否均衡</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">一、数据清理</span></span><br><span class="line"><span class="string">    1、分类变量哑编码</span></span><br><span class="line"><span class="string">    rank 是类别特征，其中的数字并不表示任何相对的值。排名第 2 并不是排名第 1 的两倍；</span></span><br><span class="line"><span class="string">    排名第 3 也不是排名第 2 的 1.5 倍。因此，我们需要用哑变量 来对 rank 进行编码。</span></span><br><span class="line"><span class="string">    把数据分成 4 个新列，用 0 或 1 表示。排名为 1 的行对应 rank_1 列的值为 1 ，其余三列的值为 0；</span></span><br><span class="line"><span class="string">    排名为 2 的行对应 rank_2 列的值为 1 ，其余三列的值为 0，以此类推。</span></span><br><span class="line"><span class="string">    2、连续变量标准化</span></span><br><span class="line"><span class="string">    把 GRE 和 GPA 数据标准化，变成均值为 0，标准偏差为 1。因为 sigmoid 函数会挤压很大或者很小的输入。</span></span><br><span class="line"><span class="string">    很大或者很小输入的梯度为 0，这意味着梯度下降的步长也会是 0。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_transform</span><span class="params">(admissions)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    一  rank代表学校等级（1--4），转成哑变量</span></span><br><span class="line"><span class="string">    1、 用pd.get_dummies 将rank列，转成哑变量，新变量名前缀为：prefix='rank'</span></span><br><span class="line"><span class="string">    2、将原数据集admissions 和 1 进行列拼接；</span></span><br><span class="line"><span class="string">    3、drop原始的rank列。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = pd.concat([admissions, pd.get_dummies(admissions[<span class="string">'rank'</span>], prefix=<span class="string">'rank'</span>)], axis=<span class="number">1</span>)</span><br><span class="line">    data = data.drop(<span class="string">'rank'</span>, axis=<span class="number">1</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    二、gre和gpa连续变量的标准化</span></span><br><span class="line"><span class="string">    标准做法：先拆分数据集--使用训练数据集的统计量 去标准化 验证和测试。   </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> field <span class="keyword">in</span> [<span class="string">'gre'</span>, <span class="string">'gpa'</span>]:</span><br><span class="line">        mean, std = data[field].mean(), data[field].std()</span><br><span class="line">        data.loc[:, field] = (data[field] - mean) / std <span class="comment">#取field所有行</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    三、数据拆分：分成训练 和 测试数据集</span></span><br><span class="line"><span class="string">    1、设置随机数种子，确保大家执行和我们这里演示的结果一致；</span></span><br><span class="line"><span class="string">    2、使用np.random.choice，随机选择数据集中90% 数据的index</span></span><br><span class="line"><span class="string">    3.iloc，完全基于位置的索引</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 随机打乱，并将数据集拆分为  90%训练---10%测试数据集。</span></span><br><span class="line">    np.random.seed(<span class="number">42</span>)</span><br><span class="line">    sample = np.random.choice(data.index, size=int(len(data) * <span class="number">0.9</span>), replace=<span class="literal">False</span>)</span><br><span class="line">    train_data, test_data = data.iloc[sample], data.drop(sample)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    四、 将自变量（features）和目标值分离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    features_train, targets_train = train_data.drop(<span class="string">'admit'</span>, axis=<span class="number">1</span>), train_data[<span class="string">'admit'</span>]</span><br><span class="line">    features_test, targets_test = test_data.drop(<span class="string">'admit'</span>, axis=<span class="number">1</span>), test_data[<span class="string">'admit'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> features_train.values, targets_train.values, features_test.values, targets_test.values</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    sigmoid激活函数</span></span><br><span class="line"><span class="string">    :param x:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gre_bp_answer</span><span class="params">(feature_train, target_train, feature_test, target_test)</span>:</span></span><br><span class="line">    <span class="comment"># 1、超参数</span></span><br><span class="line">    n_hidden = <span class="number">2</span> <span class="comment">#隐藏层节点个数</span></span><br><span class="line">    epochs = <span class="number">2000</span>  <span class="comment">#梯度下降迭代次数</span></span><br><span class="line">    learning_rate = <span class="number">0.06</span>  <span class="comment">#学习率</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取样本数量和 特征数量</span></span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、初始化模型权重</span></span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=<span class="number">0.0</span>, scale=<span class="number">0.1</span>, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># weights_hidden_2_output = np.random.normal(</span></span><br><span class="line">    <span class="comment">#     scale=0.1, size=n_hidden</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=<span class="number">0.1</span>, size=[n_hidden, <span class="number">1</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建梯度下降迭代次数的循环</span></span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="comment"># 构建存储梯度值的delta_w</span></span><br><span class="line">        del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(feature_train, target_train):</span><br><span class="line">            <span class="comment"># 1、正向传播；</span></span><br><span class="line">            hidden_input = np.matmul(x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            <span class="comment"># hidden_output shape = (2,)</span></span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) <span class="comment"># shape = ()  是一个标量</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2、求误差</span></span><br><span class="line">            error = y_hat - y</span><br><span class="line">            <span class="comment"># 3、反向传播</span></span><br><span class="line">            <span class="comment"># 求输出层误差项</span></span><br><span class="line">            output_error_term = error * y_hat * (<span class="number">1</span>-y_hat)  <span class="comment"># 标量</span></span><br><span class="line">            <span class="comment"># 隐藏层误差</span></span><br><span class="line">            hidden_error = output_error_term * weights_hidden_2_output  <span class="comment"># (n_hidden,)</span></span><br><span class="line">            <span class="comment"># 隐藏层误差项</span></span><br><span class="line">            <span class="comment"># print(hidden_error.shape, hidden_output.shape)</span></span><br><span class="line">            hidden_error_term = hidden_error.reshape(<span class="number">-1</span>) * hidden_output *(<span class="number">1</span>-hidden_output) <span class="comment">#reshape 将其拉成一个向量与后面维度保持一致</span></span><br><span class="line">            <span class="comment"># (n_hidden,)</span></span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden += x[:, <span class="literal">None</span>] * hidden_error_term <span class="comment">#累加求和</span></span><br><span class="line">            del_weights_hidden_2_output += hidden_output[:, <span class="literal">None</span>] * output_error_term</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新模型权重</span></span><br><span class="line">        weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">        weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印模型损失</span></span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> last_loss <span class="keyword">and</span> last_loss < loss:</span><br><span class="line">                print(<span class="string">'警告：模型损失在上升, Train Loss:{}'</span>.format(loss))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'Epochs:{} - Train Loss:{}'</span>.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">  <span class="comment">#训练结束，使用测试数据集验证模型准确率</span></span><br><span class="line">        hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">        test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">        predictions = test_pred > <span class="number">0.5</span></span><br><span class="line">        accuracy = np.mean(predictions == target_test)</span><br><span class="line">        print(<span class="string">"Test Accuray:{:,.5f}"</span>.format(accuracy))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># data_explore(admissions)</span></span><br><span class="line">    features_train, targets_train, features_test, targets_test = data_transform(admissions)</span><br><span class="line">    <span class="comment"># print(features_train)</span></span><br><span class="line">    gre_bp_answer(features_train, targets_train, features_test, targets_test)</span><br></pre></td></tr></tbody></table></figure></div><h2 id="gre案例的伪代码bgd"><a class="markdownIt-Anchor" href="#gre案例的伪代码bgd"></a> GRE案例的伪代码（BGD）</h2><p>传入（train_features, train_target）<br>n_records, n_features = train_features.shape<br>hidden_nodes = 3（隐藏层节点数）<br>learning_rate = 0.01<br>初始化权重。 Winput2h , Wh2output （随机初始化）<br>Last_loss = None<br>epochs = 200（迭代次数）<br>for e in range(epochs):（所有样本训练一次=一个epochc）<br>delta_Winput2h,  delta_Wh2output = np.zeros(),   np.zeros()<br>for  X,y  in zip(train_features,  train_target):<br>#1、正向传播；<br>#2、获得损失(error)   用的MSE作为损失函数<br>#3、执行反向传播<br>#4、delta_Winput2h,  delta_Wh2output 进行累加<br>执行Winput2h , Wh2output 梯度下降。<br>if  e % 10==0:<br>执行正向传播，求出当前的损失，并且打印。<br>用测试数据集，做正向传播，并且求准确率。</p><p>注:zip函数用法</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = [1,2,3]</span><br><span class="line"></span><br><span class="line">b = [4,5,6] </span><br><span class="line"></span><br><span class="line">c = [4,5,6,7,8] </span><br><span class="line"></span><br><span class="line">zipped = zip(a,b)     # 打包为元组的列表 </span><br><span class="line"> [(1, 4), (2, 5), (3, 6)] </span><br><span class="line"> >>> zip(a,c)              # 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] </span><br><span class="line"> zip(*zipped)          </span><br><span class="line"> # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式 [(1, 2, 3), (4, 5, 6)]</span><br></pre></td></tr></tbody></table></figure></div><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">小批量梯度下降MBGD 一般选用2的n次方大小</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">案例：研究生学院录取数据，用梯度下降训练一个网络。</span><br><span class="line">数据有三个输入特征：GRE 分数、GPA 分数和本科院校排名（从 1 到 4）。排名 1 代表最好，排名 4 代表最差。</span><br><span class="line">"""</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">pd.set_option('display.max_columns', 1000)</span><br><span class="line">pd.set_option('display.width', 1000)</span><br><span class="line">pd.set_option('display.max_colwidth', 1000)</span><br><span class="line"></span><br><span class="line">admissions = pd.read_csv('../datas/11.csv')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def data_explore(admissions):</span><br><span class="line">    print(admissions.head(n=10))</span><br><span class="line">    print(admissions.info())         # 查看是否有空值，以及数据类型</span><br><span class="line">    print(admissions.describe())     # 再次可以看到是否有空值，以及值范围，需要考虑做数据变换。</span><br><span class="line">    print('各个样本相应的数量为:{}'.format(admissions['admit'].value_counts()))   # 查看样本是否均衡</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">一、数据清理</span><br><span class="line">    1、分类变量哑编码</span><br><span class="line">    rank 是类别特征，其中的数字并不表示任何相对的值。排名第 2 并不是排名第 1 的两倍；</span><br><span class="line">    排名第 3 也不是排名第 2 的 1.5 倍。因此，我们需要用哑变量 来对 rank 进行编码。</span><br><span class="line">    把数据分成 4 个新列，用 0 或 1 表示。排名为 1 的行对应 rank_1 列的值为 1 ，其余三列的值为 0；</span><br><span class="line">    排名为 2 的行对应 rank_2 列的值为 1 ，其余三列的值为 0，以此类推。</span><br><span class="line">    2、连续变量标准化</span><br><span class="line">    把 GRE 和 GPA 数据标准化，变成均值为 0，标准偏差为 1。因为 sigmoid 函数会挤压很大或者很小的输入。</span><br><span class="line">    很大或者很小输入的梯度为 0，这意味着梯度下降的步长也会是 0。</span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line">def data_transform(admissions):</span><br><span class="line">    """</span><br><span class="line">    一  rank代表学校等级（1--4），转成哑变量</span><br><span class="line">    1、 用pd.get_dummies 将rank列，转成哑变量，新变量名前缀为：prefix='rank'</span><br><span class="line">    2、将原数据集admissions 和 1 进行列拼接；</span><br><span class="line">    3、drop原始的rank列。</span><br><span class="line">    """</span><br><span class="line">    data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)</span><br><span class="line">    data = data.drop('rank', axis=1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    二、gre和gpa连续变量的标准化</span><br><span class="line">    标准做法：先拆分数据集--使用训练数据集的统计量 去标准化 验证和测试。</span><br><span class="line">    """</span><br><span class="line"></span><br><span class="line">    for field in ['gre', 'gpa']:</span><br><span class="line">        mean, std = data[field].mean(), data[field].std()</span><br><span class="line">        data.loc[:, field] = (data[field] - mean) / std</span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    三、数据拆分：分成训练 和 测试数据集</span><br><span class="line">    1、设置随机数种子，确保大家执行和我们这里演示的结果一致；</span><br><span class="line">    2、使用np.random.choice，随机选择数据集中90% 数据的index</span><br><span class="line">    """</span><br><span class="line">    # 随机打乱，并将数据集拆分为  90%训练---10%测试数据集。</span><br><span class="line">    np.random.seed(42)</span><br><span class="line">    sample = np.random.choice(data.index, size=int(len(data) * 0.9), replace=False)</span><br><span class="line">    train_data, test_data = data.iloc[sample], data.drop(sample)</span><br><span class="line"></span><br><span class="line">    """</span><br><span class="line">    四、 将自变量（features）和目标值分离</span><br><span class="line">    """</span><br><span class="line">    features_train, targets_train = train_data.drop('admit', axis=1), train_data['admit']</span><br><span class="line">    features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']</span><br><span class="line"></span><br><span class="line">    return features_train.values, targets_train.values, features_test.values, targets_test.values</span><br><span class="line"></span><br><span class="line">def sigmoid(x):</span><br><span class="line">    """</span><br><span class="line">    sigmoid激活函数</span><br><span class="line">    :param x:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    return 1/(1+np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gre_bp_answer(feature_train, target_train, feature_test, target_test):</span><br><span class="line">    # 1、超参数</span><br><span class="line">    n_hidden = 2</span><br><span class="line">    epochs = 2000</span><br><span class="line">    learning_rate = 0.06</span><br><span class="line"></span><br><span class="line">    # 获取样本数量和 特征数量</span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = None</span><br><span class="line"></span><br><span class="line">    # 2、初始化模型权重</span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=0.0, scale=0.1, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line">    # weights_hidden_2_output = np.random.normal(</span><br><span class="line">    #     scale=0.1, size=n_hidden</span><br><span class="line">    # )</span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=0.1, size=[n_hidden, 1]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 构建迭代次数的循环</span><br><span class="line">    for e in range(epochs):</span><br><span class="line">        # 构建存储梯度值的delta_w</span><br><span class="line">        del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        for x, y in zip(feature_train, target_train):</span><br><span class="line">            # 1、正向传播；</span><br><span class="line">            hidden_input = np.matmul(x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            # hidden_output shape = (2,)</span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) # shape = ()  是一个标量</span><br><span class="line"></span><br><span class="line">            # 2、求误差</span><br><span class="line">            error = y_hat - y</span><br><span class="line">            # 3、反向传播</span><br><span class="line">            # 求输出层误差项</span><br><span class="line">            output_error_term = error * y_hat * (1-y_hat)  # 标量</span><br><span class="line">            # 隐藏层误差</span><br><span class="line">            hidden_error = output_error_term * weights_hidden_2_output  # (n_hidden,)</span><br><span class="line">            # 隐藏层误差项</span><br><span class="line">            # print(hidden_error.shape, hidden_output.shape)</span><br><span class="line">            hidden_error_term = hidden_error.reshape(-1) * hidden_output *(1-hidden_output)</span><br><span class="line">            # (n_hidden,)</span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden += x[:, None] * hidden_error_term</span><br><span class="line">            del_weights_hidden_2_output += hidden_output[:, None] * output_error_term</span><br><span class="line"></span><br><span class="line">        # 更新模型权重</span><br><span class="line">        weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">        weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        # 打印模型损失</span><br><span class="line">        if e % 100 == 0:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**2)</span><br><span class="line"></span><br><span class="line">            if last_loss and last_loss < loss:</span><br><span class="line">                print('警告：模型损失在上升, Train Loss:{}'.format(loss))</span><br><span class="line">            else:</span><br><span class="line">                print('Epochs:{} - Train Loss:{}'.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">    #训练结束，使用测试数据集验证模型准确率</span><br><span class="line">    hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">    test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">    predictions = test_pred > 0.5</span><br><span class="line">    accuracy = np.mean(predictions == target_test)</span><br><span class="line">    print("Test Accuray:{:,.5f}".format(accuracy))</span><br><span class="line">def get_batches(feature_train, target_train, batch_size = 32):</span><br><span class="line">    """</span><br><span class="line">    构建批量数据的生成器</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param batch_size:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    for ii in range(0,len(feature_train), batch_size):</span><br><span class="line">        batch_x = feature_train[ii:ii+batch_size]</span><br><span class="line">        batch_y = target_train[ii:ii+batch_size]</span><br><span class="line">        yield batch_x,batch_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gre_bp_MBGD(feature_train, target_train, feature_test, target_test,batch_size = 128):</span><br><span class="line">    """</span><br><span class="line">    使用小批量梯度下降实现GRE</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param feature_test:</span><br><span class="line">    :param target_test:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    # 1、超参数</span><br><span class="line">    n_hidden = 4</span><br><span class="line">    epochs = 2000</span><br><span class="line">    learning_rate = 0.06</span><br><span class="line"></span><br><span class="line">    # 获取样本数量和 特征数量</span><br><span class="line">    n_records, n_features = features_train.shape</span><br><span class="line">    last_loss = None</span><br><span class="line"></span><br><span class="line">    # 2、初始化模型权重</span><br><span class="line">    weights_input_2_hidden = np.random.normal(</span><br><span class="line">        loc=0.0, scale=0.1, size=[n_features, n_hidden]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    weights_hidden_2_output = np.random.normal(</span><br><span class="line">        scale=0.1, size=[n_hidden, 1]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 构建迭代次数的循环</span><br><span class="line"></span><br><span class="line">    for e in range(epochs):</span><br><span class="line">        # 构建存储梯度值的delta_w</span><br><span class="line">        # del_weights_input_2_hidden = np.zeros(weights_input_2_hidden.shape)</span><br><span class="line">        # del_weights_hidden_2_output = np.zeros(weights_hidden_2_output.shape)</span><br><span class="line">        for batch_x, batch_y in get_batches(feature_train, target_train, batch_size):</span><br><span class="line">            # 1、正向传播；</span><br><span class="line">            hidden_input = np.matmul(batch_x, weights_input_2_hidden)</span><br><span class="line">            hidden_output = sigmoid(hidden_input)</span><br><span class="line">            # hidden_output shape = (2,)</span><br><span class="line"></span><br><span class="line">            final_input = np.matmul(hidden_output, weights_hidden_2_output)</span><br><span class="line">            y_hat = sigmoid(final_input) # shape = ()  是一个标量</span><br><span class="line"></span><br><span class="line">            # 2、求误差</span><br><span class="line">            error = y_hat - batch_y[:,None]       #[N,1]</span><br><span class="line">            # 3、反向传播</span><br><span class="line">            # 求输出层误差项 [N,1]</span><br><span class="line">            output_error_term = error * y_hat * (1-y_hat)  # 标量</span><br><span class="line">            # 隐藏层误差[N,4]</span><br><span class="line">            hidden_error = np.matmul(output_error_term , weights_hidden_2_output.transpose())   # (n_hidden,)</span><br><span class="line">            # 隐藏层误差项</span><br><span class="line">            # print(hidden_error.shape, hidden_output.shape)</span><br><span class="line">            hidden_error_term = hidden_error * hidden_output *(1-hidden_output)</span><br><span class="line">            # (n_hidden,)</span><br><span class="line"></span><br><span class="line">            del_weights_input_2_hidden =np.matmul(np.transpose(batch_x),hidden_error_term)/batch_size</span><br><span class="line"></span><br><span class="line">            del_weights_hidden_2_output = np.matmul(np.transpose(hidden_output),output_error_term)/batch_size</span><br><span class="line"></span><br><span class="line">            # 更新模型权重</span><br><span class="line">            weights_input_2_hidden -= del_weights_input_2_hidden * learning_rate / n_records</span><br><span class="line">            weights_hidden_2_output -= del_weights_hidden_2_output * learning_rate / n_records</span><br><span class="line"></span><br><span class="line">        # 打印模型损失</span><br><span class="line">        if e % 100 == 0:</span><br><span class="line">            hidden_output = sigmoid(np.dot(features_train, weights_input_2_hidden))</span><br><span class="line">            pred_out = sigmoid(np.dot(hidden_output, weights_hidden_2_output))</span><br><span class="line">            loss = np.mean((pred_out - target_train)**2)</span><br><span class="line"></span><br><span class="line">            if last_loss and last_loss < loss:</span><br><span class="line">                print('警告：模型损失在上升, Train Loss:{}'.format(loss))</span><br><span class="line">            else:</span><br><span class="line">                print('Epochs:{} - Train Loss:{}'.format(e, loss))</span><br><span class="line">            last_loss = loss</span><br><span class="line">    #训练结束，使用测试数据集验证模型准确率</span><br><span class="line">    hidden = sigmoid(np.dot(feature_test,weights_input_2_hidden))</span><br><span class="line">    test_pred = sigmoid(np.dot(hidden,weights_hidden_2_output))</span><br><span class="line">    predictions = test_pred > 0.5</span><br><span class="line">    accuracy = np.mean(predictions == target_test)</span><br><span class="line">    print("Test Accuray:{:,.5f}".format(accuracy))</span><br><span class="line">def get_batches(feature_train, target_train, batch_size = 32):</span><br><span class="line">    """</span><br><span class="line">    构建批量数据的生成器</span><br><span class="line">    :param feature_train:</span><br><span class="line">    :param target_train:</span><br><span class="line">    :param batch_size:</span><br><span class="line">    :return:</span><br><span class="line">    """</span><br><span class="line">    for ii in range(0,len(feature_train), batch_size):</span><br><span class="line">        batch_x = feature_train[ii:ii+batch_size]</span><br><span class="line">        batch_y = target_train[ii:ii+batch_size]</span><br><span class="line">        yield batch_x,batch_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    # data_explore(admissions)</span><br><span class="line">    features_train, targets_train, features_test, targets_test = data_transform(admissions)</span><br><span class="line">    #print(features_train[:,None])</span><br><span class="line">    gre_bp_answer(features_train, targets_train, features_test, targets_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    gre_bp_MBGD(features_train, targets_train, features_test, targets_test, batch_si</span><br></pre></td></tr></tbody></table></figure></div><p>SGD:随机梯度下降：每次随机选择一样本，计算梯度值，并且更新模型权重。（基本不用）</p><p>BGD：计算所有样本的梯度平均值。然后技更新模型权重。</p><p>MBGD:小批量梯度下降。每次随机选择batch_size样本，计算梯度的平均值，再更新模型权重。（主要）</p><h1 id><a class="markdownIt-Anchor" href="#"></a> </h1></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>过拟合与正则化</title>
      <link href="/2020/01/13/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/"/>
      <url>/2020/01/13/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="过拟合"><a class="markdownIt-Anchor" href="#过拟合"></a> 过拟合</h1><p>图1，2：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/1_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/2_ys.png" class="lazyload"></a></p><p>1-3与2-3过拟合，代价函数等于0或者无限接近于0，但无法应用于新样本中.</p><p>图3：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/3_ys.png" class="lazyload"></a></p><p>当有很多特征变量时，已经不是多项式阶次的选择问题。当我们预测房价时，有许多特征变量与房价可能有关，但是当特征变量过多，训练样本过少时，则容易出现过拟合问题。</p><p>为了解决过拟合问题，有两个方法：</p><p>1.尽量减少选取变量的数量，如人工检查变量清单，并以此决定哪些变量更为重要，哪些特征变量应该保留，哪些应该舍弃。</p><p>这种方法可以有效防止过拟合的发生，缺点;舍弃一部分特征变量也舍弃了关于问题的一些信息。</p><p>2.正则化：保留所有特征变量但是减小量级<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\theta_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的大小，</p><h1 id="正则化"><a class="markdownIt-Anchor" href="#正则化"></a> 正则化</h1><p>图4：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/4_ys.png" class="lazyload"></a></p><p>当我们想让这个新函数尽可能小的时候，要使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>尽可能小，因为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>系数为1000，使整个函数变得非常大，当我们最小化新函数时，我们要使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub><mi mathvariant="normal">尽</mi><mi mathvariant="normal">可</mi><mi mathvariant="normal">能</mi><mi mathvariant="normal">者</mi><mi mathvariant="normal">接</mi><mi mathvariant="normal">近</mi><mn>0</mn></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4尽可能者接近0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">尽</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">者</span><span class="mord cjk_fallback">接</span><span class="mord cjk_fallback">近</span><span class="mord">0</span></span></span></span>，即消去<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>3</mn></msub><mi mathvariant="normal">与</mi><msub><mi>θ</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\theta_3与\theta_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">与</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，那么这个函数相当于二次函数加上了一些非常小的项。</p><p>这就是加入惩罚增大两个参数的结果，即正则化的思想：如果将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>4</mn></msub><msub><mi>θ</mi><mn>5</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\theta_1,\theta_2,\theta_3,\theta_4\theta_5...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span></span></span></span>都加上惩罚项，这么做就相当于去简化这个假设模型，参数越接近于0.结果表明，这些参数的数值越小，我们得到的函数就越平滑也越简单，越不容易出现过拟合问题，</p><p>图5：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/5_ys.png" class="lazyload"></a></p><p>在正则化中，修改代价函数（添加正则化项）来缩小所有参数（因为不知该选那些参数去缩小），此处求和从参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>开始没有给参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>添加惩罚项（约定俗成），对结果影响不大。</p><p>图6：<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/6_ys.png" class="lazyload"></a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>作用，控制两个不同目标之间的取舍，第一个目标与函数第一项有关（更好的拟合训练集），第二个目标，保持参数尽量地小（与正则化目标有关）。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>即正则化参数作用是控制这辆两个目标之间的关系。即更好的拟合训练集和将参数控制的更小，保持假设模型简单避免出现过拟合。</p><p>图7:<a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" title="7_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%BF%87%E6%8B%9F%E5%90%88/7_ys.png" class="lazyload"></a></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span>过大会导致参数都接近于0，相当于只保留了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，用一条直线去拟合数据，导致欠拟合。</p><h1 id="l1与l2正则"><a class="markdownIt-Anchor" href="#l1与l2正则"></a> L1与L2正则</h1></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学公式：</title>
      <link href="/2020/01/10/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%9A/"/>
      <url>/2020/01/10/%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%EF%BC%9A/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="数学公式"><a class="markdownIt-Anchor" href="#数学公式"></a> 数学公式：</h1><h3 id="jensen不等式"><a class="markdownIt-Anchor" href="#jensen不等式"></a> Jensen不等式</h3><p>如果函数f为凸函数，那么存在下列公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>≤</mo><mi>θ</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta x_1 +(1-\theta x_2))\leq  \theta f(x_1)+(1-\theta)f(x_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>若<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>θ</mi><mi>n</mi></msub><mo>≥</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\theta_1,\theta_2,...\theta_n\geq0,\theta_1+\theta_2+...+\theta_n=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，则<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>θ</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>≤</mo><msub><mi>θ</mi><mn>1</mn></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>θ</mi><mn>2</mn></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>θ</mi><mi>n</mi></msub><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta_1x_1+\theta_2x_2+...+\theta_nx_n)\leq\theta_1f(x_1)+\theta_2f(x_2)+...+\theta_nf(x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>,则f((E(x))≤E(f(x))</p><p>特别地，如果函数 f(x)是严格凸函数，当且仅当p(x=E(x))=1,即随机变量是常量时等号成立。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>θ</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\theta x_1 +(1-\theta x_1))=\theta f(x_1)+(1-\theta)f(x_1)=f(x_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><h1 id="em算法"><a class="markdownIt-Anchor" href="#em算法"></a> EM算法</h1><p>EM算法(Expectation Maximization Algorithm, 最大期望算法)是一种迭代类型的算法，是一种在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量。</p><p>EM算法(Expectation Maximization Algorithm, 最大期望算法)是一种迭代类型的算法，是一种在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量。</p><h2 id="em算法流程"><a class="markdownIt-Anchor" href="#em算法流程"></a> EM算法流程：</h2><p>1.初始化分布参数/模型参数</p><p>2.重复下列两个操作直到收敛：</p><p>E步骤：估计隐藏变量的概率分布期望函数；<br>M步骤：根据期望函数重新估计分布参数。</p><h2 id="em算法原理"><a class="markdownIt-Anchor" href="#em算法原理"></a> EM算法原理</h2><p>给定的m个训练样本{x(1),x(2),…,x(m)}，样本间独立，找出样本的模型参数θ，极大化模型分布的对数似然函数如下：</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mtext> </mtext><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>i</mi></msup><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">{\underset {\theta}{\operatorname {arg\,max} }}\,\sum_{i=1}^{m}{log(P(x^{i};\theta))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.7712119999999998em;vertical-align:-0.946548em;"></span><span class="mord"><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.153452em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.946548em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>假定样本数据中存在隐含数据z={z(1),z(2),…,z(k)}，此时极大化模型分布的对数似然函数如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>i</mi></msup><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msup><mi>z</mi><mo stretchy="false">(</mo></msup><mi>i</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mi>P</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mi mathvariant="normal">∣</mi><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mo separator="true">;</mo><mi>θ</mi></mrow><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><munder><mo>∑</mo><mrow><msup><mi>z</mi><mo stretchy="false">(</mo></msup><mi>i</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mi>P</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>z</mi><mi>i</mi></msup><mo stretchy="false">)</mo><mo separator="true">;</mo><mi>θ</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=arg\max_{\theta}L({\theta})=arg\max_{\theta}\sum_{i=1}^{m}{log(P(x^{i};\theta))}\\　　　　　　　　　=arg\max_{\theta}\sum_{i=1}^{m}{log(\sum_{z^(i)}{P(z^{i})P(x^{(i)}|z^{i});\theta})}\\　　　　　　=arg\max_{\theta}\sum_{i=1}^{m}{log(\sum_{z^(i)}{P(x^{(i)},z^{i});\theta})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.217827em;vertical-align:-1.56643em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.75857em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8220357142857143em;"><span style="top:-2.8220357142857138em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.56643em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.217827em;vertical-align:-1.56643em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.75857em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8220357142857143em;"><span style="top:-2.8220357142857138em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.56643em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span><span class="mclose">)</span></span></span></span></span></span></p><p>令z的分布为Q(z;θ) ，并且Q(z;θ)≥0；那么有如下公式：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ｌ</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac></mrow></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>≥</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>E</mi><mi>Q</mi></msub><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><munderover><mo>∑</mo><mi>a</mi><mi>b</mi></munderover><mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mrow></mrow><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Ｌ(\theta)=\sum_{i=1}^{m}{log\sum_{z}^{}{P(x,z;\theta)}}\\　　　　　　=\sum_{i=1}^{m}{log \sum_{z}^{}{Q(z;\theta ^{old})\frac{P(x,z;\theta)}{Q(z;\theta^{old})}}}\\　　　　=\sum_{i=1}^{m}{log(E_Q(  \frac{P(x,z;\theta)} {Q(z;\theta^{old})}  ))}\\　　　　\geq \sum_{i=1}^{m}{E_Q(log(  \frac{P(x,z;\theta)} {Q(z;\theta^{old} )}  ))}\\　　　　　　　=\sum_{a}^{b}{\sum_{z}^{}{ Q(z;\theta^{old} ) log(   \frac{P(x,z;\theta^{}{})} {Q(z;\theta^{old} )}  ) }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">Ｌ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.086118em;vertical-align:-1.250005em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.836113em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mord"></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span></span></p><h3 id="公式2详解"><a class="markdownIt-Anchor" href="#公式2详解"></a> 公式(2)详解：</h3><p>1.公式(1)得出的结论理论上可行，实践起来不成。主要是因为似然函数有“和的log”这一项，（公式（2）的前两步）log里面是一个和的形式，一求导这画面不要太美，直接强来你要面对 “两个正态分布的概率密度函数相加”做分母，“两个正态分布分别求导再相加”做分子的分数形式。m个这玩意加起来令它等于0，要求出关于θ的解析解，你对自己的数学水平想的不要太高</p><p>2.引入Jensen不等式:X是一个随机变量，f(X)是一个凸函数（二阶导数大或等于0），那么有：E(f(x))≥f(E(x))，当且仅当X是常数的时候等号成立，如果f（X）是凹函数，不等号反向。</p><p>3.直接最大化似然函数做不到，那么如果我们能找到似然函数的一个<strong>紧</strong>的下界一直优化它，并保证每次迭代能够使总的似然函数一直增大，其实也是一样的。怎么说？画个图你就明白了：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/1_ys.png" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/1_ys.png" class="lazyload"></a></p><p>横坐标是参数，纵坐标是似然函数，首先我们初始化一个θ1，根据它求似然函数一个紧的下界，也就是图中第一条黑短线，黑短线上的值虽然都小于似然函数的值，但至少有一点可以满足等号（所以称为紧下界），最大化小黑短线我们就hit到至少与似然函数刚好相等的位置，对应的横坐标就是我们的新的θ2，如此进行，只要保证随着θ的更新，每次最大化的小黑短线值都比上次的更大，那么算法收敛，最后就能最大化到似然函数的极大值处。</p><p>来到公式2最后两步骤，我们找到了似然函数的一个下界，那么优化它是否就可以呢？不是的，上面说了必须保证这个下界是紧的，也就是至少有点能使等号成立。由Jensen不等式，等式成立的条件是随机变量是常数，具体到这里，就是：</p><p>根据Jensen不等式的特性，当下列式子的值为常数的时候，L(θ)函数才能取等号。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>c</mi><mo separator="true">,</mo><mi mathvariant="normal">∀</mi><mi mathvariant="normal">ｘ</mi><mi mathvariant="normal">．</mi><mi mathvariant="normal">∀</mi><mi mathvariant="normal">ｚ</mi></mrow><annotation encoding="application/x-tex">\\　　　　　　　\frac{P(x,z;\theta^{old})} {Q(z;\theta^{old} )} =c,\forallｘ．\forallｚ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="mspace newline"></span><span class="base"><span class="strut" style="height:2.462108em;vertical-align:-0.936em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∀</span><span class="mord cjk_fallback">ｘ</span><span class="mord cjk_fallback">．</span><span class="mord">∀</span><span class="mord cjk_fallback">ｚ</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ｑ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">,</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>c</mi></mfrac><mspace linebreak="newline"></mspace><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>c</mi><mo>⋅</mo><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mo>=</mo><mn>1</mn><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>c</mi><mo>⋅</mo><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mi mathvariant="normal">　</mi><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><msup><mi>z</mi><mi>i</mi></msup><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mrow></mfrac><mi mathvariant="normal">　</mi><mspace linebreak="newline"></mspace><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mspace linebreak="newline"></mspace><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Ｑ(z,\theta^{old}) =\frac{P(x,z;\theta^{old})}{c}\\　　　　　　　　　　　　　=\frac{P(x,z;\theta^{old})}{c\cdot \sum_{z^i}^{} {Q(z^i;\theta^{old})}}　　　　　　　　　 \sum_{z^i}^{} {Q(z^i;\theta^{old})}=1\\=\frac{P(x,z;\theta^{old})}{ \sum_{z^i}^{} {c\cdot Q(z^i;\theta^{old})}}　　\\=\frac{P(x,z;\theta^{old})}{ \sum_{z^i}^{} {P(x,z^i;\theta^{old})}}　\\=\frac{P(x,z;\theta^{old})}{ P(x;\theta^{old})}\\=P(z|x;\theta^{old})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">Ｑ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.212108em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">c</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.872073em;vertical-align:-1.3459649999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000006em;"><span style="top:-1.804035em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3459649999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8746639999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.511818em;vertical-align:-0.9857100000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.511818em;vertical-align:-0.9857100000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.750664em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857100000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">　</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.462108em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>则可得：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi mathvariant="normal">Ｌ</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mspace linebreak="newline"></mspace><mo>≃</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><msup><mi>θ</mi><mrow></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=arg\max_{\theta}Ｌ(\theta)=arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{Q(z;\theta^{old})}log(\frac{P(x,z;\theta^{})}{Q(z;\theta^{old})})\\=arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{P(z|x;\theta^{old}log(\frac{P(x,z;\theta^{}}{P(z|x;\theta^{old})}))}\\ \simeq  arg\max_{\theta} \sum_{i=1}^{m}{} \sum_{z}^{}{P(z|x;\theta^{old})log(P(x,z;\theta^{}))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">Ｌ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.363em;"><span style="top:-2.363em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.46375em;vertical-align:0em;"></span><span class="mrel">≃</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span style="top:-2.413em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></span></p><p>此处我们化简去loga-logb中的logb,logb此处为常数</p><h2 id="em算法总结"><a class="markdownIt-Anchor" href="#em算法总结"></a> EM算法总结：</h2><p>条件：样本数据x={x1,x2,…,xm}，联合分布p(x,z;θ)，条件分布p(z|x;θ)，最大迭代次数J</p><ol><li>随机初始化模型参数θ的初始值θ0</li><li>开始EM算法的迭代处理：<br>E步：计算联合分布的条件概率期望</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Q</mi><mi>j</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><msup><mi>θ</mi><mi>j</mi></msup><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow><munderover><mo>∑</mo><mi>z</mi><mrow></mrow></munderover><mrow><msup><mi>Q</mi><mi>j</mi></msup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">Q^j=[(z|x;\theta^j)  \\L(\theta)=\sum_{i=1}^{m}{}\sum_{z}^{}{Q^jlog(P(x,z;\theta))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.069104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.124664em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3500050000000001em;"><span style="top:-1.8999949999999999em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.250005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></span></p><p>​       M步：极大化L函数，得到θj+1</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>θ</mi></munder><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta^{j+1}=arg\max_{\theta}L(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.874664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.502108em;vertical-align:-0.752108em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.047892em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.752108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span></p><p>如果θj+1已经收敛，则算法结束，输出最终的模型参数θ，否则继续     迭代处理。</p><h2 id="ems算法收敛性证明"><a class="markdownIt-Anchor" href="#ems算法收敛性证明"></a> EMs算法收敛性证明</h2><h1 id="em算法举例"><a class="markdownIt-Anchor" href="#em算法举例"></a> EM算法举例</h1><p>假设现有两个装有不定数量黑球、白球的盒子，随机从盒子中抽取出一个白球的概率分布为p1和p2；为了估计这两个概率，每次选择一个盒子，有放回的连续随机抽取5个球，记录如下：</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/2_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/3_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/4_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/5_ys.png" class="lazyload"></a></p><p>求解过程看如下推导:</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/6_ys.jpg" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/6_ys.jpg" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/7_ys.png" data-fancybox="group" data-caption="7_ys" class="fancybox"><img alt="7_ys" title="7_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/7_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/8_ys.png" data-fancybox="group" data-caption="8_ys" class="fancybox"><img alt="8_ys" title="8_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/8_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/9_ys.png" data-fancybox="group" data-caption="9_ys" class="fancybox"><img alt="9_ys" title="9_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/9_ys.png" class="lazyload"></a></p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/10_ys.png" data-fancybox="group" data-caption="10_ys" class="fancybox"><img alt="10_ys" title="10_ys" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/10_ys.png" class="lazyload"></a></p><h2 id="em算法收敛性证明"><a class="markdownIt-Anchor" href="#em算法收敛性证明"></a> EM算法收敛性证明</h2><p>详见PPT</p><h1 id="gmm算法"><a class="markdownIt-Anchor" href="#gmm算法"></a> GMM算法</h1><p>GMM(Gaussian Mixture Model, 高斯混合模型)是指该算法由多个高斯模型线性叠加混合而成。每个高斯模型称之为component。GMM算法描述的是数据的本身存在的一种分布。<br>GMM算法常用于聚类应用中，component的个数就可以认为是类别的数量。<br>假定GMM由k个Gaussian分布线性叠加而成，那么概率密度函数如下：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>k</mi><mo stretchy="false">)</mo></mrow><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><msub><mi>π</mi><mi>k</mi></msub><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msub><mi>μ</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mrow><msubsup><mo>∑</mo><mrow></mrow><mrow></mrow></msubsup><mrow></mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(x)=\sum_{k=1}^{K}{p(k)p(x|k)}=\sum_{k=1}^{K}{π_kp(x;\mu_k,{\sum_{}^{}{}}_k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.330641em;vertical-align:-0.34941em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-1.7002899999999999em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span><span style="top:-2.5029em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.13669799999999993em;"><span style="top:-2.3505900000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34941em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>此处<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">π_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是符号，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mi>k</mi></msub><mo separator="true">,</mo><msub><mrow><msubsup><mo>∑</mo><mrow></mrow><mrow></mrow></msubsup><mrow></mrow></mrow><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mu_k,{\sum_{}^{}{}}_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.09941em;vertical-align:-0.34941em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-1.7002899999999999em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span><span style="top:-2.5029em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.13669799999999993em;"><span style="top:-2.3505900000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34941em;"><span></span></span></span></span></span></span></span></span></span>代表均值与协方差矩阵</p><p><a href="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/11.png" data-fancybox="group" data-caption="11" class="fancybox"><img alt="11" title="11" data-src="/img/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/EM%E7%AE%97%E6%B3%95/11.png" class="lazyload"></a></p><h1 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h1><p>[<a href="https://www.cnblogs.com/bigmoyan/p/4550375.html" target="_blank" rel="noopener">【机器学习】EM算法详细推导和讲解</a>](<a href="https://www.cnblogs.com/bigmoyan/p/4550375.html" target="_blank" rel="noopener">https://www.cnblogs.com/bigmoyan/p/4550375.html</a>)</p></body></html>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯</title>
      <link href="/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
      <url>/2020/01/08/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="涉及公式"><a class="markdownIt-Anchor" href="#涉及公式"></a> 涉及公式</h1><p>先验概率P(A)：在不考虑任何情况下，A事件发生的概率<br>条件概率P(B|A)：A事件发生的情况下，B事件发生的概率:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(AB)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>后验概率P(A|B)：在B事件发生之后，对A事件发生的概率的重新评估<br>全概率：如果A和A’构成样本空间的一个划分，那么事件B的概率为：A和A’的概率分别乘以B对这两个事件的概率之和。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>+</mo><mi>P</mi><mo stretchy="false">(</mo><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msup><mi>A</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(B)=P(A)*P(B|A)+P(A')*P(B|A')</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(B)=\sum_{i=1}^{n}{P(A_i)*(B|A_i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p><p>乘法定理：成立条件，A1A2…An全连接<a href="/img/beiyesi/pinghua/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/pinghua/1.png" class="lazyload"></a></p><p>A1无依赖，A2依赖于A1,A3依赖于A1A2</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>1</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>A</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>A</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mn>1</mn></msub><msub><mi>A</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>A</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(A_1A_2...A_n)=P(A_1)P(A_2|A_1)...P(A_n|A_1A_2...A_{n-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><h1 id="朴素贝叶斯算法"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法"></a> 朴素贝叶斯算法</h1><p>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。而朴素朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。</p><p><a href="/img/beiyesi/1.jpg" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/1.jpg" class="lazyload"></a></p><h2 id="分类问题综述"><a class="markdownIt-Anchor" href="#分类问题综述"></a> 分类问题综述</h2><p><strong>从数学角度来说，分类问题可做如下定义：已知集合</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>y</mi><mi>n</mi></msub><mi mathvariant="normal">和</mi><mi>I</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">C=y_1,y_2,......y_n和I=x_1,x_2,......x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>确定映射规则y=f()，<strong>使得任意</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">x_i\in I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>**有且仅有一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">y_i\in C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>**使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y_i\in f(x_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>成立</p><p>其中C叫做类别集合，其中每一个元素是一个类别，而I叫做项集合（<strong>特征集合</strong>），其中每一个元素是一个待分类项，f叫做分类器。<strong>分类算法的任务就是构造分类器f。</strong></p><p><strong>分类算法的内容是要求给定特征，让我们得出类别，这也是所有分类问题的关键。那么如何由指定特征，得到我们最终的类别，也是我们下面要讲的，每一个不同的分类算法，对应着不同的核心思想。</strong></p><h2 id="朴素贝叶斯分类"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类"></a> 朴素贝叶斯分类</h2><p>那么既然是朴素贝叶斯<strong>分类算法</strong>，它的核心算法又是什么呢？</p><p><strong>是下面这个贝叶斯公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mi mathvariant="normal">∣</mi><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mi mathvariant="normal">∣</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(B|A)=\frac{P(B)*P(A|B)}{P(A)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord">∣</span><span class="mord mathdefault">A</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">A</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>换个表达形式就会明朗很多，如下：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">类</mi><mi mathvariant="normal">别</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">特</mi><mi mathvariant="normal">征</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(类别|特征)=\frac{P(类别)*P(特征|类别)}{P(特征)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mord">∣</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord cjk_fallback">特</span><span class="mord cjk_fallback">征</span><span class="mord">∣</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">别</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><strong>我们最终求的p(类别|特征)即可！就相当于完成了我们的任务。</strong></p><h2 id="例题分析"><a class="markdownIt-Anchor" href="#例题分析"></a> <strong>例题分析</strong></h2><p><strong>下面我先给出例子问题。</strong></p><p><strong>给定数据如下：</strong></p><p><a href="/img/beiyesi/1.png" data-fancybox="group" data-caption="1" class="fancybox"><img alt="1" title="1" data-src="/img/beiyesi/1.png" class="lazyload"></a></p><p><strong>现在给我们的问题是，如果一对男女朋友，男生想女生求婚，男生的四个特点分别是不帅，性格不好，身高矮，不上进，请你判断一下女生是嫁还是不嫁？</strong></p><p>这是一个典型的分类问题，<strong>转为数学问题就是比较p(嫁|(不帅、性格不好、身高矮、不上进))与p(不嫁|(不帅、性格不好、身高矮、不上进))的概率</strong>，谁的概率大，我就能给出嫁或者不嫁的答案！</p><p>这里我们联系到朴素贝叶斯公式：<a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" title="2" data-src="/img/beiyesi/2.png" class="lazyload"></a></p><p>我们需要求p(嫁|(不帅、性格不好、身高矮、不上进),这是我们不知道的，但是通过朴素贝叶斯公式可以转化为好求的三个量，<strong>p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)（至于为什么能求，后面会讲，那么就太好了，将待求的量转化为其它可求的值，这就相当于解决了我们的问题！）</strong></p><h2 id="朴素贝叶斯算法的朴素一词解释"><a class="markdownIt-Anchor" href="#朴素贝叶斯算法的朴素一词解释"></a> <strong>朴素贝叶斯算法的朴素一词解释</strong></h2><p><strong>那么这三个量是如何求得？</strong></p><p>是根据已知训练数据统计得来，下面详细给出该例子的求解过程。</p><p>回忆一下我们要求的公式如下：</p><p><a href="/img/beiyesi/2.png" data-fancybox="group" data-caption="2" class="fancybox"><img alt="2" title="2" data-src="/img/beiyesi/2.png" class="lazyload"></a></p><p>那么我只要求得p(不帅、性格不好、身高矮、不上进|嫁)、p（不帅、性格不好、身高矮、不上进)、p(嫁)即可，好的，下面我分别求出这几个概率，最后一比，就得到最终结果。</p><p><strong>p(不帅、性格不好、身高矮、不上进|嫁) = p(不帅|嫁)*p(性格不好|嫁)*p(身高矮|嫁)*p(不上进|嫁)，那么我就要分别统计后面几个概率，也就得到了左边的概率！</strong></p><p>等等，为什么这个成立呢？学过概率论的同学可能有感觉了，这个等式成立的条件需要特征之间相互独立吧！</p><p><strong>对的！这也就是为什么朴素贝叶斯分类有朴素一词的来源，朴素贝叶斯算法是假设各个特征之间相互独立，那么这个等式就成立了！</strong></p><p><strong>但是为什么需要假设特征之间相互独立呢？</strong></p><p>1、我们这么想，假如没有这个假设，那么我们对右边这些概率的估计其实是不可做的，这么说，我们这个例子有4个特征，其中帅包括{帅，不帅}，性格包括{不好，好，爆好}，身高包括{高，矮，中}，上进包括{不上进，上进}，<strong>那么四个特征的联合概率分布总共是4维空间，总个数为2*3*3*2=36个。</strong></p><p><strong>24个，计算机扫描统计还可以，但是现实生活中，往往有非常多的特征，每一个特征的取值也是非常之多，那么通过统计来估计后面概率的值，变得几乎不可做，这也是为什么需要假设特征之间独立的原因。</strong></p><p>2、假如我们没有假设特征之间相互独立，那么我们统计的时候，就需要在整个特征空间中去找，比如统计p(不帅、性格不好、身高矮、不上进|嫁),</p><p><strong>我们就需要在嫁的条件下，去找四种特征全满足分别是不帅，性格不好，身高矮，不上进的人的个数，这样的话，由于数据的稀疏性，很容易统计到0的情况。 这样是不合适的。</strong></p><p>根据上面俩个原因，朴素贝叶斯法对条件概率分布做了条件独立性的假设，由于这是一个较强的假设，朴素贝叶斯也由此得名！这一假设使得朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p><p>好的，上面我解释了为什么可以拆成分开连乘形式。那么下面我们就开始求解！</p><p>我们将上面公式整理一下如下：<a href="/img/beiyesi/3.png" data-fancybox="group" data-caption="3" class="fancybox"><img alt="3" title="3" data-src="/img/beiyesi/3.png" class="lazyload"></a></p><p>下面我将一个一个的进行统计计算（<strong>在数据量很大的时候，根据中心极限定理，频率是等于概率的，这里只是一个例子，所以我就进行统计即可</strong>）。</p><p>p(嫁)=？</p><p>首先我们整理训练数据中，嫁的样本数如下：<a href="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" data-fancybox="group" data-caption="v2-82d69514c761c791c6eaf90dc0771b44_b" class="fancybox"><img alt="v2-82d69514c761c791c6eaf90dc0771b44_b" title="v2-82d69514c761c791c6eaf90dc0771b44_b" data-src="/img/beiyesi/v2-82d69514c761c791c6eaf90dc0771b44_b.png" class="lazyload"></a></p><p><strong>则 p(嫁) = 6/12（总样本数） = 1/2</strong></p><p><strong>p(不帅|嫁) = 3/6 = 1/2</strong></p><p><strong>则p(性格不好|嫁)= 1/6</strong></p><p>p(矮|嫁) = 1/6**</p><p>p(不上进|嫁) = 1/6**</p><p><strong>下面开始求分母，p(不帅)，p（性格不好），p（矮），p（不上进）</strong></p><p><strong>不帅统计占4个，那么p（不帅）= 4/12 = 1/3</strong></p><p>性格不好占4个，那么p（性格不好） = 4/12 = 1/3</p><p>身高矮统计，占7个，那么p（身高矮） = 7/12</p><p>不上进统计所示，占4个，那么p（不上进） = 4/12 = 1/3</p><p><strong>到这里，要求p(不帅、性格不好、身高矮、不上进|嫁)的所需项全部求出来了，下面我带入进去即可，<a href="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" data-fancybox="group" data-caption="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" class="fancybox"><img alt="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" title="v2-e0abd30b1376c18c3dfd0d0bf4375c26_b" data-src="/img/beiyesi/v2-e0abd30b1376c18c3dfd0d0bf4375c26_b.png" class="lazyload"></a></strong></p><p>= (1/2<em>1/6</em>1/6<em>1/6</em>1/2)/(1/3<em>1/3</em>7/12*1/3)</p><p><strong>下面我们根据同样的方法来求p(不嫁|不帅，性格不好，身高矮，不上进)，完全一样的做法，为了方便理解，我这里也走一遍帮助理解。首先公式如下：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" title="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload"></a></strong></p><p>下面我也一个一个来进行统计计算，这里与上面公式中，分母是一样的，于是我们分母不需要重新统计计算！</p><p>p(不嫁)=6/12 = 1/2</p><p>p（不帅|不嫁） = 1/6</p><p>p（性格不好|不嫁） =3/6 = 1/2</p><p>p（矮|不嫁） = 6/6 = 1</p><p>p（不上进|不嫁） = 3/6 = 1/2</p><p>那么根据公式：<a href="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" data-fancybox="group" data-caption="v2-7caa2cca71867344273c32a949b291f3_b" class="fancybox"><img alt="v2-7caa2cca71867344273c32a949b291f3_b" title="v2-7caa2cca71867344273c32a949b291f3_b" data-src="/img/beiyesi/v2-7caa2cca71867344273c32a949b291f3_b.png" class="lazyload"></a></p><p>p (不嫁|不帅、性格不好、身高矮、不上进) = ((1/6<em>1/2</em>1<em>1/2)<em>1/2)/(1/3</em>1/3</em>7/12*1/3)</p><p><strong>很显然(1/6*1/2*1*1/2) > (1/2*1/6*1/6*1/6*1/2)</strong></p><p><strong>于是有p (不嫁|不帅、性格不好、身高矮、不上进)>p (嫁|不帅、性格不好、身高矮、不上进)</strong></p><p><strong>所以我们根据朴素贝叶斯算法可以给这个女生答案，是不嫁！！！！</strong></p><h2 id="朴素贝叶斯分类的优缺点"><a class="markdownIt-Anchor" href="#朴素贝叶斯分类的优缺点"></a> <strong>朴素贝叶斯分类的优缺点</strong></h2><p>优点：</p><p>（1） 算法逻辑简单,易于实现</p><p>（2）分类过程中时空开销小</p><p>缺点：</p><p>理论上，<strong>朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong></p><p>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</p><h1 id="常用朴素贝叶斯分类模型"><a class="markdownIt-Anchor" href="#常用朴素贝叶斯分类模型"></a> 常用朴素贝叶斯分类模型</h1><p>依据特征值是连续还是离散选择</p><h2 id="高斯朴素贝叶斯"><a class="markdownIt-Anchor" href="#高斯朴素贝叶斯"></a> 高斯朴素贝叶斯</h2><p>Gaussian Naive Bayes是指当特征属性为连续值时，而且分布服从高斯分布，那么在计算P(x|y)的时候可以直接使用高斯分布的概率公式：假定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>∼</mo><mi>N</mi><mo stretchy="false">(</mo><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x_i |c)\sim N(\mu_{c,i},\sigma_{c,i}^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20888em;vertical-align:-0.394772em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><msub><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow></mfrac><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x_i |c)=\frac{1}{\sqrt{2π}\sigma_{c,i}}exp(-\frac{(x_i-\mu_{c,i})^2}{2\sigma_{c,i}^2})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.82764em;vertical-align:-0.6963999999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5510085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.912845em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span><span style="top:-2.872845em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.12715500000000002em;"><span></span></span></span></span></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6463114999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.13124em;"><span style="top:-2.6264200000000004em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051142857142857em;"><span style="top:-2.177714285714286em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.50732em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6963999999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span> ,其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>μ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>σ</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\mu_{c,i},\sigma_{c,i}^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20888em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>分别是第c类样本和第i个属性上取值的均值和方差。</p><h2 id="伯努利朴素贝叶斯"><a class="markdownIt-Anchor" href="#伯努利朴素贝叶斯"></a> 伯努利朴素贝叶斯</h2><p>Bernoulli Naive Bayes是指当特征属性为连续值时，而且分布服从伯努利分布，那么在计算P(x|y)的时候可以直接使用伯努利分布的概率公式：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>k</mi></msub><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mi>k</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy="false">(</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_k |y)=P(1|y)x_k+(1-P(1|y))(1-x_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>伯努利分布是一种离散分布，只有两种可能的结果。1表示成功，出现的概率为p；0表示失败，出现的概率为q=1-p；其中均值为E(x)=p，方差为Var(X)=p(1-p)</p><h2 id="多项式朴素贝叶斯引入平滑项"><a class="markdownIt-Anchor" href="#多项式朴素贝叶斯引入平滑项"></a> 多项式朴素贝叶斯（引入平滑项）</h2><p>Multinomial Naive Bayes是指当特征属性服从多项分布(特征是离散的形式的时候)，直接计算类别数目的占比作为先验概率和条件概率。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub><mo>+</mo><mi>α</mi></mrow><mrow><mi>N</mi><mo>+</mo><mi>k</mi><mo>∗</mo><mi>α</mi></mrow></mfrac><mspace linebreak="newline"></mspace><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi><mo separator="true">,</mo><mi>x</mi><mi>i</mi></mrow></msub><mo>+</mo><mi>α</mi></mrow><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub><mo>+</mo><msub><mi>n</mi><mi>i</mi></msub><mo>∗</mo><mi>α</mi></mrow></mfrac><mi mathvariant="normal">​</mi></mrow><annotation encoding="application/x-tex">P(y_k)=\frac{N_{yk}+\alpha}{N+k*\alpha}   \\p(x_i|y_k)=\frac{N_{yk,xi}+\alpha}{N_{yk}+n_i*\alpha}​</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.332438em;vertical-align:-0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">x</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">​</span></span></span></span></span></p><p>N是总样本个数，k是总的类别个数，Nyk是类别为yk的样本个数，α为平滑值。<br><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{yk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是类别为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的样本个数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">n_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为特征属性<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的不同取值数目，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi mathvariant="normal">.</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{y.k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">.</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为类别<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>中第i维特征的值为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的样本个数，α为平滑值。<br>当α=1时，称为Laplace平滑，当0<α<1时，称为Lidstone平滑，α=0时不做平滑；平滑的主要作用是可以克服条件概率为0的问题。(当存在0时，整个式子*0为0)</p><p>即，当某一特征属性为0时，我们通过分子+α来避免<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>y</mi><mi mathvariant="normal">.</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">N_{y.k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">.</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为0，即人为增加一样本，此时为确保公平，任一特征属性下都应该加1样本。<strong>平滑项(参考https://zhuanlan.zhihu.com/p/26329951)</strong></p><h1 id="多项式朴素贝叶斯案例理解平滑项作用举例"><a class="markdownIt-Anchor" href="#多项式朴素贝叶斯案例理解平滑项作用举例"></a> 多项式朴素贝叶斯案例理解(平滑项作用举例)</h1><p>（参考文章末尾附带PPT 13-16）</p><p><a href="/img/beiyesi/pinghua/1_ys.jpg" data-fancybox="group" data-caption="1_ys" class="fancybox"><img alt="1_ys" title="1_ys" data-src="/img/beiyesi/pinghua/1_ys.jpg" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/2_ys.png" data-fancybox="group" data-caption="2_ys" class="fancybox"><img alt="2_ys" title="2_ys" data-src="/img/beiyesi/pinghua/2_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/3_ys.png" data-fancybox="group" data-caption="3_ys" class="fancybox"><img alt="3_ys" title="3_ys" data-src="/img/beiyesi/pinghua/3_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/beiyesi/pinghua/4_ys.png" class="lazyload"></a></p><p><a href="/img/beiyesi/pinghua/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/beiyesi/pinghua/5_ys.png" class="lazyload"></a></p><h1 id="贝叶斯网络"><a class="markdownIt-Anchor" href="#贝叶斯网络"></a> 贝叶斯网络</h1><ol><li>把某个研究系统中涉及到的随机变量，根据是否条件独立绘制在一个有向图中，就形成了贝叶斯网络。</li><li>贝叶斯网络(Bayesian Network)，又称<strong>有向无环图模型</strong>(directed acyclic graphical model, DAG)，是一种概率图模型，根据概率图的拓扑结构，考察一组随机变量{X1,X2,…,Xn}及其N组条件概率分布(Conditional Probabililty Distributions, CPD)的性质。</li><li><strong>当多个特征属性之间存在着某种相关关系的时候，使用朴素贝叶斯算法就没法解决这类问题，那么贝叶斯网络就是解决这类应用场景的一个非常好的算法。</strong></li><li>一般而言，贝叶斯网络的有向无环图中的节点表示随机变量，可以是可观察到的变量，或隐变量，未知参数等等。连接两个节点之间的箭头代表两个随机变量之间的因果关系(也就是这两个随机变量之间非条件独立)，如果两个节点间以一个单箭头连接在一起，表示其中一个节点是“因”，另外一个是“果”，从而两节点之间就会产生一个条件概率值。</li><li>贝叶斯网络的关键方法是图模型，构建一个图模型我们需要把具有因果联系的各个变量用箭头连在一起。贝叶斯网络的有向无环图中的节点表示随机变量。连接两个节点的箭头代表此两个随机变量是具有因果关系的。</li><li>贝叶斯网络是模拟人的认知思维推理模式的，用一组条件概率以及有向无环图对不确定性因果推理关系建模</li></ol><p>最简单的一个贝叶斯网络：P(a,b,c ) = P(c|a.b)P(b|a)P(a)</p><p><a href="/img/beiyesi/4_ys.png" data-fancybox="group" data-caption="4_ys" class="fancybox"><img alt="4_ys" title="4_ys" data-src="/img/beiyesi/4_ys.png" class="lazyload"></a></p><p>全连接贝叶斯网络：每一对节点都有边连接：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>2</mn></mrow><mi>n</mi></munderover><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_1,x_2...,x_n)=P(x_n|x_1,x_2...,x_n)...P(x_2|x_1)P(x_1) \\P(x_1,x_2...,x_n)=\prod_{i=2}^{n}P(x_i|x_1,x_2,...,x_{i-1})*P(x_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p><a href="/img/beiyesi/5_ys.png" data-fancybox="group" data-caption="5_ys" class="fancybox"><img alt="5_ys" title="5_ys" data-src="/img/beiyesi/5_ys.png" class="lazyload"></a></p><p>“正常”贝叶斯网络：<a href="/img/beiyesi/6_ys.png" data-fancybox="group" data-caption="6_ys" class="fancybox"><img alt="6_ys" title="6_ys" data-src="/img/beiyesi/6_ys.png" class="lazyload"></a></p><ul><li></li><li>x6和x7在给定条件下独立</li><li>x1,x2,x3…x7的联合分布为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>5</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>6</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>7</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>4</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>5</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>6</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>4</mn></msub><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>7</mn></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x_1,x_2,x_3,x_4,x_5,x_6,x_7)=P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2,x_3) P(x_5|x_1,x_3) P(x_6|x_4) P(x_7|x_4,x_5)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li></ul><p>举例：详见文末PPT  29-30</p><h3 id="贝叶斯网络判定条件独立贝叶斯网络的结构形式"><a class="markdownIt-Anchor" href="#贝叶斯网络判定条件独立贝叶斯网络的结构形式"></a> 贝叶斯网络判定条件独立(贝叶斯网络的结构形式)</h3><p>1.head - to - head</p><p><a href="/img/beiyesi/1-1_ys.png" data-fancybox="group" data-caption="1-1_ys" class="fancybox"><img alt="1-1_ys" title="1-1_ys" data-src="/img/beiyesi/1-1_ys.png" class="lazyload"></a></p><p>在C未知的情况下，a和b被阻断(blocked)，是独立的</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><msubsup><mo>∑</mo><mi>c</mi><mrow></mrow></msubsup><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mi>c</mi><mrow></mrow></msubsup><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mrow><mo>⇒</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b,c)=P(a)P(b)P(c|a,b)\\\sum_{c}^{}{P(a,b,c)=\sum_{c}^{}{P(a)*P(b)*p(c|a,b)}}\Rightarrow P(a,b)=P(a)*P(b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">∣</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5029em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">∣</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span></p><p>2.head- to -tail</p><p><a href="/img/beiyesi/1-2_ys.png" data-fancybox="group" data-caption="1-2_ys" class="fancybox"><img alt="1-2_ys" title="1-2_ys" data-src="/img/beiyesi/1-2_ys.png" class="lazyload"></a></p><p>在C给定的条件下，a和b被阻断(blocked)是独立的:</p><p>P(a,b,c)=P(a)P(c|a)P(b|c)</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b|c)=P(a,b,c)|P(c) =\frac{P(a)P(c|a)P(b|c)}{P(c)}  = \frac{P(a,c)*P(b|c)}{P(c)}=P(a|c)*P(b|c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">a</span><span class="mclose mtight">)</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">a</span><span class="mclose mtight">)</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">b</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">a</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">b</span><span class="mord mtight">∣</span><span class="mord mathdefault mtight">c</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></p><p>c未知时，有：P(a,b,c)=P(a)*P(c|a)*P(b|c)，但无法推出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p><p>3.tail - to -tail<a href="/img/beiyesi/1-3_ys.png" data-fancybox="group" data-caption="1-3_ys" class="fancybox"><img alt="1-3_ys" title="1-3_ys" data-src="/img/beiyesi/1-3_ys.png" class="lazyload"></a></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>⇒</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mo>∵</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">.</mi><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mspace linebreak="newline"></mspace><mo>∴</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">.</mi><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(a,b,c)=P(c)P(b|c)P(a|c)\Rightarrow \frac{P(a,b,c)}{P(c)}=P(b|c)P(a|c)\\∵P(a.b|c) =\frac{P(a,b,c)}{P(c)}\\∴ P(a.b|c)  = P(a|c)P(b|c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.69224em;vertical-align:0em;"></span><span class="mrel amsrm">∵</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">.</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.69224em;vertical-align:0em;"></span><span class="mrel amsrm">∴</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">.</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">b</span><span class="mord">∣</span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></span></p><p>在C给定的条件下，a和b被阻断(blocked)是独立的</p><p>在c未知的时候，有：P(a,b,c)=P©*P(a|c)*P(b|c)，此时，没法得出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p><h1 id="本章节ppt与文字参考链接"><a class="markdownIt-Anchor" href="#本章节ppt与文字参考链接"></a> 本章节PPT与文字参考链接</h1><p><a href="https://zhuanlan.zhihu.com/p/26262151" target="_blank" rel="noopener">带你理解朴素贝叶斯分类算法</a></p><p><a href="https://zhuanlan.zhihu.com/p/26329951" target="_blank" rel="noopener">理解朴素贝叶斯分类的拉普拉斯平滑</a></p><p><a href="https://zhuanlan.zhihu.com/p/73415944" target="_blank" rel="noopener">贝叶斯网络，看完这篇我终于理解了(附代码)！</a></p><p><a href="/ppt/beiys.pptx">PPT下载</a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM算法总结</title>
      <link href="/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2020/01/06/SVM%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><h1 id="感知机模型"><a class="markdownIt-Anchor" href="#感知机模型"></a> 感知机模型：</h1><p>感知器模型是SVM、神经网络、深度学习等算法的基础;感知器模型就是试图找到一条直线，能够把所有的“+1”类和“-1”类分隔开，如果是高维空间中，感知器模型寻找的就是一个超平面，能够把所有的二元类别分割开。感知器模型的前提是：数据是线性可分的。</p><p><a href="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-624de9659125f370026c972f21dcbb69_hd.jpg" class="lazyload"></a></p><p>目标是找到一个超平面，即： <a href="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta_%7B0%7D%2B+%5Ctheta_%7B1%7Dx_%7B1%7D%2B%5Ctheta_%7B0%7D%2B......%2B+%5Ctheta_%7Bn%7D%2B+%5Ctheta_%7B1%7Dx_%7Bn%7D%3D%5Ctheta%5Ccdot+x+%3D+0" class="lazyload"></a></p><p>感知器模型为: <a href="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3D+%5Cbegin%7Bcases%7D++%2B1+%2C%5Ctheta+%5Ccdot+x+%3E+0+%5C%5C%5B2ex%5D++-1%2C%5Ctheta+%5Ccdot+x+%3C+0+%5C%5C%5B2ex%5D+++%5Cend%7Bcases%7D++" class="lazyload"></a></p><p>感知器模型正确分类（预测和实际类别一致）：yθx>0（y为实际值，θx为预测值），错误分类（预测和实际类别不一致）：yθx<0；所以我们可以定义我们的损失函数为：期望使分类错误的所有样本(k条样本)到超平面的距离之和最小。</p><p>即：<a href="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L++%3D%5Cfrac%7B%7C%5Ctheta%5Ccdot+x_%7Bi%7D%7C%7D%7B%7C%7C+%5Ctheta%7C%7C_%7B2%7D%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cfrac%7B-y%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D%7D%7B%7C%7C+%5Ctheta+%7C%7C_%7B2%7D%7D%7D" class="lazyload"></a> (去绝对值符号，分类错误<0,分子加”—“)</p><p>简化损失函数：因为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）:</p><p>简化损失函数：因 为此时分子和分母中都包含了θ值，当分子扩大N倍的时候，分母也会随之扩大，也就是说分子和分母之间存 在倍数关系，所以可以固定分子或者分母为1，然后求另一个即分子或者分母的倒数的最小化作为损失函数，简化后的损失函数为（分母为1）: <a href="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=L+%3D+-+%5Csum_%7Bi+%3D+1%7D%5E%7Bk%7Dy%5E%7B%28i%29%7D%5Ctheta%5Ccdot+x%5E%7B%28i%29%7D" class="lazyload"></a> (即 <a href="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Ctheta+%5Ccdot+x+%3D%7C%5Ctheta%7C%2A%7Cx%7C%2Acos%5Calpha" class="lazyload"></a> ,分子分母相抵消，模长对结果无影响)。</p><p>直接使用梯度下降法就可以对损失函数求解，不过由于这里的k是分类错误的样本点集合，不是固定的，所以我们不能使用批量梯度下降法(BGD)求解，只能使用随机梯度下降(SGD)或者小批量梯度下降(MBGD)；一般在感知器模型中使用SGD来求解。</p><hr><h1 id="svm支持向量机"><a class="markdownIt-Anchor" href="#svm支持向量机"></a> SVM(支持向量机)</h1><p>支持向量机(Support Vecor Machine, SVM)本身是一个二元分类算法，是对感知器算法模型的一种扩展，现在的SVM算法支持线性分类和非线性分类的分类应用，并且也能够直接将SVM应用于回归应用中，同时通过OvR或者OvO的方式我们也可以将SVM应用在多元分类领域中。在不考虑集成学习算法，不考虑特定的数据集的时候，在分类算法中SVM可以说是特别优秀的。</p><p><a href="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-74d81e6bced6d75cf21eb04753a57e6e_hd.jpg" class="lazyload"></a></p><p>在感知器模型中，算法是在数据中找出一个划分超平面，让尽可能多的数据分布在这个平面的两侧，从而达到分类的效果，但是在实际数据中这个符合我们要求的超平面是可能存在多个的。</p><p><a href="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-34a9bf1b868a6880b38d2a932745a098_hd.jpg" class="lazyload"></a></p><p>SVM思想：在感知器模型中，我们可以找到多个可以分类的超平面将数据分开，并且优化时希望所有的点(预测正确的点)都离超平面尽可能的远，但是实际上离超平面足够远的点基本上都是被正确分类的，所以这个是没有意义的；反而比较关心那些离超平面很近的点，这些点比较容易分错。所以说我们<strong>只要让离超平面比较近的点尽可能的远离这个超平面</strong>，那么我们的模型分类效果应该就会比较不错。SVM其实就是这个思想。</p><p><a href="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-b98fb3e59d80593346f14ab66fa0f808_hd.jpg" class="lazyload"></a></p><p>名词概念：</p><ul><li>线性可分(Linearly Separable)：在数据集中，如果可以找出一个超平面，将两组数据分开，那么这个数据集叫做线性可分数据。</li><li>线性不可分(Linear Inseparable)：在数据集中，没法找出一个超平面，能够将两组数据分开，那么这个数据集就叫做线性不可分数据。</li><li>分割超平面(Separating Hyperplane)：将数据集分割开来的直线/平面叫做分割超平面。</li><li>支持向量(Support Vector)：离分割超平面最近的那些点叫做支持向量。</li><li>间隔(Margin)：支持向量数据点到分割超平面的距离称为间隔。</li></ul><p>支持向量到超平面的距离为：在SVM中支持向量到超平面的函数距离一般设置为1</p><p>∵ <a href="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=W%5E%7BT%7D+%2B+b+%3D+%5Cpm1" class="lazyload"></a></p><p>∵ <a href="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=+y%5Cin+%5Cleft%5C%7B+%2B1%2C-1+%5Cright%5C%7D" class="lazyload"></a></p><p>∴ <a href="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7C%28W%5E%7BT%7D%2Bb%29%7C%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D%3D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_%7B2%7D%7D" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-24ef088e0b602c5df7fa8b668fe3ba64_hd.jpg" class="lazyload"></a></p><p>SVM模型是让所有的分类点在各自类别的支持向量远离超平面的一侧，同时要求支持向量尽可能的远离这个超平面，用数学公式表示如下：</p><p>W^{T}=(w_1,w_2,…,w_n)</p><p><a href="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%7C%7CW%7C%7C_2+%3D+%5Csqrt%7Bw_1%5E2%2Bw_2%5E2%2B...%2Bw_n%5E2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmax_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B%7C%7CW%7C%7C_2%7D" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>(s.t: 指”受限制于…“)</p><p><a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%AD%89%E4%BB%B7%E4%BA%8E%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> (对偶问题）</p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>则SVM原始目标函数/损失函数为：</p><p><a href="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=J%28W%29%3D%5Cfrac%7B1%7D%7B2%7D%7B%7C%7CW%7C%7C_2%5E2%7D" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverrightarrow%7B%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87%7D+" class="lazyload"></a> <a href="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=w%5E%2A%2Cb%5E%2A+%3D%5Cmin_%7Bw%2Cb%7DJ%28w%29" class="lazyload"></a></p><p><a href="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=s.t%3Ay%5E%7B%28i%29%7D%28W%5E%7B%28T%29%7D%2Bb%29%5Cgeq+1%2Ci+%3D1%2C2%2C...%2Cm" class="lazyload"></a></p><p>将此时的目标函数和约束条件使用KKT条件转换为拉格朗日函数，从而转换为无约束的优化函数。</p><p><a href="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-02cb85bf58d3c9bd7e8468bf9e316aa6_hd.jpg" class="lazyload"></a></p><p>引入拉格朗日乘子后，优化目标变成：</p><p><a href="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6a43946ee01a9fa39158a042a9b43057_hd.jpg" class="lazyload"></a>g(x)小于等于0 当L取最大值 g(x)等于0 消去g(x) KKT条件分析</p><p>根据拉格朗日对偶化特性，将该优化目标转换为等价的对偶问题来求解，从而优化目标变成：</p><p><a href="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-fff56cdc72e5c16d06562fb521d94f68_hd.jpg" class="lazyload"></a></p><p>所以对于该优化函数而言，可以先求优化函数对于w和b的极小值，然后再求解对于拉格朗日乘子β的极大值。</p><p>首先求让函数L极小化的时候w和b的取值，这个极值可以直接通过对函数L分别求w和b的偏导数得到：</p><p><a href="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f7a305ac6d94f52143db6001a2cfc851_hd.jpg" class="lazyload"></a></p><p>将求解出来的w和b带入优化函数L中，定义优化之后的函数如下：</p><p><a href="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-18d648a84ac7cdb4f1d2ffd497bcb795_hd.jpg" class="lazyload"></a></p><p>通过对w、b极小化后，我们最终得到的优化函数只和β有关，所以此时我们可以直接极大化我们的优化函数，得到β的值，从而可以最终得到w和b的值。β值的求解使用SMO算法</p><p><a href="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-cd158ebb1f823326173942c2f9f7108c_hd.jpg" class="lazyload"></a></p><p>假设存在最优解β*； 根据w、b和β的关系，可以分别计算出对应的w值和b值(一般使用所有支持向量的计算均值来作为实际的b值)；</p><p><a href="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-06bce1ace7a3b98dffe7701e4bc72df0_hd.jpg" class="lazyload"></a></p><p>这里的(xs,ys)即支持向量，根据KKT条件中的对偶互补条件(松弛条件约束)，支持向量必须满足一下公式：</p><p><a href="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-76a71adf17a85bc6b56c95182da3861c_hd.jpg" class="lazyload"></a></p><p>2.线性可分SVM算法流程：</p><ul><li>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</li><li>构造约束优化问题；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-2fb844dd35ea9e4749f487155febbdce_hd.jpg" class="lazyload"></a></p><p>使用SMO算法求出上式优化中对应的最优解β*；</p><ul><li>找出所有的支持向量集合S;</li></ul><p><a href="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-db35ea6da50a013d1cda1f7ea4be5db2_hd.png" class="lazyload"></a></p><ul><li>更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-52855c337fa0a411e6874812f63b875d_hd.png" class="lazyload"></a></p><ul><li>构建最终的分类器；</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.png" class="lazyload"></a></p><h2 id="线性可分svm总结"><a class="markdownIt-Anchor" href="#线性可分svm总结"></a> 线性可分SVM总结</h2><p>\1. 要求数据必须是线性可分的；</p><p>\2. 纯线性可分的SVM模型对于异常数据的预测可能会不太准；</p><p>\3. 对于线性可分的数据，线性SVM分类器的效果非常不错。</p><h1 id="svm的软间隔模型"><a class="markdownIt-Anchor" href="#svm的软间隔模型"></a> SVM的软间隔模型</h1><p>线性可分SVM中要求数据必须是线性可分的，才可以找到分类的超平面，但是有的时候线性数据集中存在少量的异常点，由于这些异常点导致了数据集不能够线性划分；直白来讲就是：正常数据本身是线性可分的，但是由于存在异常点数据，导致数据集不能够线性可分；</p><p><a href="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-57f4e89f38c95bc52155d9a9c4d42a83_hd.jpg" class="lazyload"></a></p><p>如果线性数据中存在异常点导致没法直接使用SVM线性分割模型的时候，我们可以通过引入软间隔的概念来解决这个问题；</p><p>硬间隔：可以认为线性划分SVM中的距离度量就是硬间隔，在线性划分SVM中，要求函数距离一定是大于1的，最大化硬间隔条件为：</p><p><a href="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-058d1967d7f0d71469dd0a9b44e0e4e8_hd.jpg" class="lazyload"></a></p><p>软间隔：SVM对于训练集中的每个样本都引入一个松弛因子(ξ)，使得函数距离加上松弛因子后的值是大于等于1；这表示相对于硬间隔，对样本到超平面距离的要求放松了。(引入松弛因子(ξ))</p><p><a href="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-81f1775aeb8eacd4a0f51abd0c80752c_hd.jpg" class="lazyload"></a></p><p>松弛因子(ξ)越大，表示样本点离超平面越近，如果松弛因子大于1，那么表示允许该样本点分错，所以说加入松弛因子是有成本的，过大的松弛因子可能会导致模型分类错误，所以最终的目标函数就转换成为：</p><p><a href="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-e63000f5acfb29f7ca37250392c46be7_hd.jpg" class="lazyload"></a>注：函数中的C&amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;0是惩罚参数，是一个超参数，类似L1/L2 norm的参数；C越大表示对误分类的惩罚越大，也就是越不允许存在分错的样本；C越小表示对误分类的惩罚越小， 也就是表示允许更多的分错样本存在；C值的给定需要调参。</p><p>同线性可分SVM，根据KKT条件构造软间隔最大化的约束问题对应的拉格朗日函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-ddf2017f97eb62e7cb8ff4aee842171f_hd.jpg" class="lazyload"></a></p><p>从而将我们的优化目标函数转换为：</p><p><a href="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-6dd10648ce3fe36aef7e6e93aba6d847_hd.jpg" class="lazyload"></a></p><p>优化目标同样满足KKT条件，所以使用拉格朗日对偶将优化问题转换为等价的对偶问题：</p><p><a href="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-18bb582ca922a2650aacc0acbd4e42a0_hd.jpg" class="lazyload"></a></p><p>先求优化函数对于w、b、ξ的极小值，这个可以通过分别对优化函数L求w、b、ξ的偏导数得，从而可以得到w、b、ξ关于β和μ之间的关系。</p><p><a href="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-9e698440e94c50fdb44bc99485f7e378_hd.jpg" class="lazyload"></a></p><p>将w、b、ξ的值带入L函数中，就可以消去优化函数中的w、b、ξ，定义优化之后的函数如下：</p><p><a href="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-5ea9e711795f161aeb9ae2efa236dc4b_hd.jpg" class="lazyload"></a></p><p>最终优化后的目标函数/损失函数和线性可分SVM模型基本一样，除了约束条件不同而已， 也就是说也可以使用SMO算法来求解。</p><p><a href="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-abb262a8a47df33a2df066417e9bdc3c_hd.jpg" class="lazyload"></a></p><ul><li>在硬间隔最大化的时候，支持向量比较简单，就是离超平面的函数距离为1的样本点就是支持向量。</li><li>在软间隔中，根据KKT条件中的对偶互补条件: β(1-ξ-y(wx+b))=0和μ(-ξ)=0，以及C-β-μ=0；从而有：</li><li>当0<βi≤C的时候，并且ξi=0的样本点均是支持向量(即所有的0<βi<c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑 第二个kkt条件)< li></c)。即满足|wx+b|=1的所有样本均是支持向量。(取等号时，所有样本都分对，不考虑></li><li>当0<βi<c对应的样本就是支持向量。< li></c对应的样本就是支持向量。<></li><li>注：软间隔和硬间隔中的支持向量的规则是一样的；</li><li><a href="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%E4%B8%BE%E4%BE%8B%EF%BC%9Ax_1%3A%5Cbeta_1%3D%5Cfrac%7Bc%7D%7B2%7D%3Bx_2%3A%5Cbeta_1%3DC%3Bx_3%3A%5Cbeta_1%3D0" class="lazyload"></a> 则x1是支持变量</li></ul><p><a href="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-985576a38c3462b71dea0fdcb9399a5f_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型算法流程"><a class="markdownIt-Anchor" href="#svm的软间隔模型算法流程"></a> SVM的软间隔模型算法流程：</h2><p>输入线性可分的m个样本数据{(x1,y1),(x2,y2),…,(xm,ym)}，其中x为n维的特征向量，y为二元输出，取值为+1或者-1；SVM模型输出为参数w、b以及分类决策函数。</p><p>step 1:选择一个惩罚系数C>0，构造约束优化问题；</p><p><a href="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-416b040899ba4f9baeb36ae3edc20459_hd.jpg" class="lazyload"></a></p><ul><li>Step2:使用SMO算法求出上式优化中对应的最优解β*；</li><li>step3:找出所有的支持向量集合S;</li></ul><p><a href="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-41de52616f86fef3c258acea2e8f053b_hd.jpg" class="lazyload"></a></p><ul><li>step4:更新参数w*、b*的值；</li></ul><p><a href="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-15d6fd74fc0e06eafe0fd45684ae0a65_hd.jpg" class="lazyload"></a></p><ul><li>step5:构建最终的分类器</li></ul><p><a href="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4e99183e9f88171656c5b96946d0bdea_hd.jpg" class="lazyload"></a></p><h2 id="svm的软间隔模型总结"><a class="markdownIt-Anchor" href="#svm的软间隔模型总结"></a> SVM的软间隔模型总结</h2><ul><li>\1. 可以解决线性数据中携带异常点的分类模型构建的问题；</li><li>\2. 通过引入惩罚项系数(松弛因子)，可以增加模型的泛化能力，即鲁棒性；</li><li>\3. 如果给定的惩罚项系数C越小，表示在模型构建的时候，就允许存在越多的分类错误的样本， 也就表示此时模型的准确率会比较低；如果惩罚项系数越大，表示在模型构建的时候，就越不允许存在分类错误的样本，也就表示此时模型的准确率会比较高。</li></ul><h1 id="非线性可分svm"><a class="markdownIt-Anchor" href="#非线性可分svm"></a> 非线性可分SVM</h1><p>不管是线性可分SVM还是加入惩罚系数后的软间隔线性可分SVM其实都要求数据本身是线性可分的，对于完全不可以线性可分的数据，这两种算法模型就没法解决这个问题了</p><p><a href="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-f8f67063f27e49b71c616cd8b0ff1768_hd.jpg" class="lazyload"></a></p><p>结合多项式回归在处理非线性可分数据时候的作用，在SVM的线性不可分的数据上，如果将数据映射到高维空间中，那么数据就会变成线性可分的，从而就可以使用线性可分SVM模型或者软间隔线性可分SVM模型。也就是说，对于线性不可分SVM模型来讲，重点在于低维特征数据到高维特征数据之间的映射。</p><p>定义一个从低维特征空间到高维特征空间的映射函数Ф，非线性可分SVM的优化目标函数：</p><p><a href="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-75f510cb89c8c361c77eb1160299ae35_hd.jpg" class="lazyload"></a></p><p>可以看到的是，只需要将原来的低维空间中的两个向量的点积转换为高维空间中两个向量的点积即可。</p><p><strong>问题</strong>：这样一来问题就解决了吗？似乎是的：拿到非线性数据，就找一个映射，然后一股脑把原来的数据映射到新空间中，再做线性 SVM 即可。不过事实上没有这么简单！其实刚才的方法稍想一下就会发现有问题：在最初的例子里做了一个二阶多项式的转换，对一个二维空间做映射，选择的新空间是原始空间的所有一阶和二阶的组合，得到了5个维度；如果原始空间是三维，那么我们会得到9维的新空间；如果原始空间是n维，那么我们会得到一个n(n+3)/2维的新空间**；这个数目是呈爆炸性增长的，这给计算带来了非常大的困难，而且如果遇到无穷维的情况，就根本无从计算。**</p><p><strong>2.核函数</strong></p><p>假设函数Ф是一个从低维特征空间到高维特征空间的一个映射，那么如果存在函数K(x,z), 对于任意的低维特征向量x和z，都有：</p><p><a href="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-b4a8dff1556c831f44ced2b4b8a68bb2_hd.jpg" class="lazyload"></a></p><p>称函数K(x,z)为核函数(kernal function)：在低维空间上的计算值等价于向量做维度扩展后的点乘的结果。 核函数在解决线性不可分问题的时候，采取的方式是：使用低维特征空间上的计算来避免在高维特征空间中向量内积的恐怖计算量；也就是说此时SVM模型可以应用在高维特征空间中数据可线性分割的优点，同时又避免了引入这个高维特征空间恐怖的内积计算量。</p><p>即：用低维空间中少的内积的计算量来让模型具有高维空间中的线性可分的优点。</p><p><strong>例</strong>：，设两个向量<a href="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_1%3D%28%5Cmu_1%2C%5Cmu_2%29%5ET" class="lazyload"></a> 和<a href="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_2%3D%28%5Ceta_1%2C%5Ceta_2%29%5ET" class="lazyload"></a>，而即是到前面说的五维空间的映射，因此映射过后的内积为：</p><p><a href="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-4b2c15ae39b22357516477bc75f4153f_hd.jpg" class="lazyload"></a></p><p>而同时我们可以发现有一下公式</p><p><a href="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f39d10df0eef97e8fca010239386e89d_hd.jpg" class="lazyload"></a></p><p>可以发现两者之间非常相似，所以我们只要乘上一个相关的系数，就可以让这两个式子的值相等，这样不就将五维空间的一个内积转换为两维空间的内积的运算。</p><p>现有有两个两维的向量，进行二阶多项式扩展，然后进行内积计算，这个时候映射高维后计算的计算量为：11次乘法+4次加法；采用近似计算的计算量为：3次乘法+2次加法；采用加系数后的近似计算的计算量为：4次乘法+2次加法；</p><p><a href="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-43856572c820569884f1422d9f67b4e7_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-7c7d56214ee04cc8877e77e553b5f2d6_hd.jpg" class="lazyload"></a></p><h1 id="核函数总结"><a class="markdownIt-Anchor" href="#核函数总结"></a> 核函数总结</h1><p>\1. 核函数可以自定义；核函数必须是正定核函数，即Gram矩阵是半正定矩阵；</p><p>\2. 核函数的价值在于它的效果相当于将特征进行从低维到高维的转换，但核函数它是在低维空间上的计算，而将实质上的分类效果表现在了高维上，也就如上文所说的避免了直接在高维空间中的复杂计算；</p><p>\3. 通过核函数，可以将非线性可分的数据转换为线性可分数据；</p><p><a href="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-1329d1727de95e807778d939a0be684e_hd.jpg" class="lazyload"></a></p><h2 id="svr"><a class="markdownIt-Anchor" href="#svr"></a> SVR</h2><p>做回归用，了解即可</p><h1 id="坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"><a class="markdownIt-Anchor" href="#坐标下降上升法原理搬运自httpsblogcsdnnetu010626937articledetails75044343"></a> 坐标下降（上升）法原理(搬运自<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/u010626937/article/details/75044343">https://blog.csdn.net/u010626937/article/details/75044343</a>)</h1><p>假设要求解下面的优化问题：</p><p><a href="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-86fdda7492b0e91d559074c7c3504b15_hd.jpg" class="lazyload"></a></p><p>在这里，我们需要求解m个变量αi，一般来说是通过梯度下降（这里是求最大值，所以应该叫上升）等算法来求解，每一次迭代对所有m个变量αi也就是α向量进行一次性优化。（这里指的是一个向量的所有分量）。通过每次迭代中的误差调整α向量中每个元素的值。而坐标上升法（坐标上升与坐标下降可以看做是一对，坐标上升是用来求解max最优化问题，坐标下降用于求min最优化问题）的思想是每次迭代只调整一个变量αi的值，其他变量的值在这次迭代中固定不变。(这里指的是一个向量中的一个分量)。</p><p><a href="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-0a76ca02d7aeca50e12f87d8768e23fa_hd.jpg" class="lazyload"></a></p><p>最里面语句的意思是固定除αi之外的所有αj(i不等于j)，这时W可看作只是关于αi的函数，那么直接对αi求导优化即可。这里我们进行最大化求导的顺序i是从1到m，可以通过更改优化顺序来使W能够更快地增加并收敛。如果W在内循环中能够很快地达到最优，那么坐标上升法会是一个很高效的求极值方法。</p><p>用个二维的例子来说明下坐标下降法：我们需要寻找f(x,y)=x2+xy+y2的最小值处的(x*, y*)，也就是下图的F*点的地方.</p><p><a href="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-0cfa7b069221d4712fc548de565fa4bf_hd.jpg" class="lazyload"></a></p><p>假设我们初始的点是A（图是函数投影到xoy平面的等高线图，颜色越深值越小），我们需要达到F<em>的地方。那最快的方法就是图中黄色线的路径，一次性就到达了，其实这个是牛顿优化法，但如果是高维的话，这个方法就不太高效了（因为需要求解矩阵的逆，这个不在这里讨论）。我们也可以按照红色所指示的路径来走。从A开始，先固定x，沿着y轴往让f(x, y)值减小的方向走到B点，然后固定y，沿着x轴往让f(x, y)值减小的方向走到C点，不断循环，直到到达F</em>。反正每次只要我们都往让f(x, y)值小的地方走就行了，这样脚踏实地，一步步走，每一步都使f(x, y)慢慢变小，总有一天，皇天不负有心人的。到达F*也是时间问题。到这里你可能会说，这红色线比黄色线贫富差距也太严重了吧。因为这里是二维的简单的情况嘛。如果是高维的情况，而且目标函数很复杂的话，再加上样本集很多，那么在梯度下降中，目标函数对所有αi求梯度或者在牛顿法中对矩阵求逆，都是很耗时的。这时候，如果W只对单个αi优化很快的时候，坐标下降法可能会更加高效。</p><p>数学例题讲解</p><p>下面以如下的优化问题为例：</p><p><a href="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e8e0fbf24641d2870e73afb37d5ea314_hd.jpg" class="lazyload"></a></p><p>在迭代的过程中，每次固定x2更新x1，在确定了x1的条件下，固定x1，更新x2。即每次迭代求解：</p><p><a href="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-a7ca59f51128df8fda73c1bb5d526caf_hd.jpg" class="lazyload"></a></p><p>也即求解</p><p><a href="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-752c0afacf65bc82834fdbda663d5563_hd.jpg" class="lazyload"></a></p><p>，假设我们首先固定x2,来更新x1：</p><p><a href="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-f5f023d363b7c98ad1e8bf5c0fef8056_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-33dec1f932c2d1e1fab44e765f71b47f_hd.jpg" class="lazyload"></a></p><p>再固定x1，得到：</p><p><a href="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-78e53345eee05fe96b87d2fdd2d420e8_hd.jpg" class="lazyload"></a></p><p>令其为0，得到：</p><p><a href="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2fee9f423e18184370e88bdbd62e1647_hd.jpg" class="lazyload"></a></p><p>不断按照上述的过程，直到算法收敛。</p><h1 id="七-smo可略过"><a class="markdownIt-Anchor" href="#七-smo可略过"></a> 七、SMO（可略过）</h1><p>序列最小优化算法(Sequential minimal optimization, SMO)是一种用于解决SVM训练过程中所产生的优化问题的算法。 于1998年由John Platt发明。SMO的思想类似坐标上升算法，我们需要优化一系列的αα的值，我们每次选择尽量少的 <a href="https://www.zhihu.com/equation?tex=%5Calpha" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Calpha" class="lazyload"></a> 来优化，不断迭代直到函数收敛到最优值。</p><p>梯度提升算法采用增量完成迭代，SMO利用自身完成迭代，如 <a href="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=x_%7Bn%7D%3Dx_%7Bn-1%7D%2Bx_%7Bn-1%7D%5E2" class="lazyload"></a> 。</p><p>目标函数：</p><p><a href="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-471fb90bee8734bf5b96e0f2e4159c88_hd.jpg" class="lazyload"></a></p><p>假定存在一个β*=(β1,β2,…,βm)是我们最终的最优解，那么根据KKT条件我们可以计算出w和b的最优解，如下：</p><p><a href="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-c6f6d5f7a46fa9ae8e34f02f2d01c32e_hd.jpg" class="lazyload"></a></p><p>进而我们可以得到最终的分离超平面为:</p><p><a href="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-8eb2de93cbd432ae34c2839b338b904d_hd.jpg" class="lazyload"></a></p><p>拉格朗日乘子法和KKT的对偶互补条件为：</p><p><a href="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-7a3db75451bdbc18cd60b661c09951e9_hd.jpg" class="lazyload"></a></p><p>β、μ和C之间的关系为：</p><p><a href="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-877f9fafcdd102240967047500c2b65e_hd.jpg" class="lazyload"></a></p><p>根据这个对偶互补条件，我们有如下关系式：</p><p><a href="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-e08707660871b5c8b0b3e1fda541c164_hd.jpg" class="lazyload"></a></p><p>也就是说我们找出的最优的分割超平面必须满足下列的目标条件(g(x)):</p><p><a href="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-2a8a996a29ec10417594a7e1d168d9f3_hd.jpg" class="lazyload"></a></p><p>拉格朗日对偶化要求的两个限制的初始条件为：</p><p><a href="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-711f5cbe7a1707bfa223b5f01aa9a37f_hd.jpg" class="lazyload"></a></p><p>从而可以得到解决问题的思路如下：</p><ul><li>首先，初始化后一个β值，让它满足对偶问题的两个初始限制条件；</li><li>然后不断优化这个β值，使得由它确定的分割超平面满足g(x)目标条件；而且在优化过程中，始终保证β值满足初始限制条件。</li><li>备注：这个求解过程中，和传统的思路不太一样，不是对目标函数求最小值，而是让g(x)目标条件尽可能的满足。</li></ul><p>在这样一个过程中，到底如何优化这个β值呢？？？整理可以发现β值的优化必须遵循以下两个基本原则：</p><ul><li>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</li><li>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于1的，yg(x)结果越是小于1就表示违反g(x)目标条件就越多。</li></ul><p>或者换一种思路来理解，因为目标函数中存在m个变量，直接优化比较难，利用启发式的方法/EM算法的思想，每次优化的时候，只优化两个变量，将其它的变量看成常数项，这样SMO算法就将一个复杂的优化算法转换为一个比较简单的两变量优化问题了。</p><p><a href="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-65ef6118e70d770cc1158702600b5b14_hd.jpg" class="lazyload"></a></p><p>认为β1、β2是变量，其它β值是常量，从而将目标函数转换如下(C是常数项)：</p><p><a href="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-8f0adc4e3d95b422d2932ac0b61e4b14_hd.jpg" class="lazyload"></a></p><p>由于 <a href="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cbeta_1y%5E%7B%281%29%7D%2B%5Cbeta_2y%5E%7B%282%29%7D%3Dk" class="lazyload"></a> ,并且y2=1，也就是我们使用β2来表示β1的值：</p><p>将上式带入目标优化函数，就可以消去β1，从而只留下仅仅包含β2的式子。</p><p><a href="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-341757aa247825ba112eb1e22f3b9b8b_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-73dc77410e0e3689046625d4235464ec_hd.jpg" class="lazyload"></a>V1,V2</p><p><a href="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-bc7cbecd90e8b2bdd6a88eecbba638d2_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-2934406d28667dbe5b2dbaef9fce4b9d_hd.jpg" class="lazyload"></a>消去beta1</p><p><a href="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-3555ff104a22b4cf7b3516a74ef66e3e_hd.jpg" class="lazyload"></a></p><p><a href="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-6cc402edcdb1dba8489a880f567ad865_hd.jpg" class="lazyload"></a></p><p>考虑β1和β2的取值限定范围，假定新求出来的β值是满足我们的边界限制的，即如下所示：</p><p><a href="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-3ad3cc4186a75ac656b9c9a660809f93_hd.jpg" class="lazyload"></a></p><p>当y1=y2的时候，β1+β2=k； 由于β的限制条件，我们可以得到：</p><p><a href="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-0cfc8d419c83c41d1b7026959a12c200_hd.jpg" class="lazyload"></a></p><p><a href="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-74ce7b68817b967c97e0e7942ee83437_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-dfc7811742ce6fd78c6034157b3f1024_hd.jpg" class="lazyload"></a></p><p><a href="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-4d2d313ed0adcd1205a7bda97eeb352e_hd.jpg" class="lazyload"></a></p><p>可以发现SMO算法中，是选择两个合适的β变量做迭代，其它变量作为常量来进行优化的一个过程，那么这两个变量到底怎么选择呢???</p><p>每次优化的时候，必须同时优化β的两个分量；因为如果只优化一个分量的话，新的β值就没法满足初始限制条件中的等式约束条件了。</p><p>每次优化的两个分量应该是违反g(x)目标条件比较多的。也就是说，本来应当是大于等于1的，越是小于1违反g(x)目标条件就越多。</p><p>SMO算法在选择第一个β变量的时候，需要选择在训练集上违反KKT条件最严重的样本点。一般情况下，先选择0<β<c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。< p></c的样本点(即支持向量)，只有当所有的支持向量都满足kkt条件的时候，才会选择其它样本点。因为此时违反kkt条件越严重，在经过一次优化后，会让变量β尽可能的发生变化，从而可以以更少的迭代次数让模型达到g(x)目标条件。<></p><p><a href="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-28ab310c1eebe7b33e070e6067b5e15b_hd.jpg" class="lazyload"></a></p><p>在选择第一个变量β1后，在选择第二个变量β2的时候，希望能够按照优化后的β1和β2有尽可能多的改变来选择，也就是说让|E1-E2|足够的大，当E1为正的时候，选择最小的Ei作为E2；当E1为负的时候，选择最大的Ei作为E2。</p><p>备注：如果选择的第二个变量不能够让目标函数有足够的下降，那么可以通过遍历所有样本点来作为β2，直到目标函数有足够的下降，如果都没有足够的下降的话，那么直接跳出循环，重新选择β1；</p><p>在每次完成两个β变量的优化更新之后，需要重新计算阈值b和差值Ei。当0<β1new<c时，有：< p></c时，有：<></p><p><a href="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic2.zhimg.com/80/v2-f786b8a13e569ea78098c3233af43bd5_hd.jpg" class="lazyload"></a></p><p>化简可得：</p><p><a href="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-afb0a7abbd6bc3d3089ea59d2c0c9548_hd.jpg" class="lazyload"></a></p><p><a href="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic1.zhimg.com/80/v2-36299a18d8454fe5fd5e9228b08604a4_hd.jpg" class="lazyload"></a></p><p>同样的当β2的取值为: 0<β2<c的时候，我们也可以得到< p></c的时候，我们也可以得到<></p><p><a href="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-078e311d32f22c21573b2c9ecde73d07_hd.jpg" class="lazyload"></a></p><p>最终计算出来的b为：</p><p><a href="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic4.zhimg.com/80/v2-8976450ef72064d77efba0ac4649352f_hd.jpg" class="lazyload"></a></p><p>当更新计算阈值b后，就可以得到差值Ei为：</p><p><a href="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" data-fancybox="group" data-caption="img" class="fancybox"><img alt="img" title="img" data-src="https://pic3.zhimg.com/80/v2-92670ad976295bc41da68c9100eee102_hd.jpg" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/01/06/hello-world/"/>
      <url>/2020/01/06/hello-world/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script></head><body><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2><h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure></div><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p></body></html>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
